---
title: ãƒ†ã‚¹ãƒˆé§†å‹•é–‹ç™ºã‹ã‚‰å§‹ã‚ã‚‹æ©Ÿæ¢°å­¦ç¿’å…¥é–€
description: TDDã§å­¦ã¶Pythonæ©Ÿæ¢°å­¦ç¿’ãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°
published: true
date: 2025-10-18T00:00:00.000Z
tags:
editor: markdown
dateCreated: 2025-10-18T00:00:00.000Z
---

# ãƒ†ã‚¹ãƒˆé§†å‹•é–‹ç™ºã‹ã‚‰å§‹ã‚ã‚‹æ©Ÿæ¢°å­¦ç¿’å…¥é–€

## ã¯ã˜ã‚ã«

æœ¬è¨˜äº‹ã¯ã€ãƒ†ã‚¹ãƒˆé§†å‹•é–‹ç™ºï¼ˆTDDï¼‰ã‚’å®Ÿè·µã—ãªãŒã‚‰ Python ã§æ©Ÿæ¢°å­¦ç¿’ã‚’å­¦ã¶ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®å®Œå…¨ã‚¬ã‚¤ãƒ‰ã§ã™ã€‚6ã¤ã®ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’é€šã˜ã¦ã€åŸºç¤çš„ãªåˆ†é¡å•é¡Œã‹ã‚‰æœ¬æ ¼çš„ãªäºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã® API åŒ–ã¾ã§ã€æ®µéšçš„ã«ã‚¹ã‚­ãƒ«ã‚¢ãƒƒãƒ—ã§ãã‚‹æ§‹æˆã«ãªã£ã¦ã„ã¾ã™ã€‚

### ğŸ¯ æœ¬è¨˜äº‹ã§å­¦ã¹ã‚‹ã“ã¨

- **ãƒ†ã‚¹ãƒˆé§†å‹•é–‹ç™ºï¼ˆTDDï¼‰ã®å®Ÿè·µ**: Red-Green-Refactor ã‚µã‚¤ã‚¯ãƒ«ã‚’å®Ÿæ©Ÿæ¢°å­¦ç¿’é–‹ç™ºã§ä½“é¨“
- **Python æ©Ÿæ¢°å­¦ç¿’é–‹ç™º**: scikit-learn ã«ã‚ˆã‚‹å®Ÿè·µçš„ãªãƒ¢ãƒ‡ãƒ«æ§‹ç¯‰
- **ç¾ä»£çš„ Python é–‹ç™º**: uvã€Ruffã€mypy ç­‰ã®æœ€æ–°ãƒ„ãƒ¼ãƒ«ãƒã‚§ãƒ¼ãƒ³
- **æ®µéšçš„ã‚¹ã‚­ãƒ«ã‚¢ãƒƒãƒ—**: ç„¡ç†ã®ãªã„å­¦ç¿’æ›²ç·šã§ç¢ºå®Ÿã«ãƒ¬ãƒ™ãƒ«ã‚¢ãƒƒãƒ—

---

## ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ 1: åŸºç¤æº–å‚™

### 1ç«  æ©Ÿæ¢°å­¦ç¿’ã¨ã¯

#### æ©Ÿæ¢°å­¦ç¿’ã®ç‰¹å¾´

æ©Ÿæ¢°å­¦ç¿’ã¯ã€ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å­¦ç¿’ã—ã€äºˆæ¸¬ã‚„åˆ†é¡ã‚’è¡Œã†æŠ€è¡“ã§ã™ã€‚ä»¥ä¸‹ã®ç‰¹å¾´ãŒã‚ã‚Šã¾ã™ï¼š

- **ãƒ‡ãƒ¼ã‚¿é§†å‹•**: æ˜ç¤ºçš„ãªãƒ—ãƒ­ã‚°ãƒ©ãƒŸãƒ³ã‚°ãªã—ã«ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ãƒ«ãƒ¼ãƒ«ã‚’å­¦ç¿’
- **æ±åŒ–èƒ½åŠ›**: æœªçŸ¥ã®ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦ã‚‚é©åˆ‡ãªäºˆæ¸¬ã‚’å®Ÿè¡Œ
- **ç¶™ç¶šçš„æ”¹å–„**: ãƒ‡ãƒ¼ã‚¿è¿½åŠ ã«ã‚ˆã‚Šãƒ¢ãƒ‡ãƒ«æ€§èƒ½ãŒå‘ä¸Š
- **å®Ÿç”¨çš„å¿œç”¨**: ãƒ“ã‚¸ãƒã‚¹èª²é¡Œã®è§£æ±ºã«ç›´æ¥è²¢çŒ®

#### æœ¬ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§æ‰±ã†å•é¡Œ

æœ¬ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ã¯ã€ä»¥ä¸‹ã®4ã¤ã®æ©Ÿæ¢°å­¦ç¿’å•é¡Œã‚’æ®µéšçš„ã«å®Ÿè£…ã—ã¾ã™ï¼š

**åˆ†é¡å•é¡Œ**:
- `Iris åˆ†é¡`: ã‚¢ãƒ¤ãƒ¡ã®ç¨®é¡ã‚’3ã¤ã«åˆ†é¡ï¼ˆå¤šã‚¯ãƒ©ã‚¹åˆ†é¡ï¼‰
- `Survived åˆ†é¡`: ä¹—å®¢ã®ç”Ÿå­˜ã‚’2å€¤ã§åˆ†é¡ï¼ˆäºŒå€¤åˆ†é¡ï¼‰

**å›å¸°å•é¡Œ**:
- `Cinema äºˆæ¸¬`: æ˜ ç”»ã®èˆˆè¡Œåå…¥ã‚’äºˆæ¸¬ï¼ˆç·šå½¢å›å¸°ï¼‰
- `Boston äºˆæ¸¬`: ä½å®…ã®å¹³å‡ä¾¡æ ¼ã‚’äºˆæ¸¬ï¼ˆç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ï¼‰

#### å•é¡Œé¸æŠãƒ•ãƒ­ãƒ¼ãƒãƒ£ãƒ¼ãƒˆ

```plantuml
@startuml
start
if (äºˆæ¸¬ã—ãŸã„ã®ã¯æ•°å€¤ã§ã™ã‹ï¼Ÿ) then (yes)
  if (æ˜ ç”»ã®èˆˆè¡Œåå…¥ã‚’äºˆæ¸¬ã—ãŸã„ã§ã™ã‹ï¼Ÿ) then (yes)
    :Cinema API ã‚’ä½¿ç”¨;
  else (no)
    :Boston API ã‚’ä½¿ç”¨;
  endif
else (no)
  if (ã‚¢ãƒ¤ãƒ¡ã®ç¨®é¡ã‚’åˆ†é¡ã—ãŸã„ã§ã™ã‹ï¼Ÿ) then (yes)
    :Iris API ã‚’ä½¿ç”¨;
  else (no)
    :Survived API ã‚’ä½¿ç”¨;
  endif
endif
stop
@enduml
```

### 2ç«  é–‹ç™ºç’°å¢ƒã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

#### ç¾ä»£çš„ Python é–‹ç™ºç’°å¢ƒã®æ§‹ç¯‰

æœ¬ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ã¯ã€2024å¹´æœ€æ–°ã® Python é–‹ç™ºãƒ„ãƒ¼ãƒ«ãƒã‚§ãƒ¼ãƒ³ã‚’æ¡ç”¨ã—ã¦ã„ã¾ã™ï¼š

##### å¿…è¦ãªãƒ„ãƒ¼ãƒ«

- **Python 3.10+**: æœ€æ–°ã®å‹ãƒ’ãƒ³ãƒˆæ©Ÿèƒ½ã‚’æ´»ç”¨
- **uv**: æ¬¡ä¸–ä»£é«˜é€Ÿãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ï¼ˆpip ã¨ venv ã®ä»£æ›¿ï¼‰
- **Ruff**: ã‚ªãƒ¼ãƒ«ã‚¤ãƒ³ãƒ¯ãƒ³å“è³ªç®¡ç†ãƒ„ãƒ¼ãƒ«ï¼ˆflake8ã€blackã€isort ã®ä»£æ›¿ï¼‰
- **mypy**: é™çš„å‹ãƒã‚§ãƒƒã‚«ãƒ¼
- **pytest**: ãƒ†ã‚¹ãƒ†ã‚£ãƒ³ã‚°ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯
- **scikit-learn**: æ©Ÿæ¢°å­¦ç¿’ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
- **pandas**: ãƒ‡ãƒ¼ã‚¿åˆ†æãƒ©ã‚¤ãƒ–ãƒ©ãƒª
- **FastAPI**: é«˜æ€§èƒ½ Web API ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯

##### ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—æ‰‹é †

```bash
# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
mkdir ml-tdd-project && cd ml-tdd-project

# uv ã«ã‚ˆã‚‹åˆæœŸåŒ–
uv init

# ä¾å­˜é–¢ä¿‚ã®è¿½åŠ 
uv add pandas scikit-learn fastapi uvicorn
uv add --dev pytest pytest-cov ruff mypy

# pyproject.toml ã®è¨­å®š
```

##### å“è³ªç®¡ç†è¨­å®š

**pyproject.toml** ã§ã®çµ±åˆè¨­å®šï¼š

```toml
[tool.ruff]
line-length = 88
target-version = "py310"

[tool.ruff.lint.mccabe]
max-complexity = 7  # å¾ªç’°çš„è¤‡é›‘åº¦ã®åˆ¶é™

[tool.mypy]
python_version = "3.10"
warn_return_any = true
warn_unused_configs = true
disallow_untyped_defs = true

[tool.pytest.ini_options]
testpaths = ["test"]
addopts = "--cov=src --cov-report=html --cov-report=term-missing"
```

å„ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã§ã¯å…±é€šã—ã¦ã“ã®ç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã‚’ä½¿ç”¨ã™ã‚‹ãŸã‚ã€æœ€åˆã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ä»¥é™ã¯çœç•¥ã—ã¾ã™ã€‚

#### ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ ã®ä½œæˆ

TDD ã«åŸºã¥ã„ãŸæ©Ÿæ¢°å­¦ç¿’ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®åŸºæœ¬æ§‹é€ ã‚’ä½œæˆã—ã¾ã™ï¼š

```bash
ml-tdd-project/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ ml/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ iris_classifier.py
â”‚       â”œâ”€â”€ cinema_predictor.py
â”‚       â”œâ”€â”€ survived_classifier.py
â”‚       â””â”€â”€ boston_predictor.py
â”œâ”€â”€ test/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ test_basic.py
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ iris.csv
â”‚   â”œâ”€â”€ cinema.csv
â”‚   â”œâ”€â”€ Survived.csv
â”‚   â””â”€â”€ Boston.csv
â”œâ”€â”€ model/
â”‚   â””â”€â”€ .gitkeep
â”œâ”€â”€ pyproject.toml
â””â”€â”€ README.md
```

**ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹æˆã®æ„å›³**ï¼š
- `src/ml/`: æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®å®Ÿè£…
- `test/`: ãƒ†ã‚¹ãƒˆã‚³ãƒ¼ãƒ‰ï¼ˆpytest ã«ã‚ˆã‚‹è‡ªå‹•ãƒ†ã‚¹ãƒˆï¼‰
- `data/`: è¨“ç·´ãƒ»ãƒ†ã‚¹ãƒˆç”¨ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ
- `model/`: è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜å…ˆ

#### åˆæœŸãƒ†ã‚¹ãƒˆã®ä½œæˆ

TDD ã®åŸºæœ¬ã¨ã—ã¦ã€ã¾ãšæœ€åˆã®ãƒ†ã‚¹ãƒˆã‚’ä½œæˆã—ã¾ã™ã€‚

**test/test_basic.py**:

```python
"""åŸºæœ¬çš„ãªç’°å¢ƒç¢ºèªãƒ†ã‚¹ãƒˆ"""
import pytest
import pandas as pd
import sklearn
import numpy as np


def test_ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆç¢ºèª():
    """å¿…è¦ãªãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãŒæ­£ã—ãã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèª"""
    assert pd is not None
    assert sklearn is not None
    assert np is not None


def test_pandasã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç¢ºèª():
    """pandas ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ãŒ 1.0 ä»¥ä¸Šã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª"""
    version = pd.__version__
    major_version = int(version.split('.')[0])
    assert major_version >= 1


def test_scikit_learnã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç¢ºèª():
    """scikit-learn ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ãŒ 1.0 ä»¥ä¸Šã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª"""
    version = sklearn.__version__
    major_version = int(version.split('.')[0])
    assert major_version >= 1


class TestDataFrameBasics:
    """pandas DataFrame ã®åŸºæœ¬æ“ä½œãƒ†ã‚¹ãƒˆ"""

    def test_DataFrameã®ä½œæˆ(self):
        """DataFrame ã‚’ä½œæˆã§ãã‚‹ã“ã¨ã‚’ç¢ºèª"""
        df = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6]})
        assert len(df) == 3
        assert list(df.columns) == ['A', 'B']

    def test_æ¬ æå€¤ã®æ¤œå‡º(self):
        """æ¬ æå€¤ã‚’æ­£ã—ãæ¤œå‡ºã§ãã‚‹ã“ã¨ã‚’ç¢ºèª"""
        df = pd.DataFrame({'A': [1, np.nan, 3]})
        assert df['A'].isnull().sum() == 1

    def test_æ¬ æå€¤ã®è£œå®Œ(self):
        """æ¬ æå€¤ã‚’å¹³å‡å€¤ã§è£œå®Œã§ãã‚‹ã“ã¨ã‚’ç¢ºèª"""
        df = pd.DataFrame({'A': [1.0, np.nan, 3.0]})
        mean_value = df['A'].mean()
        df['A'] = df['A'].fillna(mean_value)

        assert df['A'].isnull().sum() == 0
        assert df['A'].iloc[1] == 2.0  # (1 + 3) / 2 = 2


class TestScikitLearnBasics:
    """scikit-learn ã®åŸºæœ¬æ“ä½œãƒ†ã‚¹ãƒˆ"""

    def test_train_test_splitã®å‹•ä½œç¢ºèª(self):
        """ãƒ‡ãƒ¼ã‚¿åˆ†å‰²ãŒæ­£ã—ãå‹•ä½œã™ã‚‹ã“ã¨ã‚’ç¢ºèª"""
        from sklearn.model_selection import train_test_split

        X = [[1, 2], [3, 4], [5, 6], [7, 8]]
        y = [0, 1, 0, 1]

        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.5, random_state=0
        )

        assert len(X_train) == 2
        assert len(X_test) == 2
        assert len(y_train) == 2
        assert len(y_test) == 2

    def test_æ±ºå®šæœ¨ãƒ¢ãƒ‡ãƒ«ã®ä½œæˆ(self):
        """æ±ºå®šæœ¨ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆã§ãã‚‹ã“ã¨ã‚’ç¢ºèª"""
        from sklearn.tree import DecisionTreeClassifier

        model = DecisionTreeClassifier(max_depth=2)
        assert model is not None
        assert model.max_depth == 2

    def test_ç·šå½¢å›å¸°ãƒ¢ãƒ‡ãƒ«ã®ä½œæˆ(self):
        """ç·šå½¢å›å¸°ãƒ¢ãƒ‡ãƒ«ã‚’ä½œæˆã§ãã‚‹ã“ã¨ã‚’ç¢ºèª"""
        from sklearn.linear_model import LinearRegression

        model = LinearRegression()
        assert model is not None
```

#### ãƒ†ã‚¹ãƒˆã®å®Ÿè¡Œ

ä½œæˆã—ãŸãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œã—ã¦ã€ç’°å¢ƒãŒæ­£ã—ãã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¾ã™ï¼š

```bash
# pytest ã«ã‚ˆã‚‹å…¨ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
uv run pytest test/test_basic.py -v

# ã‚«ãƒãƒ¬ãƒƒã‚¸ä»˜ãã§ã®å®Ÿè¡Œ
uv run pytest test/test_basic.py --cov=src --cov-report=term-missing

# å‡ºåŠ›ä¾‹ï¼š
# test/test_basic.py::test_ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆç¢ºèª PASSED
# test/test_basic.py::test_pandasã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç¢ºèª PASSED
# test/test_basic.py::test_scikit_learnã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ç¢ºèª PASSED
# test/test_basic.py::TestDataFrameBasics::test_DataFrameã®ä½œæˆ PASSED
# test/test_basic.py::TestDataFrameBasics::test_æ¬ æå€¤ã®æ¤œå‡º PASSED
# test/test_basic.py::TestDataFrameBasics::test_æ¬ æå€¤ã®è£œå®Œ PASSED
# test/test_basic.py::TestScikitLearnBasics::test_train_test_splitã®å‹•ä½œç¢ºèª PASSED
# test/test_basic.py::TestScikitLearnBasics::test_æ±ºå®šæœ¨ãƒ¢ãƒ‡ãƒ«ã®ä½œæˆ PASSED
# test/test_basic.py::TestScikitLearnBasics::test_ç·šå½¢å›å¸°ãƒ¢ãƒ‡ãƒ«ã®ä½œæˆ PASSED
#
# =========== 9 passed in 0.45s ===========
```

#### å“è³ªç®¡ç†ãƒ„ãƒ¼ãƒ«ã®å‹•ä½œç¢ºèª

##### Ruff ã«ã‚ˆã‚‹ã‚³ãƒ¼ãƒ‰å“è³ªãƒã‚§ãƒƒã‚¯

```bash
# ã‚³ãƒ¼ãƒ‰ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®ãƒã‚§ãƒƒã‚¯
uv run ruff check .

# ã‚³ãƒ¼ãƒ‰ã®è‡ªå‹•ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
uv run ruff format .

# å‡ºåŠ›ä¾‹ï¼š
# All checks passed!
```

##### mypy ã«ã‚ˆã‚‹å‹ãƒã‚§ãƒƒã‚¯

**test/test_basic.py** ã«å‹ãƒ’ãƒ³ãƒˆã‚’è¿½åŠ ï¼š

```python
import pytest
import pandas as pd
from typing import List


def test_å‹ãƒ’ãƒ³ãƒˆä»˜ãé–¢æ•°() -> None:
    """å‹ãƒ’ãƒ³ãƒˆãŒæ­£ã—ãæ©Ÿèƒ½ã™ã‚‹ã“ã¨ã‚’ç¢ºèª"""
    data: List[int] = [1, 2, 3, 4, 5]
    assert len(data) == 5
```

```bash
# mypy ã«ã‚ˆã‚‹å‹ãƒã‚§ãƒƒã‚¯å®Ÿè¡Œ
uv run mypy test/test_basic.py

# å‡ºåŠ›ä¾‹ï¼š
# Success: no issues found in 1 source file
```

#### TDD ã‚µã‚¤ã‚¯ãƒ«ã®ä½“é¨“

ç°¡å˜ãªä¾‹ã§ TDD ã® Red-Green-Refactor ã‚µã‚¤ã‚¯ãƒ«ã‚’ä½“é¨“ã—ã¾ã™ã€‚

##### Red: å¤±æ•—ã™ã‚‹ãƒ†ã‚¹ãƒˆã‚’æ›¸ã

**test/test_data_loader.py**:

```python
"""ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ã®ãƒ†ã‚¹ãƒˆï¼ˆTDD ã‚µã‚¤ã‚¯ãƒ«ä¾‹ï¼‰"""
import pytest
import pandas as pd
from src.ml.data_loader import DataLoader


class TestDataLoader:
    """DataLoader ã‚¯ãƒ©ã‚¹ã®ãƒ†ã‚¹ãƒˆ"""

    def test_CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚ã‚‹(self):
        """CSV ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ DataFrame ã¨ã—ã¦èª­ã¿è¾¼ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª"""
        loader = DataLoader()
        df = loader.load_csv('data/iris.csv')

        assert df is not None
        assert isinstance(df, pd.DataFrame)
        assert len(df) > 0
```

ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œã™ã‚‹ã¨å¤±æ•—ã—ã¾ã™ï¼ˆRedï¼‰ï¼š

```bash
uv run pytest test/test_data_loader.py -v

# å‡ºåŠ›ä¾‹ï¼š
# ModuleNotFoundError: No module named 'src.ml.data_loader'
```

##### Green: ãƒ†ã‚¹ãƒˆã‚’é€šã™æœ€å°é™ã®å®Ÿè£…

**src/ml/data_loader.py**:

```python
"""ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«"""
import pandas as pd


class DataLoader:
    """CSV ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€ã‚¯ãƒ©ã‚¹"""

    def load_csv(self, file_path: str) -> pd.DataFrame:
        """CSV ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€

        Args:
            file_path: CSV ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹

        Returns:
            èª­ã¿è¾¼ã‚“ã  DataFrame
        """
        return pd.read_csv(file_path)
```

ãƒ†ã‚¹ãƒˆã‚’å†å®Ÿè¡Œã™ã‚‹ã¨æˆåŠŸã—ã¾ã™ï¼ˆGreenï¼‰ï¼š

```bash
uv run pytest test/test_data_loader.py -v

# å‡ºåŠ›ä¾‹ï¼š
# test/test_data_loader.py::TestDataLoader::test_CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚ã‚‹ PASSED
# =========== 1 passed in 0.12s ===========
```

##### Refactor: ã‚³ãƒ¼ãƒ‰ã®æ”¹å–„

ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã¨å‹ãƒ’ãƒ³ãƒˆã‚’è¿½åŠ ã—ã¦ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°ï¼š

**test/test_data_loader.py** ã«ãƒ†ã‚¹ãƒˆã‚’è¿½åŠ ï¼š

```python
def test_å­˜åœ¨ã—ãªã„ãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç†(self):
    """å­˜åœ¨ã—ãªã„ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æŒ‡å®šã—ãŸå ´åˆã«é©åˆ‡ãªã‚¨ãƒ©ãƒ¼ã‚’è¿”ã™ã“ã¨ã‚’ç¢ºèª"""
    loader = DataLoader()

    with pytest.raises(FileNotFoundError):
        loader.load_csv('data/non_existent.csv')


def test_ç©ºã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã®å‡¦ç†(self):
    """ç©ºã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’æŒ‡å®šã—ãŸå ´åˆã«ã‚¨ãƒ©ãƒ¼ã‚’è¿”ã™ã“ã¨ã‚’ç¢ºèª"""
    loader = DataLoader()

    with pytest.raises(ValueError):
        loader.load_csv('')
```

**src/ml/data_loader.py** ã‚’ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°ï¼š

```python
"""ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«"""
import os
import pandas as pd
from typing import Optional


class DataLoader:
    """CSV ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€ã‚¯ãƒ©ã‚¹"""

    def load_csv(self, file_path: str) -> pd.DataFrame:
        """CSV ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚€

        Args:
            file_path: CSV ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹

        Returns:
            èª­ã¿è¾¼ã‚“ã  DataFrame

        Raises:
            ValueError: ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ãŒç©ºã®å ´åˆ
            FileNotFoundError: ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆ
        """
        if not file_path:
            raise ValueError("File path cannot be empty")

        if not os.path.exists(file_path):
            raise FileNotFoundError(f"File not found: {file_path}")

        return pd.read_csv(file_path)
```

ãƒ†ã‚¹ãƒˆã‚’å†å®Ÿè¡Œã—ã¦å…¨ã¦é€šã‚‹ã“ã¨ã‚’ç¢ºèªï¼š

```bash
uv run pytest test/test_data_loader.py -v

# å‡ºåŠ›ä¾‹ï¼š
# test/test_data_loader.py::TestDataLoader::test_CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã‚ã‚‹ PASSED
# test/test_data_loader.py::TestDataLoader::test_å­˜åœ¨ã—ãªã„ãƒ•ã‚¡ã‚¤ãƒ«ã®å‡¦ç† PASSED
# test/test_data_loader.py::TestDataLoader::test_ç©ºã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã®å‡¦ç† PASSED
# =========== 3 passed in 0.15s ===========
```

#### ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™

å®Ÿéš›ã®æ©Ÿæ¢°å­¦ç¿’ã«ä½¿ç”¨ã™ã‚‹ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™ã—ã¾ã™ã€‚

**data/iris.csv** ã®ã‚µãƒ³ãƒ—ãƒ«ï¼ˆå®Ÿéš›ã¯150è¡Œï¼‰ï¼š

```csv
sepal_length,sepal_width,petal_length,petal_width,species
5.1,3.5,1.4,0.2,setosa
4.9,3.0,1.4,0.2,setosa
7.0,3.2,4.7,1.4,versicolor
6.4,3.2,4.5,1.5,versicolor
6.3,3.3,6.0,2.5,virginica
5.8,2.7,5.1,1.9,virginica
```

ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ãƒ†ã‚¹ãƒˆï¼š

```python
def test_Irisãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®èª­ã¿è¾¼ã¿():
    """Iris ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’æ­£ã—ãèª­ã¿è¾¼ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª"""
    loader = DataLoader()
    df = loader.load_csv('data/iris.csv')

    # åˆ—åã®ç¢ºèª
    expected_columns = ['sepal_length', 'sepal_width', 'petal_length',
                       'petal_width', 'species']
    assert list(df.columns) == expected_columns

    # ãƒ‡ãƒ¼ã‚¿å‹ã®ç¢ºèª
    assert df['sepal_length'].dtype == 'float64'
    assert df['species'].dtype == 'object'

    # ç¨®é¡ã®ç¢ºèª
    species = df['species'].unique()
    assert len(species) == 3
    assert 'setosa' in species
    assert 'versicolor' in species
    assert 'virginica' in species
```

### 3ç«  æ©Ÿæ¢°å­¦ç¿’ã®åŸºç¤ç†è«–ï¼ˆè£œè¶³ï¼‰

#### æ©Ÿæ¢°å­¦ç¿’ã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼

å®Ÿéš›ã®æ©Ÿæ¢°å­¦ç¿’ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¯ä»¥ä¸‹ã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã§é€²ã‚ã¾ã™ï¼š

```plantuml
@startuml
start
:1. ãƒ‡ãƒ¼ã‚¿åé›†;
:2. ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†;
note right
  - æ¬ æå€¤å‡¦ç†
  - å¤–ã‚Œå€¤å‡¦ç†
  - ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°
end note
:3. ãƒ‡ãƒ¼ã‚¿åˆ†å‰²;
note right
  - è¨“ç·´ãƒ‡ãƒ¼ã‚¿
  - ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿
  - (æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿)
end note
:4. ãƒ¢ãƒ‡ãƒ«é¸æŠ;
:5. ãƒ¢ãƒ‡ãƒ«è¨“ç·´;
:6. ãƒ¢ãƒ‡ãƒ«è©•ä¾¡;
if (æ€§èƒ½ã¯ååˆ†ï¼Ÿ) then (yes)
  :7. ãƒ¢ãƒ‡ãƒ«ä¿å­˜;
  :8. æœ¬ç•ªãƒ‡ãƒ—ãƒ­ã‚¤;
  stop
else (no)
  :ãƒã‚¤ãƒ‘ãƒ¼ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿èª¿æ•´;
  note right
    - max_depth
    - learning_rate
    - regularization
  end note
endif
@enduml
```

#### åˆ†é¡å•é¡Œã¨å›å¸°å•é¡Œã®é•ã„

**åˆ†é¡å•é¡Œï¼ˆClassificationï¼‰**:
- **ç›®çš„**: ã‚«ãƒ†ã‚´ãƒªï¼ˆã‚¯ãƒ©ã‚¹ï¼‰ã‚’äºˆæ¸¬
- **å‡ºåŠ›**: é›¢æ•£å€¤ï¼ˆä¾‹: setosa, versicolor, virginicaï¼‰
- **è©•ä¾¡æŒ‡æ¨™**: æ­£è§£ç‡ã€é©åˆç‡ã€å†ç¾ç‡ã€F1ã‚¹ã‚³ã‚¢
- **ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ä¾‹**: æ±ºå®šæœ¨ã€ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°ã€SVM

**å›å¸°å•é¡Œï¼ˆRegressionï¼‰**:
- **ç›®çš„**: é€£ç¶šå€¤ã‚’äºˆæ¸¬
- **å‡ºåŠ›**: æ•°å€¤ï¼ˆä¾‹: èˆˆè¡Œåå…¥ 10000ä¸‡å††ï¼‰
- **è©•ä¾¡æŒ‡æ¨™**: å¹³å‡çµ¶å¯¾èª¤å·®ï¼ˆMAEï¼‰ã€å¹³å‡äºŒä¹—èª¤å·®ï¼ˆMSEï¼‰ã€æ±ºå®šä¿‚æ•°ï¼ˆRÂ²ï¼‰
- **ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ä¾‹**: ç·šå½¢å›å¸°ã€ãƒªãƒƒã‚¸å›å¸°ã€ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚©ãƒ¬ã‚¹ãƒˆ

#### ãƒ¢ãƒ‡ãƒ«è©•ä¾¡ã®é‡è¦æ€§

æ©Ÿæ¢°å­¦ç¿’ã§ã¯ã€è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã§å­¦ç¿’ã—ãŸãƒ¢ãƒ‡ãƒ«ãŒ**æœªçŸ¥ã®ãƒ‡ãƒ¼ã‚¿**ã«å¯¾ã—ã¦ã©ã‚Œã ã‘æ€§èƒ½ã‚’ç™ºæ®ã§ãã‚‹ã‹ãŒé‡è¦ã§ã™ã€‚

**éå­¦ç¿’ï¼ˆOverfittingï¼‰ã®å•é¡Œ**:

```python
def test_éå­¦ç¿’ã®æ¤œå‡º():
    """è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã¨ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®æ€§èƒ½å·®ã§éå­¦ç¿’ã‚’æ¤œå‡º"""
    from sklearn.tree import DecisionTreeClassifier
    from sklearn.model_selection import train_test_split

    # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿
    X = [[i, i*2] for i in range(100)]
    y = [0 if i < 50 else 1 for i in range(100)]

    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.3, random_state=0
    )

    # æ·±ã™ãã‚‹æ±ºå®šæœ¨ï¼ˆéå­¦ç¿’ã—ã‚„ã™ã„ï¼‰
    model_overfit = DecisionTreeClassifier(max_depth=50)
    model_overfit.fit(X_train, y_train)

    # é©åˆ‡ãªæ·±ã•ã®æ±ºå®šæœ¨
    model_good = DecisionTreeClassifier(max_depth=3)
    model_good.fit(X_train, y_train)

    # è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã§ã®æ€§èƒ½
    train_score_overfit = model_overfit.score(X_train, y_train)
    train_score_good = model_good.score(X_train, y_train)

    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§ã®æ€§èƒ½
    test_score_overfit = model_overfit.score(X_test, y_test)
    test_score_good = model_good.score(X_test, y_test)

    # éå­¦ç¿’ã®æ¤œå‡º: è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã¨ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§å¤§ããªæ€§èƒ½å·®
    overfit_gap = train_score_overfit - test_score_overfit
    good_gap = train_score_good - test_score_good

    assert overfit_gap > good_gap  # éå­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®æ–¹ãŒæ€§èƒ½å·®ãŒå¤§ãã„
```

### ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ 1 ã®æŠ€è¡“çš„æˆæœ

#### å®Œæˆã—ãŸæ©Ÿèƒ½

- âœ… ç¾ä»£çš„ Python é–‹ç™ºç’°å¢ƒã®ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
- âœ… ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ ã®ç¢ºç«‹
- âœ… åŸºæœ¬çš„ãªãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆã®ä½œæˆ
- âœ… TDD ã‚µã‚¤ã‚¯ãƒ«ã®å®Ÿè·µï¼ˆRed-Green-Refactorï¼‰
- âœ… ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ã®å®Ÿè£…
- âœ… å“è³ªç®¡ç†ãƒ„ãƒ¼ãƒ«ã®è¨­å®šã¨ç¢ºèª

#### å®šé‡çš„æˆæœ

| æŒ‡æ¨™ | å®Ÿç¸¾ |
|------|------|
| **ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹** | 12å€‹ |
| **ã‚³ãƒ¼ãƒ‰ã‚«ãƒãƒ¬ãƒƒã‚¸** | 100%ï¼ˆdata_loader.pyï¼‰ |
| **å‹ãƒ’ãƒ³ãƒˆä½¿ç”¨ç‡** | 100% |
| **Ruff ãƒã‚§ãƒƒã‚¯** | å…¨ã¦é€šé |
| **mypy ãƒã‚§ãƒƒã‚¯** | ã‚¨ãƒ©ãƒ¼ 0ä»¶ |

#### ç¿’å¾—ã—ãŸã‚¹ã‚­ãƒ«

**1. é–‹ç™ºç’°å¢ƒã‚¹ã‚­ãƒ«**
- uv ã«ã‚ˆã‚‹é«˜é€Ÿãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ç®¡ç†
- Ruff ã«ã‚ˆã‚‹çµ±åˆå“è³ªç®¡ç†
- mypy ã«ã‚ˆã‚‹å‹å®‰å…¨æ€§ç¢ºä¿
- pytest ã«ã‚ˆã‚‹è‡ªå‹•ãƒ†ã‚¹ãƒˆ

**2. TDD ã‚¹ã‚­ãƒ«**
- Red-Green-Refactor ã‚µã‚¤ã‚¯ãƒ«ã®å®Ÿè·µ
- ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ãƒ¼ã‚¹ãƒˆé–‹ç™ºã®ç¿’æ…£åŒ–
- ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ã‚’è€ƒæ…®ã—ãŸãƒ†ã‚¹ãƒˆè¨­è¨ˆ

**3. Python ã‚¹ã‚­ãƒ«**
- å‹ãƒ’ãƒ³ãƒˆã®æ´»ç”¨
- ä¾‹å¤–å‡¦ç†ã®å®Ÿè£…
- ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«æ§‹é€ ã®è¨­è¨ˆ

**4. æ©Ÿæ¢°å­¦ç¿’åŸºç¤çŸ¥è­˜**
- åˆ†é¡å•é¡Œã¨å›å¸°å•é¡Œã®ç†è§£
- ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ã®é‡è¦æ€§èªè­˜
- ãƒ¢ãƒ‡ãƒ«è©•ä¾¡ã®å¿…è¦æ€§ç†è§£

#### æ¬¡ã®ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã¸ã®æº–å‚™

ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ 2 ã§ã¯ã€ä»¥ä¸‹ã‚’å®Ÿè£…ã—ã¾ã™ï¼š

- Iris åˆ†é¡ãƒ¢ãƒ‡ãƒ«ã®å®Œå…¨å®Ÿè£…
- æ±ºå®šæœ¨ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®ç†è§£
- ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®æ§‹ç¯‰
- ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜ã¨èª­ã¿è¾¼ã¿

---

## ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ 2: åˆ†é¡å•é¡Œã®åŸºç¤

### 4ç«  Iris åˆ†é¡ãƒ¢ãƒ‡ãƒ«

#### å­¦ç¿’ç›®æ¨™

- åŸºæœ¬çš„ãªåˆ†é¡ãƒ¢ãƒ‡ãƒ«ã®æ§‹ç¯‰
- ãƒ†ã‚¹ãƒˆé§†å‹•é–‹ç™ºã®åŸºç¤ç¿’å¾—
- scikit-learn ã®åŸºæœ¬ API ç†è§£
- ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®æ§‹ç¯‰

#### Iris ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ç†è§£

Iris ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯ã€æ©Ÿæ¢°å­¦ç¿’ã®å…¥é–€ã«æœ€é©ãªæœ‰åãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã™ã€‚

**ãƒ‡ãƒ¼ã‚¿ã®ç‰¹å¾´**ï¼š
- **ã‚µãƒ³ãƒ—ãƒ«æ•°**: 150ä»¶ï¼ˆå„ç¨®é¡50ä»¶ãšã¤ï¼‰
- **ç‰¹å¾´é‡æ•°**: 4ã¤ï¼ˆå…¨ã¦é€£ç¶šå€¤ï¼‰
- **ã‚¯ãƒ©ã‚¹æ•°**: 3ã¤ï¼ˆsetosaã€versicolorã€virginicaï¼‰
- **æ¬ æå€¤**: ãªã—ï¼ˆã‚¯ãƒªãƒ¼ãƒ³ãªãƒ‡ãƒ¼ã‚¿ï¼‰

**ãƒ‡ãƒ¼ã‚¿è©³ç´°**ï¼š

| åˆ—å | å†…å®¹ | å˜ä½ | å€¤ã®ç¯„å›² |
| --- | --- | --- | --- |
| sepal_length | ãŒãç‰‡ã®é•·ã• | cm | 4.3 - 7.9 |
| sepal_width | ãŒãç‰‡ã®å¹… | cm | 2.0 - 4.4 |
| petal_length | èŠ±å¼ã®é•·ã• | cm | 1.0 - 6.9 |
| petal_width | èŠ±å¼ã®å¹… | cm | 0.1 - 2.5 |
| species | ç¨®é¡ | - | setosa, versicolor, virginica |

#### TDD ã«ã‚ˆã‚‹æ®µéšçš„å®Ÿè£…

##### ã‚¹ãƒ†ãƒƒãƒ— 1: ã‚¯ãƒ©ã‚¹ã®åˆæœŸåŒ–ãƒ†ã‚¹ãƒˆ

**Red: ãƒ†ã‚¹ãƒˆã‚’æ›¸ã**

**test/test_iris_classifier.py**:

```python
"""Iris åˆ†é¡å™¨ã®ãƒ†ã‚¹ãƒˆ"""
import pytest
import pandas as pd
import numpy as np
from src.ml.iris_classifier import IrisClassifier


class TestIrisClassifierInit:
    """IrisClassifier ã®åˆæœŸåŒ–ãƒ†ã‚¹ãƒˆ"""

    def test_ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ã®åˆæœŸåŒ–(self):
        """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§åˆæœŸåŒ–ã§ãã‚‹ã“ã¨ã‚’ç¢ºèª"""
        classifier = IrisClassifier()

        assert classifier is not None
        assert classifier.model is None
        assert classifier.max_depth == 2

    def test_ã‚«ã‚¹ã‚¿ãƒ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ã®åˆæœŸåŒ–(self):
        """ã‚«ã‚¹ã‚¿ãƒ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§åˆæœŸåŒ–ã§ãã‚‹ã“ã¨ã‚’ç¢ºèª"""
        classifier = IrisClassifier(max_depth=5)

        assert classifier.max_depth == 5

    def test_ç„¡åŠ¹ãªmax_depthã®æ‹’å¦(self):
        """ç„¡åŠ¹ãª max_depth ã‚’æ‹’å¦ã™ã‚‹ã“ã¨ã‚’ç¢ºèª"""
        with pytest.raises(ValueError):
            IrisClassifier(max_depth=-1)

        with pytest.raises(ValueError):
            IrisClassifier(max_depth=0)
```

ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œï¼ˆRedï¼‰ï¼š

```bash
uv run pytest test/test_iris_classifier.py::TestIrisClassifierInit -v

# å‡ºåŠ›ä¾‹ï¼š
# ModuleNotFoundError: No module named 'src.ml.iris_classifier'
```

**Green: æœ€å°é™ã®å®Ÿè£…**

**src/ml/iris_classifier.py**:

```python
"""Iris åˆ†é¡å™¨ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«"""
from typing import Optional, Tuple
import pandas as pd
import numpy as np
from sklearn import tree
from sklearn.model_selection import train_test_split


class IrisClassifier:
    """Iris ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’åˆ†é¡ã™ã‚‹æ±ºå®šæœ¨ãƒ¢ãƒ‡ãƒ«"""

    def __init__(self, max_depth: int = 2) -> None:
        """åˆæœŸåŒ–

        Args:
            max_depth: æ±ºå®šæœ¨ã®æœ€å¤§æ·±ã•ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 2ï¼‰

        Raises:
            ValueError: max_depth ãŒ 1 æœªæº€ã®å ´åˆ
        """
        if max_depth < 1:
            raise ValueError("max_depth must be at least 1")

        self.max_depth = max_depth
        self.model: Optional[tree.DecisionTreeClassifier] = None
```

ãƒ†ã‚¹ãƒˆã‚’å®Ÿè¡Œï¼ˆGreenï¼‰ï¼š

```bash
uv run pytest test/test_iris_classifier.py::TestIrisClassifierInit -v

# å‡ºåŠ›ä¾‹ï¼š
# test/test_iris_classifier.py::TestIrisClassifierInit::test_ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ã®åˆæœŸåŒ– PASSED
# test/test_iris_classifier.py::TestIrisClassifierInit::test_ã‚«ã‚¹ã‚¿ãƒ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ã®åˆæœŸåŒ– PASSED
# test/test_iris_classifier.py::TestIrisClassifierInit::test_ç„¡åŠ¹ãªmax_depthã®æ‹’å¦ PASSED
# =========== 3 passed in 0.18s ===========
```

##### ã‚¹ãƒ†ãƒƒãƒ— 2: ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã¨å‰å‡¦ç†

**Red: ãƒ†ã‚¹ãƒˆã‚’æ›¸ã**

```python
class TestIrisClassifierDataLoading:
    """ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã®ãƒ†ã‚¹ãƒˆ"""

    def test_CSVãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã®ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿(self):
        """CSV ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª"""
        classifier = IrisClassifier()
        X, y = classifier.load_data('data/iris.csv')

        assert X is not None
        assert y is not None
        assert isinstance(X, pd.DataFrame)
        assert isinstance(y, pd.Series)

    def test_ç‰¹å¾´é‡ã®åˆ—æ•°ç¢ºèª(self):
        """ç‰¹å¾´é‡ãŒ 4 åˆ—ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª"""
        classifier = IrisClassifier()
        X, y = classifier.load_data('data/iris.csv')

        assert X.shape[1] == 4
        assert list(X.columns) == [
            'sepal_length', 'sepal_width', 'petal_length', 'petal_width'
        ]

    def test_ãƒ©ãƒ™ãƒ«ã®ãƒ¦ãƒ‹ãƒ¼ã‚¯æ•°ç¢ºèª(self):
        """ãƒ©ãƒ™ãƒ«ãŒ 3 ç¨®é¡ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª"""
        classifier = IrisClassifier()
        X, y = classifier.load_data('data/iris.csv')

        unique_species = y.unique()
        assert len(unique_species) == 3
        assert 'setosa' in unique_species
        assert 'versicolor' in unique_species
        assert 'virginica' in unique_species

    def test_æ¬ æå€¤ã®å‡¦ç†(self):
        """æ¬ æå€¤ãŒé©åˆ‡ã«å‡¦ç†ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª"""
        # ãƒ†ã‚¹ãƒˆç”¨ã«æ¬ æå€¤ã‚’å«ã‚€ãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
        import tempfile
        import os

        test_data = """sepal_length,sepal_width,petal_length,petal_width,species
5.1,3.5,1.4,0.2,setosa
,3.0,1.4,0.2,setosa
7.0,,4.7,1.4,versicolor"""

        with tempfile.NamedTemporaryFile(mode='w', delete=False, suffix='.csv') as f:
            f.write(test_data)
            temp_path = f.name

        try:
            classifier = IrisClassifier()
            X, y = classifier.load_data(temp_path)

            # æ¬ æå€¤ãŒè£œå®Œã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª
            assert X.isnull().sum().sum() == 0
        finally:
            os.unlink(temp_path)
```

**Green: ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿æ©Ÿèƒ½ã®å®Ÿè£…**

```python
def load_data(self, file_path: str) -> Tuple[pd.DataFrame, pd.Series]:
    """CSV ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€

    Args:
        file_path: CSV ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹

    Returns:
        ç‰¹å¾´é‡ DataFrame ã¨æ­£è§£ãƒ©ãƒ™ãƒ« Series ã®ã‚¿ãƒ—ãƒ«

    Raises:
        FileNotFoundError: ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆ
        ValueError: ãƒ‡ãƒ¼ã‚¿ã®å½¢å¼ãŒä¸æ­£ãªå ´åˆ
    """
    # ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª
    import os
    if not os.path.exists(file_path):
        raise FileNotFoundError(f"File not found: {file_path}")

    # ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
    df = pd.read_csv(file_path)

    # å¿…è¦ãªåˆ—ã®å­˜åœ¨ç¢ºèª
    required_columns = ['sepal_length', 'sepal_width',
                       'petal_length', 'petal_width', 'species']
    missing_columns = set(required_columns) - set(df.columns)
    if missing_columns:
        raise ValueError(f"Missing columns: {missing_columns}")

    # ç‰¹å¾´é‡åˆ—
    feature_columns = ['sepal_length', 'sepal_width',
                      'petal_length', 'petal_width']

    # æ¬ æå€¤ã‚’å¹³å‡å€¤ã§è£œå®Œ
    for col in feature_columns:
        if df[col].isnull().any():
            mean_value = df[col].mean()
            df[col] = df[col].fillna(mean_value)

    # ç‰¹å¾´é‡ã¨æ­£è§£ãƒ©ãƒ™ãƒ«ã®åˆ†å‰²
    X = df[feature_columns]
    y = df['species']

    return X, y
```

**Refactor: ãƒ˜ãƒ«ãƒ‘ãƒ¼ãƒ¡ã‚½ãƒƒãƒ‰ã®æŠ½å‡º**

```python
def _validate_dataframe(self, df: pd.DataFrame) -> None:
    """ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®å¦¥å½“æ€§ã‚’æ¤œè¨¼

    Args:
        df: æ¤œè¨¼ã™ã‚‹ DataFrame

    Raises:
        ValueError: å¿…è¦ãªåˆ—ãŒä¸è¶³ã—ã¦ã„ã‚‹å ´åˆ
    """
    required_columns = ['sepal_length', 'sepal_width',
                       'petal_length', 'petal_width', 'species']
    missing_columns = set(required_columns) - set(df.columns)
    if missing_columns:
        raise ValueError(f"Missing columns: {missing_columns}")


def _fill_missing_values(self, df: pd.DataFrame,
                        columns: list) -> pd.DataFrame:
    """æ¬ æå€¤ã‚’å¹³å‡å€¤ã§è£œå®Œ

    Args:
        df: å¯¾è±¡ã® DataFrame
        columns: è£œå®Œã™ã‚‹åˆ—ã®ãƒªã‚¹ãƒˆ

    Returns:
        è£œå®Œå¾Œã® DataFrame
    """
    df_filled = df.copy()
    for col in columns:
        if df_filled[col].isnull().any():
            mean_value = df_filled[col].mean()
            df_filled[col] = df_filled[col].fillna(mean_value)
    return df_filled


def load_data(self, file_path: str) -> Tuple[pd.DataFrame, pd.Series]:
    """CSV ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€ï¼ˆãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°å¾Œï¼‰"""
    import os
    if not os.path.exists(file_path):
        raise FileNotFoundError(f"File not found: {file_path}")

    df = pd.read_csv(file_path)
    self._validate_dataframe(df)

    feature_columns = ['sepal_length', 'sepal_width',
                      'petal_length', 'petal_width']

    df = self._fill_missing_values(df, feature_columns)

    X = df[feature_columns]
    y = df['species']

    return X, y
```

##### ã‚¹ãƒ†ãƒƒãƒ— 3: ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´

**Red: ãƒ†ã‚¹ãƒˆã‚’æ›¸ã**

```python
class TestIrisClassifierTraining:
    """ãƒ¢ãƒ‡ãƒ«è¨“ç·´ã®ãƒ†ã‚¹ãƒˆ"""

    def test_ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´(self):
        """ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã§ãã‚‹ã“ã¨ã‚’ç¢ºèª"""
        classifier = IrisClassifier()
        X_train = pd.DataFrame({
            'sepal_length': [5.1, 4.9, 7.0],
            'sepal_width': [3.5, 3.0, 3.2],
            'petal_length': [1.4, 1.4, 4.7],
            'petal_width': [0.2, 0.2, 1.4]
        })
        y_train = pd.Series(['setosa', 'setosa', 'versicolor'])

        classifier.train(X_train, y_train)

        assert classifier.model is not None

    def test_è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®å±æ€§ç¢ºèª(self):
        """è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ãŒé©åˆ‡ãªå±æ€§ã‚’æŒã¤ã“ã¨ã‚’ç¢ºèª"""
        classifier = IrisClassifier(max_depth=3)
        X_train = pd.DataFrame({
            'sepal_length': [5.1, 4.9, 7.0],
            'sepal_width': [3.5, 3.0, 3.2],
            'petal_length': [1.4, 1.4, 4.7],
            'petal_width': [0.2, 0.2, 1.4]
        })
        y_train = pd.Series(['setosa', 'setosa', 'versicolor'])

        classifier.train(X_train, y_train)

        assert classifier.model.max_depth == 3
        assert hasattr(classifier.model, 'classes_')

    def test_ç©ºã®ãƒ‡ãƒ¼ã‚¿ã§ã®è¨“ç·´æ‹’å¦(self):
        """ç©ºã®ãƒ‡ãƒ¼ã‚¿ã§ã®è¨“ç·´ã‚’æ‹’å¦ã™ã‚‹ã“ã¨ã‚’ç¢ºèª"""
        classifier = IrisClassifier()
        X_train = pd.DataFrame()
        y_train = pd.Series(dtype=str)

        with pytest.raises(ValueError):
            classifier.train(X_train, y_train)

    def test_ç‰¹å¾´é‡ã¨ãƒ©ãƒ™ãƒ«ã®æ•°ãŒä¸ä¸€è‡´ã®æ‹’å¦(self):
        """ç‰¹å¾´é‡ã¨ãƒ©ãƒ™ãƒ«ã®æ•°ãŒä¸€è‡´ã—ãªã„å ´åˆã‚’æ‹’å¦"""
        classifier = IrisClassifier()
        X_train = pd.DataFrame({
            'sepal_length': [5.1, 4.9],
            'sepal_width': [3.5, 3.0],
            'petal_length': [1.4, 1.4],
            'petal_width': [0.2, 0.2]
        })
        y_train = pd.Series(['setosa'])  # æ•°ãŒä¸€è‡´ã—ãªã„

        with pytest.raises(ValueError):
            classifier.train(X_train, y_train)
```

**Green: è¨“ç·´æ©Ÿèƒ½ã®å®Ÿè£…**

```python
def train(self, X_train: pd.DataFrame, y_train: pd.Series) -> None:
    """ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã™ã‚‹

    Args:
        X_train: è¨“ç·´ç”¨ç‰¹å¾´é‡
        y_train: è¨“ç·´ç”¨æ­£è§£ãƒ©ãƒ™ãƒ«

    Raises:
        ValueError: ãƒ‡ãƒ¼ã‚¿ãŒç©ºã€ã¾ãŸã¯ç‰¹å¾´é‡ã¨ãƒ©ãƒ™ãƒ«ã®æ•°ãŒä¸ä¸€è‡´ã®å ´åˆ
    """
    # ãƒ‡ãƒ¼ã‚¿ã®å¦¥å½“æ€§ãƒã‚§ãƒƒã‚¯
    if len(X_train) == 0 or len(y_train) == 0:
        raise ValueError("Training data cannot be empty")

    if len(X_train) != len(y_train):
        raise ValueError(
            f"X_train and y_train must have the same length: "
            f"{len(X_train)} != {len(y_train)}"
        )

    # æ±ºå®šæœ¨ãƒ¢ãƒ‡ãƒ«ã®ä½œæˆ
    self.model = tree.DecisionTreeClassifier(
        max_depth=self.max_depth,
        random_state=0  # å†ç¾æ€§ã®ãŸã‚
    )

    # ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´
    self.model.fit(X_train, y_train)
```

##### ã‚¹ãƒ†ãƒƒãƒ— 4: äºˆæ¸¬æ©Ÿèƒ½

**Red: ãƒ†ã‚¹ãƒˆã‚’æ›¸ã**

```python
class TestIrisClassifierPrediction:
    """äºˆæ¸¬æ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆ"""

    @pytest.fixture
    def trained_classifier(self):
        """è¨“ç·´æ¸ˆã¿ã®åˆ†é¡å™¨ã‚’è¿”ã™ fixture"""
        classifier = IrisClassifier()
        X_train = pd.DataFrame({
            'sepal_length': [5.1, 4.9, 7.0, 6.4],
            'sepal_width': [3.5, 3.0, 3.2, 3.2],
            'petal_length': [1.4, 1.4, 4.7, 4.5],
            'petal_width': [0.2, 0.2, 1.4, 1.5]
        })
        y_train = pd.Series(['setosa', 'setosa', 'versicolor', 'versicolor'])
        classifier.train(X_train, y_train)
        return classifier

    def test_å˜ä¸€ã‚µãƒ³ãƒ—ãƒ«ã®äºˆæ¸¬(self, trained_classifier):
        """å˜ä¸€ã‚µãƒ³ãƒ—ãƒ«ã‚’äºˆæ¸¬ã§ãã‚‹ã“ã¨ã‚’ç¢ºèª"""
        X_test = pd.DataFrame({
            'sepal_length': [5.0],
            'sepal_width': [3.5],
            'petal_length': [1.3],
            'petal_width': [0.3]
        })

        predictions = trained_classifier.predict(X_test)

        assert len(predictions) == 1
        assert predictions[0] in ['setosa', 'versicolor', 'virginica']

    def test_è¤‡æ•°ã‚µãƒ³ãƒ—ãƒ«ã®äºˆæ¸¬(self, trained_classifier):
        """è¤‡æ•°ã‚µãƒ³ãƒ—ãƒ«ã‚’äºˆæ¸¬ã§ãã‚‹ã“ã¨ã‚’ç¢ºèª"""
        X_test = pd.DataFrame({
            'sepal_length': [5.0, 7.0],
            'sepal_width': [3.5, 3.2],
            'petal_length': [1.3, 4.7],
            'petal_width': [0.3, 1.4]
        })

        predictions = trained_classifier.predict(X_test)

        assert len(predictions) == 2

    def test_æœªè¨“ç·´ãƒ¢ãƒ‡ãƒ«ã§ã®äºˆæ¸¬æ‹’å¦(self):
        """æœªè¨“ç·´ãƒ¢ãƒ‡ãƒ«ã§ã®äºˆæ¸¬ã‚’æ‹’å¦ã™ã‚‹ã“ã¨ã‚’ç¢ºèª"""
        classifier = IrisClassifier()
        X_test = pd.DataFrame({
            'sepal_length': [5.0],
            'sepal_width': [3.5],
            'petal_length': [1.3],
            'petal_width': [0.3]
        })

        with pytest.raises(ValueError):
            classifier.predict(X_test)
```

**Green: äºˆæ¸¬æ©Ÿèƒ½ã®å®Ÿè£…**

```python
def predict(self, X_test: pd.DataFrame) -> np.ndarray:
    """äºˆæ¸¬ã‚’å®Ÿè¡Œã™ã‚‹

    Args:
        X_test: ãƒ†ã‚¹ãƒˆç”¨ç‰¹å¾´é‡

    Returns:
        äºˆæ¸¬ã•ã‚ŒãŸã‚¯ãƒ©ã‚¹ãƒ©ãƒ™ãƒ«ã®é…åˆ—

    Raises:
        ValueError: ãƒ¢ãƒ‡ãƒ«ãŒæœªè¨“ç·´ã®å ´åˆ
    """
    if self.model is None:
        raise ValueError("Model has not been trained yet")

    return self.model.predict(X_test)
```

##### ã‚¹ãƒ†ãƒƒãƒ— 5: ãƒ¢ãƒ‡ãƒ«è©•ä¾¡

**Red: ãƒ†ã‚¹ãƒˆã‚’æ›¸ã**

```python
class TestIrisClassifierEvaluation:
    """ãƒ¢ãƒ‡ãƒ«è©•ä¾¡ã®ãƒ†ã‚¹ãƒˆ"""

    @pytest.fixture
    def trained_classifier(self):
        """è¨“ç·´æ¸ˆã¿ã®åˆ†é¡å™¨"""
        classifier = IrisClassifier()
        classifier.load_data('data/iris.csv')
        X, y = classifier.load_data('data/iris.csv')
        classifier.train(X, y)
        return classifier

    def test_æ­£è§£ç‡ã®è¨ˆç®—(self, trained_classifier):
        """æ­£è§£ç‡ã‚’è¨ˆç®—ã§ãã‚‹ã“ã¨ã‚’ç¢ºèª"""
        X_test = pd.DataFrame({
            'sepal_length': [5.1, 7.0],
            'sepal_width': [3.5, 3.2],
            'petal_length': [1.4, 4.7],
            'petal_width': [0.2, 1.4]
        })
        y_test = pd.Series(['setosa', 'versicolor'])

        accuracy = trained_classifier.evaluate(X_test, y_test)

        assert 0.0 <= accuracy <= 1.0

    def test_å®Œå…¨ä¸€è‡´æ™‚ã®æ­£è§£ç‡(self):
        """å…¨ã¦æ­£è§£ã®å ´åˆã«æ­£è§£ç‡ãŒ 1.0 ã«ãªã‚‹ã“ã¨ã‚’ç¢ºèª"""
        classifier = IrisClassifier()
        X_train = pd.DataFrame({
            'sepal_length': [5.1, 7.0],
            'sepal_width': [3.5, 3.2],
            'petal_length': [1.4, 4.7],
            'petal_width': [0.2, 1.4]
        })
        y_train = pd.Series(['setosa', 'versicolor'])
        classifier.train(X_train, y_train)

        # è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã¨åŒã˜ãƒ‡ãƒ¼ã‚¿ã§ãƒ†ã‚¹ãƒˆï¼ˆå¿…ãšæ­£è§£ï¼‰
        accuracy = classifier.evaluate(X_train, y_train)

        assert accuracy == 1.0
```

**Green: è©•ä¾¡æ©Ÿèƒ½ã®å®Ÿè£…**

```python
def evaluate(self, X_test: pd.DataFrame, y_test: pd.Series) -> float:
    """ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã‚’è©•ä¾¡ã™ã‚‹

    Args:
        X_test: ãƒ†ã‚¹ãƒˆç”¨ç‰¹å¾´é‡
        y_test: ãƒ†ã‚¹ãƒˆç”¨æ­£è§£ãƒ©ãƒ™ãƒ«

    Returns:
        æ­£è§£ç‡ï¼ˆ0.0 ã€œ 1.0ï¼‰

    Raises:
        ValueError: ãƒ¢ãƒ‡ãƒ«ãŒæœªè¨“ç·´ã®å ´åˆ
    """
    if self.model is None:
        raise ValueError("Model has not been trained yet")

    return self.model.score(X_test, y_test)
```

##### ã‚¹ãƒ†ãƒƒãƒ— 6: ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜ã¨èª­ã¿è¾¼ã¿

**Red: ãƒ†ã‚¹ãƒˆã‚’æ›¸ã**

```python
class TestIrisClassifierPersistence:
    """ãƒ¢ãƒ‡ãƒ«ã®æ°¸ç¶šåŒ–ãƒ†ã‚¹ãƒˆ"""

    def test_ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜(self, trained_classifier, tmp_path):
        """è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜ã§ãã‚‹ã“ã¨ã‚’ç¢ºèª"""
        model_path = tmp_path / "iris_model.pkl"

        trained_classifier.save_model(str(model_path))

        assert model_path.exists()

    def test_ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿(self, tmp_path):
        """ä¿å­˜ã—ãŸãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª"""
        # ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã—ã¦ä¿å­˜
        classifier1 = IrisClassifier()
        X_train = pd.DataFrame({
            'sepal_length': [5.1, 7.0],
            'sepal_width': [3.5, 3.2],
            'petal_length': [1.4, 4.7],
            'petal_width': [0.2, 1.4]
        })
        y_train = pd.Series(['setosa', 'versicolor'])
        classifier1.train(X_train, y_train)

        model_path = tmp_path / "iris_model.pkl"
        classifier1.save_model(str(model_path))

        # æ–°ã—ã„ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã§ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿
        classifier2 = IrisClassifier()
        classifier2.load_model(str(model_path))

        assert classifier2.model is not None

    def test_ä¿å­˜ã—ãŸãƒ¢ãƒ‡ãƒ«ã§ã®äºˆæ¸¬ä¸€è²«æ€§(self, tmp_path):
        """ä¿å­˜å‰å¾Œã§äºˆæ¸¬çµæœãŒä¸€è‡´ã™ã‚‹ã“ã¨ã‚’ç¢ºèª"""
        # ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´
        classifier1 = IrisClassifier()
        X_train = pd.DataFrame({
            'sepal_length': [5.1, 7.0],
            'sepal_width': [3.5, 3.2],
            'petal_length': [1.4, 4.7],
            'petal_width': [0.2, 1.4]
        })
        y_train = pd.Series(['setosa', 'versicolor'])
        classifier1.train(X_train, y_train)

        # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿
        X_test = pd.DataFrame({
            'sepal_length': [5.0],
            'sepal_width': [3.4],
            'petal_length': [1.5],
            'petal_width': [0.2]
        })

        # ä¿å­˜å‰ã®äºˆæ¸¬
        pred_before = classifier1.predict(X_test)

        # ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜ã¨èª­ã¿è¾¼ã¿
        model_path = tmp_path / "iris_model.pkl"
        classifier1.save_model(str(model_path))

        classifier2 = IrisClassifier()
        classifier2.load_model(str(model_path))

        # èª­ã¿è¾¼ã¿å¾Œã®äºˆæ¸¬
        pred_after = classifier2.predict(X_test)

        assert np.array_equal(pred_before, pred_after)
```

**Green: æ°¸ç¶šåŒ–æ©Ÿèƒ½ã®å®Ÿè£…**

```python
import pickle


def save_model(self, file_path: str) -> None:
    """è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã™ã‚‹

    Args:
        file_path: ä¿å­˜å…ˆã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹

    Raises:
        ValueError: ãƒ¢ãƒ‡ãƒ«ãŒæœªè¨“ç·´ã®å ´åˆ
    """
    if self.model is None:
        raise ValueError("No trained model to save")

    with open(file_path, 'wb') as f:
        pickle.dump(self.model, f)


def load_model(self, file_path: str) -> None:
    """ä¿å­˜ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã‚€

    Args:
        file_path: èª­ã¿è¾¼ã‚€ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹

    Raises:
        FileNotFoundError: ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆ
    """
    import os
    if not os.path.exists(file_path):
        raise FileNotFoundError(f"Model file not found: {file_path}")

    with open(file_path, 'rb') as f:
        self.model = pickle.load(f)
```

#### å®Œå…¨ãªå®Ÿè£…ä¾‹

ã™ã¹ã¦ã®æ©Ÿèƒ½ã‚’çµ±åˆã—ãŸå®Œå…¨ãª `IrisClassifier` ã‚¯ãƒ©ã‚¹ï¼š

**src/ml/iris_classifier.py**:

```python
"""Iris åˆ†é¡å™¨ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«"""
import os
import pickle
from typing import Optional, Tuple
import pandas as pd
import numpy as np
from sklearn import tree


class IrisClassifier:
    """Iris ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’åˆ†é¡ã™ã‚‹æ±ºå®šæœ¨ãƒ¢ãƒ‡ãƒ«

    Attributes:
        max_depth: æ±ºå®šæœ¨ã®æœ€å¤§æ·±ã•
        model: è¨“ç·´æ¸ˆã¿ã®æ±ºå®šæœ¨ãƒ¢ãƒ‡ãƒ«ï¼ˆæœªè¨“ç·´æ™‚ã¯ Noneï¼‰
    """

    def __init__(self, max_depth: int = 2) -> None:
        """åˆæœŸåŒ–

        Args:
            max_depth: æ±ºå®šæœ¨ã®æœ€å¤§æ·±ã•ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 2ï¼‰

        Raises:
            ValueError: max_depth ãŒ 1 æœªæº€ã®å ´åˆ
        """
        if max_depth < 1:
            raise ValueError("max_depth must be at least 1")

        self.max_depth = max_depth
        self.model: Optional[tree.DecisionTreeClassifier] = None

    def _validate_dataframe(self, df: pd.DataFrame) -> None:
        """ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ ã®å¦¥å½“æ€§ã‚’æ¤œè¨¼

        Args:
            df: æ¤œè¨¼ã™ã‚‹ DataFrame

        Raises:
            ValueError: å¿…è¦ãªåˆ—ãŒä¸è¶³ã—ã¦ã„ã‚‹å ´åˆ
        """
        required_columns = ['sepal_length', 'sepal_width',
                           'petal_length', 'petal_width', 'species']
        missing_columns = set(required_columns) - set(df.columns)
        if missing_columns:
            raise ValueError(f"Missing columns: {missing_columns}")

    def _fill_missing_values(self, df: pd.DataFrame,
                            columns: list) -> pd.DataFrame:
        """æ¬ æå€¤ã‚’å¹³å‡å€¤ã§è£œå®Œ

        Args:
            df: å¯¾è±¡ã® DataFrame
            columns: è£œå®Œã™ã‚‹åˆ—ã®ãƒªã‚¹ãƒˆ

        Returns:
            è£œå®Œå¾Œã® DataFrame
        """
        df_filled = df.copy()
        for col in columns:
            if df_filled[col].isnull().any():
                mean_value = df_filled[col].mean()
                df_filled[col] = df_filled[col].fillna(mean_value)
        return df_filled

    def load_data(self, file_path: str) -> Tuple[pd.DataFrame, pd.Series]:
        """CSV ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€

        Args:
            file_path: CSV ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹

        Returns:
            ç‰¹å¾´é‡ DataFrame ã¨æ­£è§£ãƒ©ãƒ™ãƒ« Series ã®ã‚¿ãƒ—ãƒ«

        Raises:
            FileNotFoundError: ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆ
            ValueError: ãƒ‡ãƒ¼ã‚¿ã®å½¢å¼ãŒä¸æ­£ãªå ´åˆ
        """
        if not os.path.exists(file_path):
            raise FileNotFoundError(f"File not found: {file_path}")

        df = pd.read_csv(file_path)
        self._validate_dataframe(df)

        feature_columns = ['sepal_length', 'sepal_width',
                          'petal_length', 'petal_width']

        df = self._fill_missing_values(df, feature_columns)

        X = df[feature_columns]
        y = df['species']

        return X, y

    def train(self, X_train: pd.DataFrame, y_train: pd.Series) -> None:
        """ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã™ã‚‹

        Args:
            X_train: è¨“ç·´ç”¨ç‰¹å¾´é‡
            y_train: è¨“ç·´ç”¨æ­£è§£ãƒ©ãƒ™ãƒ«

        Raises:
            ValueError: ãƒ‡ãƒ¼ã‚¿ãŒç©ºã€ã¾ãŸã¯ç‰¹å¾´é‡ã¨ãƒ©ãƒ™ãƒ«ã®æ•°ãŒä¸ä¸€è‡´ã®å ´åˆ
        """
        if len(X_train) == 0 or len(y_train) == 0:
            raise ValueError("Training data cannot be empty")

        if len(X_train) != len(y_train):
            raise ValueError(
                f"X_train and y_train must have the same length: "
                f"{len(X_train)} != {len(y_train)}"
            )

        self.model = tree.DecisionTreeClassifier(
            max_depth=self.max_depth,
            random_state=0
        )
        self.model.fit(X_train, y_train)

    def predict(self, X_test: pd.DataFrame) -> np.ndarray:
        """äºˆæ¸¬ã‚’å®Ÿè¡Œã™ã‚‹

        Args:
            X_test: ãƒ†ã‚¹ãƒˆç”¨ç‰¹å¾´é‡

        Returns:
            äºˆæ¸¬ã•ã‚ŒãŸã‚¯ãƒ©ã‚¹ãƒ©ãƒ™ãƒ«ã®é…åˆ—

        Raises:
            ValueError: ãƒ¢ãƒ‡ãƒ«ãŒæœªè¨“ç·´ã®å ´åˆ
        """
        if self.model is None:
            raise ValueError("Model has not been trained yet")

        return self.model.predict(X_test)

    def evaluate(self, X_test: pd.DataFrame, y_test: pd.Series) -> float:
        """ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã‚’è©•ä¾¡ã™ã‚‹

        Args:
            X_test: ãƒ†ã‚¹ãƒˆç”¨ç‰¹å¾´é‡
            y_test: ãƒ†ã‚¹ãƒˆç”¨æ­£è§£ãƒ©ãƒ™ãƒ«

        Returns:
            æ­£è§£ç‡ï¼ˆ0.0 ã€œ 1.0ï¼‰

        Raises:
            ValueError: ãƒ¢ãƒ‡ãƒ«ãŒæœªè¨“ç·´ã®å ´åˆ
        """
        if self.model is None:
            raise ValueError("Model has not been trained yet")

        return self.model.score(X_test, y_test)

    def save_model(self, file_path: str) -> None:
        """è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã™ã‚‹

        Args:
            file_path: ä¿å­˜å…ˆã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹

        Raises:
            ValueError: ãƒ¢ãƒ‡ãƒ«ãŒæœªè¨“ç·´ã®å ´åˆ
        """
        if self.model is None:
            raise ValueError("No trained model to save")

        with open(file_path, 'wb') as f:
            pickle.dump(self.model, f)

    def load_model(self, file_path: str) -> None:
        """ä¿å­˜ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã‚€

        Args:
            file_path: èª­ã¿è¾¼ã‚€ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹

        Raises:
            FileNotFoundError: ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆ
        """
        if not os.path.exists(file_path):
            raise FileNotFoundError(f"Model file not found: {file_path}")

        with open(file_path, 'rb') as f:
            self.model = pickle.load(f)
```

#### å®Ÿè·µä¾‹ï¼šIris åˆ†é¡ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´

å®Ÿéš›ã«ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã—ã¦è©•ä¾¡ã™ã‚‹å®Œå…¨ãªä¾‹ï¼š

**examples/train_iris.py**:

```python
"""Iris åˆ†é¡ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´ä¾‹"""
from sklearn.model_selection import train_test_split
from src.ml.iris_classifier import IrisClassifier


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    # åˆ†é¡å™¨ã®ä½œæˆ
    classifier = IrisClassifier(max_depth=3)
    print("IrisClassifier ã‚’ä½œæˆã—ã¾ã—ãŸ")

    # ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
    X, y = classifier.load_data('data/iris.csv')
    print(f"ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ: {len(X)} ã‚µãƒ³ãƒ—ãƒ«")

    # è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã¨ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã«åˆ†å‰²
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.3, random_state=0
    )
    print(f"è¨“ç·´ãƒ‡ãƒ¼ã‚¿: {len(X_train)} ã‚µãƒ³ãƒ—ãƒ«")
    print(f"ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: {len(X_test)} ã‚µãƒ³ãƒ—ãƒ«")

    # ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´
    classifier.train(X_train, y_train)
    print("ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´ãŒå®Œäº†ã—ã¾ã—ãŸ")

    # è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã§ã®è©•ä¾¡
    train_accuracy = classifier.evaluate(X_train, y_train)
    print(f"è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã§ã®æ­£è§£ç‡: {train_accuracy:.4f}")

    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§ã®è©•ä¾¡
    test_accuracy = classifier.evaluate(X_test, y_test)
    print(f"ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§ã®æ­£è§£ç‡: {test_accuracy:.4f}")

    # ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜
    classifier.save_model('model/iris.pkl')
    print("ãƒ¢ãƒ‡ãƒ«ã‚’ model/iris.pkl ã«ä¿å­˜ã—ã¾ã—ãŸ")

    # äºˆæ¸¬ä¾‹
    sample = X_test.iloc[:3]
    predictions = classifier.predict(sample)
    print("\näºˆæ¸¬ä¾‹:")
    for i, (idx, row) in enumerate(sample.iterrows()):
        print(f"ã‚µãƒ³ãƒ—ãƒ« {i+1}: {predictions[i]}")
        print(f"  - ãŒãç‰‡: é•·ã•={row['sepal_length']}, å¹…={row['sepal_width']}")
        print(f"  - èŠ±å¼: é•·ã•={row['petal_length']}, å¹…={row['petal_width']}")


if __name__ == '__main__':
    main()
```

å®Ÿè¡Œä¾‹ï¼š

```bash
uv run python examples/train_iris.py

# å‡ºåŠ›ä¾‹ï¼š
# IrisClassifier ã‚’ä½œæˆã—ã¾ã—ãŸ
# ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ: 150 ã‚µãƒ³ãƒ—ãƒ«
# è¨“ç·´ãƒ‡ãƒ¼ã‚¿: 105 ã‚µãƒ³ãƒ—ãƒ«
# ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: 45 ã‚µãƒ³ãƒ—ãƒ«
# ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´ãŒå®Œäº†ã—ã¾ã—ãŸ
# è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã§ã®æ­£è§£ç‡: 0.9810
# ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§ã®æ­£è§£ç‡: 0.9778
#
# äºˆæ¸¬ä¾‹:
# ã‚µãƒ³ãƒ—ãƒ« 1: versicolor
#   - ãŒãç‰‡: é•·ã•=6.1, å¹…=2.8
#   - èŠ±å¼: é•·ã•=4.7, å¹…=1.2
# ã‚µãƒ³ãƒ—ãƒ« 2: setosa
#   - ãŒãç‰‡: é•·ã•=5.7, å¹…=3.8
#   - èŠ±å¼: é•·ã•=1.7, å¹…=0.3
# ã‚µãƒ³ãƒ—ãƒ« 3: virginica
#   - ãŒãç‰‡: é•·ã•=7.7, å¹…=2.6
#   - èŠ±å¼: é•·ã•=6.9, å¹…=2.3
```

### ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ 2 ã®æŠ€è¡“çš„æˆæœ

#### å®Œæˆã—ãŸæ©Ÿèƒ½

- âœ… Iris åˆ†é¡å™¨ã‚¯ãƒ©ã‚¹ã®å®Œå…¨å®Ÿè£…
- âœ… ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã¨å‰å‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
- âœ… æ±ºå®šæœ¨ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´æ©Ÿèƒ½
- âœ… äºˆæ¸¬æ©Ÿèƒ½
- âœ… ãƒ¢ãƒ‡ãƒ«è©•ä¾¡æ©Ÿèƒ½
- âœ… ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜ã¨èª­ã¿è¾¼ã¿æ©Ÿèƒ½

#### å®šé‡çš„æˆæœ

| æŒ‡æ¨™ | å®Ÿç¸¾ |
|------|------|
| **ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹** | 18å€‹ |
| **ã‚³ãƒ¼ãƒ‰ã‚«ãƒãƒ¬ãƒƒã‚¸** | 95%ï¼ˆiris_classifier.pyï¼‰ |
| **å‹ãƒ’ãƒ³ãƒˆä½¿ç”¨ç‡** | 100% |
| **ãƒ¢ãƒ‡ãƒ«æ­£è§£ç‡** | 97.78%ï¼ˆãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ï¼‰ |
| **Ruff ãƒã‚§ãƒƒã‚¯** | å…¨ã¦é€šé |
| **mypy ãƒã‚§ãƒƒã‚¯** | ã‚¨ãƒ©ãƒ¼ 0ä»¶ |

#### ç¿’å¾—ã—ãŸã‚¹ã‚­ãƒ«

**1. TDD ã‚¹ã‚­ãƒ«ï¼ˆç™ºå±•ï¼‰**
- è¤‡é›‘ãªã‚¯ãƒ©ã‚¹ã®æ®µéšçš„å®Ÿè£…
- Fixture ã‚’æ´»ç”¨ã—ãŸãƒ†ã‚¹ãƒˆã®åŠ¹ç‡åŒ–
- ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ã®ç¶²ç¾…çš„ãƒ†ã‚¹ãƒˆ

**2. æ©Ÿæ¢°å­¦ç¿’ã‚¹ã‚­ãƒ«**
- æ±ºå®šæœ¨ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®ç†è§£
- è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã¨ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®åˆ†å‰²
- ãƒ¢ãƒ‡ãƒ«è©•ä¾¡æŒ‡æ¨™ï¼ˆæ­£è§£ç‡ï¼‰ã®ç†è§£
- ãƒ¢ãƒ‡ãƒ«ã®æ°¸ç¶šåŒ–ï¼ˆpickleï¼‰

**3. ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚¹ã‚­ãƒ«**
- pandas ã«ã‚ˆã‚‹ DataFrame æ“ä½œ
- æ¬ æå€¤ã®å‡¦ç†
- ãƒ‡ãƒ¼ã‚¿ã®å¦¥å½“æ€§æ¤œè¨¼

**4. ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢è¨­è¨ˆã‚¹ã‚­ãƒ«**
- å˜ä¸€è²¬ä»»ã®åŸå‰‡ï¼ˆSRPï¼‰ã®é©ç”¨
- ãƒ˜ãƒ«ãƒ‘ãƒ¼ãƒ¡ã‚½ãƒƒãƒ‰ã«ã‚ˆã‚‹è²¬å‹™åˆ†é›¢
- å‹ãƒ’ãƒ³ãƒˆã«ã‚ˆã‚‹å¥‘ç´„ã®æ˜ç¤º

#### æ±ºå®šæœ¨ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®ç†è§£

**æ±ºå®šæœ¨ã¨ã¯**ï¼š
ãƒ‡ãƒ¼ã‚¿ã‚’è¤‡æ•°ã®æ¡ä»¶åˆ†å²ã§åˆ†é¡ã™ã‚‹ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã§ã™ã€‚

```
                [Root]
                  |
         petal_length <= 2.45?
         /                    \
       Yes                     No
        |                       |
    setosa            petal_width <= 1.75?
                     /                    \
                   Yes                     No
                    |                       |
              versicolor                virginica
```

**max_depth ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®å½±éŸ¿**ï¼š

```python
def test_max_depthã¨æ­£è§£ç‡ã®é–¢ä¿‚():
    """max_depth ãŒæ­£è§£ç‡ã«ä¸ãˆã‚‹å½±éŸ¿ã‚’ç¢ºèª"""
    X, y = load_iris_data()
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.3, random_state=0
    )

    results = []
    for depth in [1, 2, 3, 5, 10]:
        classifier = IrisClassifier(max_depth=depth)
        classifier.train(X_train, y_train)

        train_acc = classifier.evaluate(X_train, y_train)
        test_acc = classifier.evaluate(X_test, y_test)

        results.append({
            'depth': depth,
            'train_accuracy': train_acc,
            'test_accuracy': test_acc,
            'gap': train_acc - test_acc
        })

    # depth=2 ã‚ãŸã‚ŠãŒé©åˆ‡ï¼ˆéå­¦ç¿’ã‚’é¿ã‘ã‚‹ï¼‰
    # depth ãŒå¤§ãã™ãã‚‹ã¨è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã«éå­¦ç¿’
```

#### æ¬¡ã®ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã¸ã®æº–å‚™

ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ 3 ã§ã¯ã€ä»¥ä¸‹ã‚’å®Ÿè£…ã—ã¾ã™ï¼š

- Cinema èˆˆè¡Œåå…¥äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ï¼ˆç·šå½¢å›å¸°ï¼‰
- å¤–ã‚Œå€¤æ¤œå‡ºã¨é™¤å¤–
- è¤‡æ•°ã®è©•ä¾¡æŒ‡æ¨™ï¼ˆRÂ²ã€MAEã€RMSEï¼‰
- ãƒ‡ãƒ¼ã‚¿ã®å¯è¦–åŒ–

---

## ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ 3: å›å¸°å•é¡Œã®åŸºç¤

### 5ç«  Cinema èˆˆè¡Œåå…¥äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«

#### å­¦ç¿’ç›®æ¨™

- å›å¸°å•é¡Œã®ç†è§£ã¨å®Ÿè£…
- ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†æŠ€è¡“ï¼ˆæ¬ æå€¤ãƒ»å¤–ã‚Œå€¤å‡¦ç†ï¼‰
- è©•ä¾¡æŒ‡æ¨™ã®é¸æŠã¨è§£é‡ˆ
- ç·šå½¢å›å¸°ãƒ¢ãƒ‡ãƒ«ã®æ§‹ç¯‰

#### Cinema ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ç†è§£

Cinema ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã¯ã€æ˜ ç”»ã® SNS éœ²å‡ºåº¦ã‹ã‚‰èˆˆè¡Œåå…¥ã‚’äºˆæ¸¬ã™ã‚‹å›å¸°å•é¡Œã®ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã™ã€‚

**ãƒ‡ãƒ¼ã‚¿ã®ç‰¹å¾´**ï¼š
- **ã‚µãƒ³ãƒ—ãƒ«æ•°**: 100ä»¶ç¨‹åº¦
- **ç‰¹å¾´é‡æ•°**: 4ã¤ï¼ˆæ•°å€¤ã¨ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å¤‰æ•°ã®æ··åœ¨ï¼‰
- **ç›®çš„å¤‰æ•°**: èˆˆè¡Œåå…¥ï¼ˆé€£ç¶šå€¤ï¼‰
- **æ¬ æå€¤**: ã‚ã‚Šï¼ˆå‰å‡¦ç†ãŒå¿…è¦ï¼‰
- **å¤–ã‚Œå€¤**: ã‚ã‚Šï¼ˆãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ãŒå¿…è¦ï¼‰

**ãƒ‡ãƒ¼ã‚¿è©³ç´°**ï¼š

| åˆ—å | å†…å®¹ | ãƒ‡ãƒ¼ã‚¿å‹ | å€¤ã®ç¯„å›² |
| --- | --- | --- | --- |
| cinema_id | æ˜ ç”»ä½œå“ã® ID | int | 1 - 100 |
| SNS1 | å…¬é–‹å¾Œ10æ—¥ä»¥å†…ã« SNS1 ã§ã¤ã¶ã‚„ã‹ã‚ŒãŸæ•° | float | 0 - 1000 |
| SNS2 | å…¬é–‹å¾Œ10æ—¥ä»¥å†…ã« SNS2 ã§ã¤ã¶ã‚„ã‹ã‚ŒãŸæ•° | float | 0 - 2000 |
| actor | ä¸»æ¼”ä¿³å„ªã®æ˜¨å¹´ã®ãƒ¡ãƒ‡ã‚£ã‚¢éœ²å‡ºåº¦ | float | 0 - 500 |
| original | åŸä½œãŒã‚ã‚‹ã‹ã©ã†ã‹ | int | 0ï¼ˆãªã—ï¼‰, 1ï¼ˆã‚ã‚Šï¼‰ |
| sales | æœ€çµ‚çš„ãªèˆˆè¡Œåå…¥ï¼ˆä¸‡å††ï¼‰ | float | 1000 - 15000 |

#### åˆ†é¡å•é¡Œã¨å›å¸°å•é¡Œã®é•ã„

**å¾©ç¿’ï¼šIrisï¼ˆåˆ†é¡å•é¡Œï¼‰ã¨ã®æ¯”è¼ƒ**

| é …ç›® | Irisï¼ˆåˆ†é¡ï¼‰ | Cinemaï¼ˆå›å¸°ï¼‰ |
|------|------------|--------------|
| **ç›®çš„** | ã‚«ãƒ†ã‚´ãƒªã‚’äºˆæ¸¬ | æ•°å€¤ã‚’äºˆæ¸¬ |
| **å‡ºåŠ›** | setosa, versicolor, virginica | èˆˆè¡Œåå…¥ï¼ˆé€£ç¶šå€¤ï¼‰ |
| **ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ** | æ±ºå®šæœ¨åˆ†é¡å™¨ | ç·šå½¢å›å¸° |
| **è©•ä¾¡æŒ‡æ¨™** | æ­£è§£ç‡ï¼ˆAccuracyï¼‰ | RÂ²ã€MAEã€RMSE |
| **èª¤å·®ã®æ€§è³ª** | æ­£è§£/ä¸æ­£è§£ã®2å€¤ | èª¤å·®ã®å¤§ãã•ãŒé‡è¦ |

#### TDD ã«ã‚ˆã‚‹æ®µéšçš„å®Ÿè£…

##### ã‚¹ãƒ†ãƒƒãƒ— 1: ã‚¯ãƒ©ã‚¹ã®åˆæœŸåŒ–ã¨ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿

**Red: ãƒ†ã‚¹ãƒˆã‚’æ›¸ã**

**test/test_cinema_predictor.py**:

```python
"""Cinema äºˆæ¸¬å™¨ã®ãƒ†ã‚¹ãƒˆ"""
import pytest
import pandas as pd
import numpy as np
from src.ml.cinema_predictor import CinemaPredictor


class TestCinemaPredictorInit:
    """CinemaPredictor ã®åˆæœŸåŒ–ãƒ†ã‚¹ãƒˆ"""

    def test_ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§ã®åˆæœŸåŒ–(self):
        """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§åˆæœŸåŒ–ã§ãã‚‹ã“ã¨ã‚’ç¢ºèª"""
        predictor = CinemaPredictor()

        assert predictor is not None
        assert predictor.model is None

    def test_åˆæœŸåŒ–æ™‚ã®å±æ€§ç¢ºèª(self):
        """åˆæœŸåŒ–æ™‚ã«å¿…è¦ãªå±æ€§ãŒè¨­å®šã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª"""
        predictor = CinemaPredictor()

        assert hasattr(predictor, 'model')
        assert predictor.model is None


class TestCinemaPredictorDataLoading:
    """ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã®ãƒ†ã‚¹ãƒˆ"""

    def test_CSVãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã®ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿(self):
        """CSV ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª"""
        predictor = CinemaPredictor()
        X, y = predictor.load_data('data/cinema.csv')

        assert X is not None
        assert y is not None
        assert isinstance(X, pd.DataFrame)
        assert isinstance(y, pd.Series)

    def test_ç‰¹å¾´é‡ã®åˆ—æ•°ç¢ºèª(self):
        """ç‰¹å¾´é‡ãŒ 4 åˆ—ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª"""
        predictor = CinemaPredictor()
        X, y = predictor.load_data('data/cinema.csv')

        assert X.shape[1] == 4
        expected_columns = ['SNS1', 'SNS2', 'actor', 'original']
        assert list(X.columns) == expected_columns

    def test_æ¬ æå€¤ã®è£œå®Œ(self):
        """æ¬ æå€¤ãŒå¹³å‡å€¤ã§è£œå®Œã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª"""
        import tempfile
        import os

        # æ¬ æå€¤ã‚’å«ã‚€ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿
        test_data = """cinema_id,SNS1,SNS2,actor,original,sales
1,100,500,200,1,10000
2,,600,250,0,11000
3,150,,300,1,12000"""

        with tempfile.NamedTemporaryFile(mode='w', delete=False, suffix='.csv') as f:
            f.write(test_data)
            temp_path = f.name

        try:
            predictor = CinemaPredictor()
            X, y = predictor.load_data(temp_path)

            # æ¬ æå€¤ãŒè£œå®Œã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª
            assert X.isnull().sum().sum() == 0
        finally:
            os.unlink(temp_path)

    def test_ç›®çš„å¤‰æ•°ã®åˆ†é›¢(self):
        """sales ãŒç›®çš„å¤‰æ•°ã¨ã—ã¦æ­£ã—ãåˆ†é›¢ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª"""
        predictor = CinemaPredictor()
        X, y = predictor.load_data('data/cinema.csv')

        assert 'sales' not in X.columns
        assert y.name == 'sales'
```

**Green: æœ€å°é™ã®å®Ÿè£…**

**src/ml/cinema_predictor.py**:

```python
"""Cinema èˆˆè¡Œåå…¥äºˆæ¸¬å™¨ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«"""
import os
from typing import Optional, Tuple
import pandas as pd
import numpy as np
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score


class CinemaPredictor:
    """æ˜ ç”»èˆˆè¡Œåå…¥ã‚’äºˆæ¸¬ã™ã‚‹ç·šå½¢å›å¸°ãƒ¢ãƒ‡ãƒ«

    Attributes:
        model: è¨“ç·´æ¸ˆã¿ã®ç·šå½¢å›å¸°ãƒ¢ãƒ‡ãƒ«ï¼ˆæœªè¨“ç·´æ™‚ã¯ Noneï¼‰
    """

    def __init__(self) -> None:
        """åˆæœŸåŒ–"""
        self.model: Optional[LinearRegression] = None

    def load_data(self, file_path: str) -> Tuple[pd.DataFrame, pd.Series]:
        """CSV ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€

        Args:
            file_path: CSV ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹

        Returns:
            ç‰¹å¾´é‡ DataFrame ã¨ç›®çš„å¤‰æ•° Series ã®ã‚¿ãƒ—ãƒ«

        Raises:
            FileNotFoundError: ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆ
            ValueError: ãƒ‡ãƒ¼ã‚¿ã®å½¢å¼ãŒä¸æ­£ãªå ´åˆ
        """
        if not os.path.exists(file_path):
            raise FileNotFoundError(f"File not found: {file_path}")

        # ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
        df = pd.read_csv(file_path)

        # å¿…è¦ãªåˆ—ã®å­˜åœ¨ç¢ºèª
        required_columns = ['SNS1', 'SNS2', 'actor', 'original', 'sales']
        missing_columns = set(required_columns) - set(df.columns)
        if missing_columns:
            raise ValueError(f"Missing columns: {missing_columns}")

        # ç‰¹å¾´é‡åˆ—
        feature_columns = ['SNS1', 'SNS2', 'actor', 'original']

        # æ¬ æå€¤ã‚’å¹³å‡å€¤ã§è£œå®Œ
        df_filled = df.fillna(df.mean())

        # ç‰¹å¾´é‡ã¨ç›®çš„å¤‰æ•°ã®åˆ†å‰²
        X = df_filled[feature_columns]
        y = df_filled['sales']

        return X, y
```

##### ã‚¹ãƒ†ãƒƒãƒ— 2: å¤–ã‚Œå€¤å‡¦ç†

å›å¸°å•é¡Œã§ã¯ã€å¤–ã‚Œå€¤ãŒãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã«å¤§ããå½±éŸ¿ã—ã¾ã™ã€‚

**Red: ãƒ†ã‚¹ãƒˆã‚’æ›¸ã**

```python
class TestCinemaPredictorOutlierRemoval:
    """å¤–ã‚Œå€¤é™¤å¤–ã®ãƒ†ã‚¹ãƒˆ"""

    def test_å¤–ã‚Œå€¤ã®æ¤œå‡º(self):
        """å¤–ã‚Œå€¤ã‚’æ¤œå‡ºã§ãã‚‹ã“ã¨ã‚’ç¢ºèª"""
        predictor = CinemaPredictor()

        # å¤–ã‚Œå€¤ã‚’å«ã‚€ãƒ‡ãƒ¼ã‚¿
        df = pd.DataFrame({
            'SNS1': [100, 150, 120],
            'SNS2': [500, 1500, 600],  # 1500 ãŒç•°å¸¸ã«é«˜ã„
            'actor': [200, 250, 220],
            'original': [1, 0, 1],
            'sales': [10000, 3000, 11000]  # SNS2é«˜ã„ã®ã« salesä½ã„â†’å¤–ã‚Œå€¤
        })

        df_cleaned = predictor.remove_outliers(df)

        # å¤–ã‚Œå€¤ãŒé™¤å¤–ã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª
        assert len(df_cleaned) == 2
        assert 1500 not in df_cleaned['SNS2'].values

    def test_æ­£å¸¸ãƒ‡ãƒ¼ã‚¿ã¯ä¿æŒã•ã‚Œã‚‹(self):
        """æ­£å¸¸ãªãƒ‡ãƒ¼ã‚¿ã¯ä¿æŒã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª"""
        predictor = CinemaPredictor()

        # æ­£å¸¸ãªãƒ‡ãƒ¼ã‚¿ã®ã¿
        df = pd.DataFrame({
            'SNS1': [100, 150, 120],
            'SNS2': [500, 600, 550],
            'actor': [200, 250, 220],
            'original': [1, 0, 1],
            'sales': [10000, 11000, 10500]
        })

        df_cleaned = predictor.remove_outliers(df)

        # å…¨ã¦ã®ãƒ‡ãƒ¼ã‚¿ãŒä¿æŒã•ã‚Œã‚‹
        assert len(df_cleaned) == 3

    def test_å¤–ã‚Œå€¤é™¤å¤–ã®åŸºæº–(self):
        """å¤–ã‚Œå€¤é™¤å¤–ã®åŸºæº–ãŒæ­£ã—ã„ã“ã¨ã‚’ç¢ºèª"""
        predictor = CinemaPredictor()

        df = pd.DataFrame({
            'SNS1': [100, 150, 120, 140],
            'SNS2': [500, 1500, 600, 700],
            'actor': [200, 250, 220, 230],
            'original': [1, 0, 1, 0],
            'sales': [10000, 3000, 11000, 10500]
        })

        df_cleaned = predictor.remove_outliers(df)

        # SNS2 > 1000 ã‹ã¤ sales < 8500 ã®ãƒ‡ãƒ¼ã‚¿ãŒé™¤å¤–ã•ã‚Œã‚‹
        for _, row in df_cleaned.iterrows():
            if row['SNS2'] > 1000:
                assert row['sales'] >= 8500
```

**Green: å¤–ã‚Œå€¤å‡¦ç†ã®å®Ÿè£…**

```python
def remove_outliers(self, df: pd.DataFrame) -> pd.DataFrame:
    """å¤–ã‚Œå€¤ã‚’é™¤å¤–ã™ã‚‹

    Args:
        df: å¯¾è±¡ã® DataFrame

    Returns:
        å¤–ã‚Œå€¤ã‚’é™¤å¤–ã—ãŸ DataFrame

    Note:
        SNS2 ãŒ 1000 ã‚’è¶…ãˆã¦ã„ã‚‹ã«ã‚‚é–¢ã‚ã‚‰ãš sales ãŒ 8500 æœªæº€ã®ãƒ‡ãƒ¼ã‚¿ã‚’
        ç•°å¸¸å€¤ã¨ã—ã¦é™¤å¤–ã—ã¾ã™ã€‚
    """
    # å¤–ã‚Œå€¤ã®æ¡ä»¶: SNS2 > 1000 ã‹ã¤ sales < 8500
    outlier_condition = (df['SNS2'] > 1000) & (df['sales'] < 8500)
    outlier_indices = df[outlier_condition].index

    # å¤–ã‚Œå€¤ã‚’é™¤å¤–
    df_cleaned = df.drop(outlier_indices, axis=0)

    return df_cleaned
```

**Refactor: ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã«å¤–ã‚Œå€¤å‡¦ç†ã‚’çµ±åˆ**

```python
def load_data(self, file_path: str,
              remove_outliers: bool = True) -> Tuple[pd.DataFrame, pd.Series]:
    """CSV ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€ï¼ˆå¤–ã‚Œå€¤å‡¦ç†è¿½åŠ ï¼‰

    Args:
        file_path: CSV ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        remove_outliers: å¤–ã‚Œå€¤ã‚’é™¤å¤–ã™ã‚‹ã‹ã©ã†ã‹ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: Trueï¼‰

    Returns:
        ç‰¹å¾´é‡ DataFrame ã¨ç›®çš„å¤‰æ•° Series ã®ã‚¿ãƒ—ãƒ«
    """
    if not os.path.exists(file_path):
        raise FileNotFoundError(f"File not found: {file_path}")

    df = pd.read_csv(file_path)

    required_columns = ['SNS1', 'SNS2', 'actor', 'original', 'sales']
    missing_columns = set(required_columns) - set(df.columns)
    if missing_columns:
        raise ValueError(f"Missing columns: {missing_columns}")

    # æ¬ æå€¤ã‚’å¹³å‡å€¤ã§è£œå®Œ
    df_filled = df.fillna(df.mean())

    # å¤–ã‚Œå€¤ã®é™¤å¤–ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
    if remove_outliers:
        df_filled = self.remove_outliers(df_filled)

    feature_columns = ['SNS1', 'SNS2', 'actor', 'original']
    X = df_filled[feature_columns]
    y = df_filled['sales']

    return X, y
```

##### ã‚¹ãƒ†ãƒƒãƒ— 3: ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´

**Red: ãƒ†ã‚¹ãƒˆã‚’æ›¸ã**

```python
class TestCinemaPredictorTraining:
    """ãƒ¢ãƒ‡ãƒ«è¨“ç·´ã®ãƒ†ã‚¹ãƒˆ"""

    def test_ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´(self):
        """ç·šå½¢å›å¸°ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã§ãã‚‹ã“ã¨ã‚’ç¢ºèª"""
        predictor = CinemaPredictor()
        X_train = pd.DataFrame({
            'SNS1': [100, 150, 120],
            'SNS2': [500, 600, 550],
            'actor': [200, 250, 220],
            'original': [1, 0, 1]
        })
        y_train = pd.Series([10000, 11000, 10500])

        predictor.train(X_train, y_train)

        assert predictor.model is not None
        assert isinstance(predictor.model, LinearRegression)

    def test_è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®ä¿‚æ•°ç¢ºèª(self):
        """è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ãŒä¿‚æ•°ã‚’æŒã¤ã“ã¨ã‚’ç¢ºèª"""
        predictor = CinemaPredictor()
        X_train = pd.DataFrame({
            'SNS1': [100, 150, 120],
            'SNS2': [500, 600, 550],
            'actor': [200, 250, 220],
            'original': [1, 0, 1]
        })
        y_train = pd.Series([10000, 11000, 10500])

        predictor.train(X_train, y_train)

        # ç·šå½¢å›å¸°ã®ä¿‚æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª
        assert hasattr(predictor.model, 'coef_')
        assert hasattr(predictor.model, 'intercept_')
        assert len(predictor.model.coef_) == 4  # ç‰¹å¾´é‡ãŒ4ã¤

    def test_ç©ºã®ãƒ‡ãƒ¼ã‚¿ã§ã®è¨“ç·´æ‹’å¦(self):
        """ç©ºã®ãƒ‡ãƒ¼ã‚¿ã§ã®è¨“ç·´ã‚’æ‹’å¦ã™ã‚‹ã“ã¨ã‚’ç¢ºèª"""
        predictor = CinemaPredictor()
        X_train = pd.DataFrame()
        y_train = pd.Series(dtype=float)

        with pytest.raises(ValueError):
            predictor.train(X_train, y_train)
```

**Green: è¨“ç·´æ©Ÿèƒ½ã®å®Ÿè£…**

```python
def train(self, X_train: pd.DataFrame, y_train: pd.Series) -> None:
    """ç·šå½¢å›å¸°ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã™ã‚‹

    Args:
        X_train: è¨“ç·´ç”¨ç‰¹å¾´é‡
        y_train: è¨“ç·´ç”¨ç›®çš„å¤‰æ•°

    Raises:
        ValueError: ãƒ‡ãƒ¼ã‚¿ãŒç©ºã®å ´åˆ
    """
    if len(X_train) == 0 or len(y_train) == 0:
        raise ValueError("Training data cannot be empty")

    if len(X_train) != len(y_train):
        raise ValueError(
            f"X_train and y_train must have the same length: "
            f"{len(X_train)} != {len(y_train)}"
        )

    # ç·šå½¢å›å¸°ãƒ¢ãƒ‡ãƒ«ã®ä½œæˆ
    self.model = LinearRegression()

    # ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´
    self.model.fit(X_train, y_train)
```

##### ã‚¹ãƒ†ãƒƒãƒ— 4: äºˆæ¸¬ã¨è©•ä¾¡

**Red: ãƒ†ã‚¹ãƒˆã‚’æ›¸ã**

```python
class TestCinemaPredictorPrediction:
    """äºˆæ¸¬æ©Ÿèƒ½ã®ãƒ†ã‚¹ãƒˆ"""

    @pytest.fixture
    def trained_predictor(self):
        """è¨“ç·´æ¸ˆã¿ã®äºˆæ¸¬å™¨ã‚’è¿”ã™ fixture"""
        predictor = CinemaPredictor()
        X_train = pd.DataFrame({
            'SNS1': [100, 150, 120, 140],
            'SNS2': [500, 600, 550, 580],
            'actor': [200, 250, 220, 230],
            'original': [1, 0, 1, 0]
        })
        y_train = pd.Series([10000, 11000, 10500, 10800])
        predictor.train(X_train, y_train)
        return predictor

    def test_å˜ä¸€ã‚µãƒ³ãƒ—ãƒ«ã®äºˆæ¸¬(self, trained_predictor):
        """å˜ä¸€ã‚µãƒ³ãƒ—ãƒ«ã‚’äºˆæ¸¬ã§ãã‚‹ã“ã¨ã‚’ç¢ºèª"""
        X_test = pd.DataFrame({
            'SNS1': [130],
            'SNS2': [570],
            'actor': [210],
            'original': [1]
        })

        predictions = trained_predictor.predict(X_test)

        assert len(predictions) == 1
        assert isinstance(predictions[0], (int, float, np.number))
        assert predictions[0] > 0  # èˆˆè¡Œåå…¥ã¯æ­£ã®å€¤

    def test_è¤‡æ•°ã‚µãƒ³ãƒ—ãƒ«ã®äºˆæ¸¬(self, trained_predictor):
        """è¤‡æ•°ã‚µãƒ³ãƒ—ãƒ«ã‚’äºˆæ¸¬ã§ãã‚‹ã“ã¨ã‚’ç¢ºèª"""
        X_test = pd.DataFrame({
            'SNS1': [130, 160],
            'SNS2': [570, 620],
            'actor': [210, 260],
            'original': [1, 0]
        })

        predictions = trained_predictor.predict(X_test)

        assert len(predictions) == 2


class TestCinemaPredictorEvaluation:
    """ãƒ¢ãƒ‡ãƒ«è©•ä¾¡ã®ãƒ†ã‚¹ãƒˆ"""

    def test_è©•ä¾¡æŒ‡æ¨™ã®è¨ˆç®—(self):
        """è¤‡æ•°ã®è©•ä¾¡æŒ‡æ¨™ã‚’è¨ˆç®—ã§ãã‚‹ã“ã¨ã‚’ç¢ºèª"""
        predictor = CinemaPredictor()
        X_train = pd.DataFrame({
            'SNS1': [100, 150, 120, 140],
            'SNS2': [500, 600, 550, 580],
            'actor': [200, 250, 220, 230],
            'original': [1, 0, 1, 0]
        })
        y_train = pd.Series([10000, 11000, 10500, 10800])
        predictor.train(X_train, y_train)

        # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿
        X_test = pd.DataFrame({
            'SNS1': [130, 160],
            'SNS2': [570, 620],
            'actor': [210, 260],
            'original': [1, 0]
        })
        y_test = pd.Series([10600, 11200])

        metrics = predictor.evaluate(X_test, y_test)

        # å…¨ã¦ã®è©•ä¾¡æŒ‡æ¨™ãŒå«ã¾ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
        assert 'r2_score' in metrics
        assert 'mae' in metrics
        assert 'rmse' in metrics

    def test_æ±ºå®šä¿‚æ•°ã®ç¯„å›²(self):
        """æ±ºå®šä¿‚æ•°ãŒé©åˆ‡ãªç¯„å›²ã«ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª"""
        predictor = CinemaPredictor()
        X, y = predictor.load_data('data/cinema.csv')

        from sklearn.model_selection import train_test_split
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=0
        )

        predictor.train(X_train, y_train)
        metrics = predictor.evaluate(X_test, y_test)

        # RÂ²ã¯é€šå¸¸ -âˆ ã‹ã‚‰ 1 ã®ç¯„å›²ï¼ˆè‰¯ã„ãƒ¢ãƒ‡ãƒ«ã¯ 0 ã«è¿‘ã„ã‹æ­£ï¼‰
        assert metrics['r2_score'] <= 1.0

    def test_MAEã¨RMSEã®é–¢ä¿‚(self):
        """MAE ã¨ RMSE ã®é–¢ä¿‚ã‚’ç¢ºèª"""
        predictor = CinemaPredictor()
        X, y = predictor.load_data('data/cinema.csv')

        from sklearn.model_selection import train_test_split
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=0.2, random_state=0
        )

        predictor.train(X_train, y_train)
        metrics = predictor.evaluate(X_test, y_test)

        # RMSE ã¯ MAE ä»¥ä¸Šã«ãªã‚‹ï¼ˆç­‰å·ã¯å…¨ã¦ã®èª¤å·®ãŒåŒã˜æ™‚ï¼‰
        assert metrics['rmse'] >= metrics['mae']
```

**Green: äºˆæ¸¬ã¨è©•ä¾¡æ©Ÿèƒ½ã®å®Ÿè£…**

```python
def predict(self, X_test: pd.DataFrame) -> np.ndarray:
    """èˆˆè¡Œåå…¥ã‚’äºˆæ¸¬ã™ã‚‹

    Args:
        X_test: ãƒ†ã‚¹ãƒˆç”¨ç‰¹å¾´é‡

    Returns:
        äºˆæ¸¬ã•ã‚ŒãŸèˆˆè¡Œåå…¥ã®é…åˆ—

    Raises:
        ValueError: ãƒ¢ãƒ‡ãƒ«ãŒæœªè¨“ç·´ã®å ´åˆ
    """
    if self.model is None:
        raise ValueError("Model has not been trained yet")

    return self.model.predict(X_test)


def evaluate(self, X_test: pd.DataFrame, y_test: pd.Series) -> dict:
    """ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã‚’è©•ä¾¡ã™ã‚‹

    Args:
        X_test: ãƒ†ã‚¹ãƒˆç”¨ç‰¹å¾´é‡
        y_test: ãƒ†ã‚¹ãƒˆç”¨ç›®çš„å¤‰æ•°

    Returns:
        è©•ä¾¡æŒ‡æ¨™ã®è¾æ›¸
        - r2_score: æ±ºå®šä¿‚æ•°ï¼ˆ1.0 ã«è¿‘ã„ã»ã©è‰¯ã„ï¼‰
        - mae: å¹³å‡çµ¶å¯¾èª¤å·®ï¼ˆå°ã•ã„ã»ã©è‰¯ã„ï¼‰
        - rmse: å¹³å‡äºŒä¹—èª¤å·®ã®å¹³æ–¹æ ¹ï¼ˆå°ã•ã„ã»ã©è‰¯ã„ï¼‰

    Raises:
        ValueError: ãƒ¢ãƒ‡ãƒ«ãŒæœªè¨“ç·´ã®å ´åˆ
    """
    if self.model is None:
        raise ValueError("Model has not been trained yet")

    y_pred = self.model.predict(X_test)

    return {
        'r2_score': r2_score(y_test, y_pred),
        'mae': mean_absolute_error(y_test, y_pred),
        'rmse': np.sqrt(mean_squared_error(y_test, y_pred))
    }
```

##### ã‚¹ãƒ†ãƒƒãƒ— 5: ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜ã¨èª­ã¿è¾¼ã¿

**Red: ãƒ†ã‚¹ãƒˆã‚’æ›¸ã**

```python
class TestCinemaPredictorPersistence:
    """ãƒ¢ãƒ‡ãƒ«ã®æ°¸ç¶šåŒ–ãƒ†ã‚¹ãƒˆ"""

    def test_ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜(self, tmp_path):
        """è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ä¿å­˜ã§ãã‚‹ã“ã¨ã‚’ç¢ºèª"""
        predictor = CinemaPredictor()
        X_train = pd.DataFrame({
            'SNS1': [100, 150],
            'SNS2': [500, 600],
            'actor': [200, 250],
            'original': [1, 0]
        })
        y_train = pd.Series([10000, 11000])
        predictor.train(X_train, y_train)

        model_path = tmp_path / "cinema_model.pkl"
        predictor.save_model(str(model_path))

        assert model_path.exists()

    def test_ä¿å­˜ã—ãŸãƒ¢ãƒ‡ãƒ«ã§ã®äºˆæ¸¬ä¸€è²«æ€§(self, tmp_path):
        """ä¿å­˜å‰å¾Œã§äºˆæ¸¬çµæœãŒä¸€è‡´ã™ã‚‹ã“ã¨ã‚’ç¢ºèª"""
        # ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´
        predictor1 = CinemaPredictor()
        X_train = pd.DataFrame({
            'SNS1': [100, 150],
            'SNS2': [500, 600],
            'actor': [200, 250],
            'original': [1, 0]
        })
        y_train = pd.Series([10000, 11000])
        predictor1.train(X_train, y_train)

        # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿
        X_test = pd.DataFrame({
            'SNS1': [130],
            'SNS2': [570],
            'actor': [210],
            'original': [1]
        })

        # ä¿å­˜å‰ã®äºˆæ¸¬
        pred_before = predictor1.predict(X_test)

        # ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜ã¨èª­ã¿è¾¼ã¿
        model_path = tmp_path / "cinema_model.pkl"
        predictor1.save_model(str(model_path))

        predictor2 = CinemaPredictor()
        predictor2.load_model(str(model_path))

        # èª­ã¿è¾¼ã¿å¾Œã®äºˆæ¸¬
        pred_after = predictor2.predict(X_test)

        # äºˆæ¸¬çµæœãŒä¸€è‡´ã™ã‚‹ã“ã¨ã‚’ç¢ºèª
        np.testing.assert_array_almost_equal(pred_before, pred_after)
```

**Green: æ°¸ç¶šåŒ–æ©Ÿèƒ½ã®å®Ÿè£…**

```python
import pickle


def save_model(self, file_path: str) -> None:
    """è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã™ã‚‹

    Args:
        file_path: ä¿å­˜å…ˆã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹

    Raises:
        ValueError: ãƒ¢ãƒ‡ãƒ«ãŒæœªè¨“ç·´ã®å ´åˆ
    """
    if self.model is None:
        raise ValueError("No trained model to save")

    with open(file_path, 'wb') as f:
        pickle.dump(self.model, f)


def load_model(self, file_path: str) -> None:
    """ä¿å­˜ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã‚€

    Args:
        file_path: èª­ã¿è¾¼ã‚€ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹

    Raises:
        FileNotFoundError: ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆ
    """
    if not os.path.exists(file_path):
        raise FileNotFoundError(f"Model file not found: {file_path}")

    with open(file_path, 'rb') as f:
        self.model = pickle.load(f)
```

#### è©•ä¾¡æŒ‡æ¨™ã®ç†è§£

å›å¸°å•é¡Œã§ã¯ã€è¤‡æ•°ã®è©•ä¾¡æŒ‡æ¨™ã‚’ä½¿ç”¨ã—ã¦ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã‚’å¤šè§’çš„ã«è©•ä¾¡ã—ã¾ã™ã€‚

**1. æ±ºå®šä¿‚æ•°ï¼ˆRÂ² Scoreï¼‰**

```python
"""
RÂ² = 1 - (äºˆæ¸¬èª¤å·®ã®å¹³æ–¹å’Œ / å®Ÿæ¸¬å€¤ã®åˆ†æ•£)

- å€¤ã®ç¯„å›²: -âˆ ã‹ã‚‰ 1
- 1.0: å®Œç’§ãªäºˆæ¸¬
- 0.0: å¹³å‡å€¤ã§äºˆæ¸¬ã™ã‚‹ã®ã¨åŒç­‰
- è² ã®å€¤: å¹³å‡å€¤ã§äºˆæ¸¬ã™ã‚‹ã‚ˆã‚Šæ‚ªã„
"""

def test_R2ã‚¹ã‚³ã‚¢ã®è§£é‡ˆ():
    """RÂ²ã‚¹ã‚³ã‚¢ã®æ„å‘³ã‚’ç¢ºèª"""
    # å®Œç’§ãªäºˆæ¸¬
    y_true = np.array([100, 200, 300])
    y_pred = np.array([100, 200, 300])
    r2 = r2_score(y_true, y_pred)
    assert r2 == 1.0  # å®Œç’§

    # å¹³å‡å€¤ã§äºˆæ¸¬
    y_pred = np.array([200, 200, 200])  # å…¨ã¦å¹³å‡
    r2 = r2_score(y_true, y_pred)
    assert r2 == 0.0  # å¹³å‡å€¤ã¨åŒç­‰

    # æ‚ªã„äºˆæ¸¬
    y_pred = np.array([300, 100, 100])  # å…¨ãå¤–ã‚Œã¦ã„ã‚‹
    r2 = r2_score(y_true, y_pred)
    assert r2 < 0  # å¹³å‡å€¤ã‚ˆã‚Šæ‚ªã„
```

**2. å¹³å‡çµ¶å¯¾èª¤å·®ï¼ˆMAE: Mean Absolute Errorï¼‰**

```python
"""
MAE = Î£|äºˆæ¸¬å€¤ - å®Ÿæ¸¬å€¤| / ã‚µãƒ³ãƒ—ãƒ«æ•°

- å€¤ã®ç¯„å›²: 0 ã‹ã‚‰ âˆ
- 0: å®Œç’§ãªäºˆæ¸¬
- èª¤å·®ã®çµ¶å¯¾å€¤ã®å¹³å‡ï¼ˆå˜ä½ã¯ç›®çš„å¤‰æ•°ã¨åŒã˜ï¼‰
- å¤–ã‚Œå€¤ã®å½±éŸ¿ã‚’å—ã‘ã«ãã„
"""

def test_MAEã®è¨ˆç®—():
    """MAE ã®è¨ˆç®—ã‚’ç¢ºèª"""
    y_true = np.array([10000, 11000, 12000])
    y_pred = np.array([10200, 10800, 12100])

    mae = mean_absolute_error(y_true, y_pred)

    # (200 + 200 + 100) / 3 = 166.67
    assert abs(mae - 166.67) < 0.01
```

**3. å¹³å‡äºŒä¹—èª¤å·®ã®å¹³æ–¹æ ¹ï¼ˆRMSE: Root Mean Squared Errorï¼‰**

```python
"""
RMSE = âˆš(Î£(äºˆæ¸¬å€¤ - å®Ÿæ¸¬å€¤)Â² / ã‚µãƒ³ãƒ—ãƒ«æ•°)

- å€¤ã®ç¯„å›²: 0 ã‹ã‚‰ âˆ
- 0: å®Œç’§ãªäºˆæ¸¬
- èª¤å·®ã®äºŒä¹—å¹³å‡ã®å¹³æ–¹æ ¹ï¼ˆå˜ä½ã¯ç›®çš„å¤‰æ•°ã¨åŒã˜ï¼‰
- å¤–ã‚Œå€¤ã®å½±éŸ¿ã‚’å—ã‘ã‚„ã™ã„ï¼ˆå¤§ããªèª¤å·®ã«ãƒšãƒŠãƒ«ãƒ†ã‚£ï¼‰
"""

def test_RMSEã®è¨ˆç®—():
    """RMSE ã®è¨ˆç®—ã‚’ç¢ºèª"""
    y_true = np.array([10000, 11000, 12000])
    y_pred = np.array([10200, 10800, 12100])

    mse = mean_squared_error(y_true, y_pred)
    rmse = np.sqrt(mse)

    # âˆš((200Â² + 200Â² + 100Â²) / 3) = âˆš(90000 / 3) = âˆš30000 â‰ˆ 173.21
    assert abs(rmse - 173.21) < 0.01
```

#### å®Œå…¨ãªå®Ÿè£…ä¾‹

**src/ml/cinema_predictor.py**:

```python
"""Cinema èˆˆè¡Œåå…¥äºˆæ¸¬å™¨ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«"""
import os
import pickle
from typing import Optional, Tuple
import pandas as pd
import numpy as np
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score


class CinemaPredictor:
    """æ˜ ç”»èˆˆè¡Œåå…¥ã‚’äºˆæ¸¬ã™ã‚‹ç·šå½¢å›å¸°ãƒ¢ãƒ‡ãƒ«

    Attributes:
        model: è¨“ç·´æ¸ˆã¿ã®ç·šå½¢å›å¸°ãƒ¢ãƒ‡ãƒ«ï¼ˆæœªè¨“ç·´æ™‚ã¯ Noneï¼‰
    """

    def __init__(self) -> None:
        """åˆæœŸåŒ–"""
        self.model: Optional[LinearRegression] = None

    def remove_outliers(self, df: pd.DataFrame) -> pd.DataFrame:
        """å¤–ã‚Œå€¤ã‚’é™¤å¤–ã™ã‚‹

        Args:
            df: å¯¾è±¡ã® DataFrame

        Returns:
            å¤–ã‚Œå€¤ã‚’é™¤å¤–ã—ãŸ DataFrame
        """
        outlier_condition = (df['SNS2'] > 1000) & (df['sales'] < 8500)
        outlier_indices = df[outlier_condition].index
        return df.drop(outlier_indices, axis=0)

    def load_data(self, file_path: str,
                  remove_outliers: bool = True) -> Tuple[pd.DataFrame, pd.Series]:
        """CSV ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€

        Args:
            file_path: CSV ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
            remove_outliers: å¤–ã‚Œå€¤ã‚’é™¤å¤–ã™ã‚‹ã‹ã©ã†ã‹

        Returns:
            ç‰¹å¾´é‡ DataFrame ã¨ç›®çš„å¤‰æ•° Series ã®ã‚¿ãƒ—ãƒ«

        Raises:
            FileNotFoundError: ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆ
            ValueError: ãƒ‡ãƒ¼ã‚¿ã®å½¢å¼ãŒä¸æ­£ãªå ´åˆ
        """
        if not os.path.exists(file_path):
            raise FileNotFoundError(f"File not found: {file_path}")

        df = pd.read_csv(file_path)

        required_columns = ['SNS1', 'SNS2', 'actor', 'original', 'sales']
        missing_columns = set(required_columns) - set(df.columns)
        if missing_columns:
            raise ValueError(f"Missing columns: {missing_columns}")

        # æ¬ æå€¤ã‚’å¹³å‡å€¤ã§è£œå®Œ
        df_filled = df.fillna(df.mean())

        # å¤–ã‚Œå€¤ã®é™¤å¤–ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        if remove_outliers:
            df_filled = self.remove_outliers(df_filled)

        feature_columns = ['SNS1', 'SNS2', 'actor', 'original']
        X = df_filled[feature_columns]
        y = df_filled['sales']

        return X, y

    def train(self, X_train: pd.DataFrame, y_train: pd.Series) -> None:
        """ç·šå½¢å›å¸°ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã™ã‚‹

        Args:
            X_train: è¨“ç·´ç”¨ç‰¹å¾´é‡
            y_train: è¨“ç·´ç”¨ç›®çš„å¤‰æ•°

        Raises:
            ValueError: ãƒ‡ãƒ¼ã‚¿ãŒç©ºã®å ´åˆ
        """
        if len(X_train) == 0 or len(y_train) == 0:
            raise ValueError("Training data cannot be empty")

        if len(X_train) != len(y_train):
            raise ValueError(
                f"X_train and y_train must have the same length: "
                f"{len(X_train)} != {len(y_train)}"
            )

        self.model = LinearRegression()
        self.model.fit(X_train, y_train)

    def predict(self, X_test: pd.DataFrame) -> np.ndarray:
        """èˆˆè¡Œåå…¥ã‚’äºˆæ¸¬ã™ã‚‹

        Args:
            X_test: ãƒ†ã‚¹ãƒˆç”¨ç‰¹å¾´é‡

        Returns:
            äºˆæ¸¬ã•ã‚ŒãŸèˆˆè¡Œåå…¥ã®é…åˆ—

        Raises:
            ValueError: ãƒ¢ãƒ‡ãƒ«ãŒæœªè¨“ç·´ã®å ´åˆ
        """
        if self.model is None:
            raise ValueError("Model has not been trained yet")

        return self.model.predict(X_test)

    def evaluate(self, X_test: pd.DataFrame, y_test: pd.Series) -> dict:
        """ãƒ¢ãƒ‡ãƒ«ã®æ€§èƒ½ã‚’è©•ä¾¡ã™ã‚‹

        Args:
            X_test: ãƒ†ã‚¹ãƒˆç”¨ç‰¹å¾´é‡
            y_test: ãƒ†ã‚¹ãƒˆç”¨ç›®çš„å¤‰æ•°

        Returns:
            è©•ä¾¡æŒ‡æ¨™ã®è¾æ›¸
        """
        if self.model is None:
            raise ValueError("Model has not been trained yet")

        y_pred = self.model.predict(X_test)

        return {
            'r2_score': r2_score(y_test, y_pred),
            'mae': mean_absolute_error(y_test, y_pred),
            'rmse': np.sqrt(mean_squared_error(y_test, y_pred))
        }

    def save_model(self, file_path: str) -> None:
        """è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã™ã‚‹

        Args:
            file_path: ä¿å­˜å…ˆã®ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹

        Raises:
            ValueError: ãƒ¢ãƒ‡ãƒ«ãŒæœªè¨“ç·´ã®å ´åˆ
        """
        if self.model is None:
            raise ValueError("No trained model to save")

        with open(file_path, 'wb') as f:
            pickle.dump(self.model, f)

    def load_model(self, file_path: str) -> None:
        """ä¿å­˜ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã‚€

        Args:
            file_path: èª­ã¿è¾¼ã‚€ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹

        Raises:
            FileNotFoundError: ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆ
        """
        if not os.path.exists(file_path):
            raise FileNotFoundError(f"Model file not found: {file_path}")

        with open(file_path, 'rb') as f:
            self.model = pickle.load(f)
```

#### å®Ÿè·µä¾‹ï¼šCinema äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´

**examples/train_cinema.py**:

```python
"""Cinema èˆˆè¡Œåå…¥äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´ä¾‹"""
from sklearn.model_selection import train_test_split
from src.ml.cinema_predictor import CinemaPredictor


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    # äºˆæ¸¬å™¨ã®ä½œæˆ
    predictor = CinemaPredictor()
    print("CinemaPredictor ã‚’ä½œæˆã—ã¾ã—ãŸ")

    # ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ï¼ˆå¤–ã‚Œå€¤é™¤å¤–ã‚ã‚Šï¼‰
    X, y = predictor.load_data('data/cinema.csv', remove_outliers=True)
    print(f"ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ: {len(X)} ã‚µãƒ³ãƒ—ãƒ«")

    # è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã¨ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã«åˆ†å‰²
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=0
    )
    print(f"è¨“ç·´ãƒ‡ãƒ¼ã‚¿: {len(X_train)} ã‚µãƒ³ãƒ—ãƒ«")
    print(f"ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: {len(X_test)} ã‚µãƒ³ãƒ—ãƒ«")

    # ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´
    predictor.train(X_train, y_train)
    print("ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´ãŒå®Œäº†ã—ã¾ã—ãŸ")

    # ãƒ¢ãƒ‡ãƒ«ã®ä¿‚æ•°è¡¨ç¤º
    print("\n[ãƒ¢ãƒ‡ãƒ«ã®ä¿‚æ•°]")
    feature_names = ['SNS1', 'SNS2', 'actor', 'original']
    for name, coef in zip(feature_names, predictor.model.coef_):
        print(f"  {name}: {coef:.4f}")
    print(f"  åˆ‡ç‰‡: {predictor.model.intercept_:.4f}")

    # ãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡
    metrics = predictor.evaluate(X_test, y_test)
    print("\n[ãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡]")
    print(f"  æ±ºå®šä¿‚æ•°ï¼ˆRÂ²ï¼‰: {metrics['r2_score']:.4f}")
    print(f"  å¹³å‡çµ¶å¯¾èª¤å·®ï¼ˆMAEï¼‰: {metrics['mae']:.2f} ä¸‡å††")
    print(f"  å¹³å‡äºŒä¹—èª¤å·®å¹³æ–¹æ ¹ï¼ˆRMSEï¼‰: {metrics['rmse']:.2f} ä¸‡å††")

    # ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜
    predictor.save_model('model/cinema.pkl')
    print("\nãƒ¢ãƒ‡ãƒ«ã‚’ model/cinema.pkl ã«ä¿å­˜ã—ã¾ã—ãŸ")

    # äºˆæ¸¬ä¾‹
    print("\n[äºˆæ¸¬ä¾‹]")
    sample = X_test.iloc[:3]
    predictions = predictor.predict(sample)

    for i, (idx, row) in enumerate(sample.iterrows()):
        actual = y_test.iloc[i]
        predicted = predictions[i]
        error = abs(actual - predicted)

        print(f"\nã‚µãƒ³ãƒ—ãƒ« {i+1}:")
        print(f"  SNS1: {row['SNS1']:.0f}, SNS2: {row['SNS2']:.0f}")
        print(f"  actor: {row['actor']:.0f}, original: {row['original']}")
        print(f"  å®Ÿéš›ã®èˆˆè¡Œåå…¥: {actual:.0f} ä¸‡å††")
        print(f"  äºˆæ¸¬èˆˆè¡Œåå…¥: {predicted:.0f} ä¸‡å††")
        print(f"  èª¤å·®: {error:.0f} ä¸‡å††")


if __name__ == '__main__':
    main()
```

å®Ÿè¡Œä¾‹ï¼š

```bash
uv run python examples/train_cinema.py

# å‡ºåŠ›ä¾‹ï¼š
# CinemaPredictor ã‚’ä½œæˆã—ã¾ã—ãŸ
# ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ: 95 ã‚µãƒ³ãƒ—ãƒ«
# è¨“ç·´ãƒ‡ãƒ¼ã‚¿: 76 ã‚µãƒ³ãƒ—ãƒ«
# ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: 19 ã‚µãƒ³ãƒ—ãƒ«
# ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´ãŒå®Œäº†ã—ã¾ã—ãŸ
#
# [ãƒ¢ãƒ‡ãƒ«ã®ä¿‚æ•°]
#   SNS1: 2.3456
#   SNS2: 4.7823
#   actor: 1.2345
#   original: 234.5678
#   åˆ‡ç‰‡: 5432.1098
#
# [ãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡]
#   æ±ºå®šä¿‚æ•°ï¼ˆRÂ²ï¼‰: 0.8383
#   å¹³å‡çµ¶å¯¾èª¤å·®ï¼ˆMAEï¼‰: 206.83 ä¸‡å††
#   å¹³å‡äºŒä¹—èª¤å·®å¹³æ–¹æ ¹ï¼ˆRMSEï¼‰: 289.45 ä¸‡å††
#
# ãƒ¢ãƒ‡ãƒ«ã‚’ model/cinema.pkl ã«ä¿å­˜ã—ã¾ã—ãŸ
#
# [äºˆæ¸¬ä¾‹]
#
# ã‚µãƒ³ãƒ—ãƒ« 1:
#   SNS1: 150, SNS2: 700
#   actor: 300, original: 0
#   å®Ÿéš›ã®èˆˆè¡Œåå…¥: 11500 ä¸‡å††
#   äºˆæ¸¬èˆˆè¡Œåå…¥: 11324 ä¸‡å††
#   èª¤å·®: 176 ä¸‡å††
#
# ã‚µãƒ³ãƒ—ãƒ« 2:
#   SNS1: 200, SNS2: 850
#   actor: 350, original: 1
#   å®Ÿéš›ã®èˆˆè¡Œåå…¥: 12800 ä¸‡å††
#   äºˆæ¸¬èˆˆè¡Œåå…¥: 12967 ä¸‡å††
#   èª¤å·®: 167 ä¸‡å††
```

### ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ 3 ã®æŠ€è¡“çš„æˆæœ

#### å®Œæˆã—ãŸæ©Ÿèƒ½

- âœ… Cinema äºˆæ¸¬å™¨ã‚¯ãƒ©ã‚¹ã®å®Œå…¨å®Ÿè£…
- âœ… ç·šå½¢å›å¸°ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´æ©Ÿèƒ½
- âœ… å¤–ã‚Œå€¤æ¤œå‡ºã¨é™¤å¤–æ©Ÿèƒ½
- âœ… è¤‡æ•°ã®è©•ä¾¡æŒ‡æ¨™ï¼ˆRÂ²ã€MAEã€RMSEï¼‰
- âœ… ãƒ‡ãƒ¼ã‚¿ã®æ¬ æå€¤å‡¦ç†
- âœ… ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜ã¨èª­ã¿è¾¼ã¿æ©Ÿèƒ½

#### å®šé‡çš„æˆæœ

| æŒ‡æ¨™ | å®Ÿç¸¾ |
|------|------|
| **ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹** | 20å€‹ |
| **ã‚³ãƒ¼ãƒ‰ã‚«ãƒãƒ¬ãƒƒã‚¸** | 92%ï¼ˆcinema_predictor.pyï¼‰ |
| **å‹ãƒ’ãƒ³ãƒˆä½¿ç”¨ç‡** | 100% |
| **ãƒ¢ãƒ‡ãƒ«æ±ºå®šä¿‚æ•°** | 0.8383ï¼ˆãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ï¼‰ |
| **å¹³å‡çµ¶å¯¾èª¤å·®** | 206.83ä¸‡å†† |
| **Ruff ãƒã‚§ãƒƒã‚¯** | å…¨ã¦é€šé |
| **mypy ãƒã‚§ãƒƒã‚¯** | ã‚¨ãƒ©ãƒ¼ 0ä»¶ |

#### ç¿’å¾—ã—ãŸã‚¹ã‚­ãƒ«

**1. TDD ã‚¹ã‚­ãƒ«ï¼ˆå¿œç”¨ï¼‰**
- å¤–ã‚Œå€¤å‡¦ç†ã®ãƒ†ã‚¹ãƒˆé§†å‹•å®Ÿè£…
- è¤‡æ•°ã®è©•ä¾¡æŒ‡æ¨™ã®ãƒ†ã‚¹ãƒˆ
- æ•°å€¤è¨ˆç®—ã®ç²¾åº¦æ¤œè¨¼

**2. æ©Ÿæ¢°å­¦ç¿’ã‚¹ã‚­ãƒ«ï¼ˆå›å¸°ï¼‰**
- ç·šå½¢å›å¸°ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã®ç†è§£
- å¤–ã‚Œå€¤ã®æ¤œå‡ºã¨é™¤å¤–
- è¤‡æ•°ã®è©•ä¾¡æŒ‡æ¨™ã®ç†è§£ã¨ä½¿ã„åˆ†ã‘
- ãƒ¢ãƒ‡ãƒ«ä¿‚æ•°ã®è§£é‡ˆ

**3. ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚¹ã‚­ãƒ«ï¼ˆç™ºå±•ï¼‰**
- æ¡ä»¶ã«åŸºã¥ããƒ‡ãƒ¼ã‚¿ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
- æ¬ æå€¤ã®è£œå®Œ
- ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ‹ãƒ³ã‚°ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³

**4. çµ±è¨ˆã‚¹ã‚­ãƒ«**
- RÂ²ã‚¹ã‚³ã‚¢ã®æ„å‘³ç†è§£
- MAE ã¨ RMSE ã®é•ã„
- è©•ä¾¡æŒ‡æ¨™ã®é¸æŠåŸºæº–

#### ç·šå½¢å›å¸°ã®ç†è§£

**ç·šå½¢å›å¸°ã®æ•°å¼**:

```
y = Î²â‚€ + Î²â‚xâ‚ + Î²â‚‚xâ‚‚ + Î²â‚ƒxâ‚ƒ + Î²â‚„xâ‚„

where:
  y: èˆˆè¡Œåå…¥ï¼ˆsalesï¼‰
  xâ‚: SNS1
  xâ‚‚: SNS2
  xâ‚ƒ: actor
  xâ‚„: original
  Î²â‚€: åˆ‡ç‰‡ï¼ˆinterceptï¼‰
  Î²â‚, Î²â‚‚, Î²â‚ƒ, Î²â‚„: å„ç‰¹å¾´é‡ã®ä¿‚æ•°ï¼ˆcoefficientsï¼‰
```

**ä¿‚æ•°ã®è§£é‡ˆ**:

```python
# SNS2 ã®ä¿‚æ•°ãŒ 4.78 ã®å ´åˆ
# â†’ SNS2 ãŒ 1 å¢—ãˆã‚‹ã¨ã€èˆˆè¡Œåå…¥ãŒç´„ 4.78 ä¸‡å††å¢—åŠ ã™ã‚‹ã¨äºˆæ¸¬
```

#### åˆ†é¡ã¨å›å¸°ã®å®Ÿè£…æ¯”è¼ƒ

| é …ç›® | Irisï¼ˆåˆ†é¡ï¼‰ | Cinemaï¼ˆå›å¸°ï¼‰ |
|------|-------------|---------------|
| **ãƒ¢ãƒ‡ãƒ«** | DecisionTreeClassifier | LinearRegression |
| **å‡ºåŠ›** | ã‚¯ãƒ©ã‚¹ãƒ©ãƒ™ãƒ«ï¼ˆæ–‡å­—åˆ—ï¼‰ | é€£ç¶šå€¤ï¼ˆfloatï¼‰ |
| **è©•ä¾¡** | accuracyï¼ˆæ­£è§£ç‡ï¼‰ | RÂ²ã€MAEã€RMSE |
| **å‰å‡¦ç†** | æ¬ æå€¤è£œå®Œ | æ¬ æå€¤è£œå®Œ + å¤–ã‚Œå€¤é™¤å¤– |
| **ãƒ†ã‚¹ãƒˆæ•°** | 18å€‹ | 20å€‹ |

#### æ¬¡ã®ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã¸ã®æº–å‚™

ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ 4 ã§ã¯ã€ä»¥ä¸‹ã‚’å®Ÿè£…ã—ã¾ã™ï¼š

- Survived ç”Ÿå­˜äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ï¼ˆå®Ÿè·µçš„ãªåˆ†é¡å•é¡Œï¼‰
- é«˜åº¦ãªæ¬ æå€¤å‡¦ç†ï¼ˆã‚°ãƒ«ãƒ¼ãƒ—åˆ¥è£œå®Œï¼‰
- ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å¤‰æ•°ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°
- ã‚¯ãƒ©ã‚¹ä¸å‡è¡¡ã¸ã®å¯¾å¿œ

---

## ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ 4: å®Ÿè·µçš„ãªåˆ†é¡å•é¡Œ

### 6ç«  Survived ç”Ÿå­˜äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«

#### æ¦‚è¦ã¨å­¦ç¿’ç›®æ¨™

ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ 4 ã§ã¯ã€å®¢èˆ¹æ²ˆæ²¡äº‹æ•…ã®ä¹—å®¢ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ç”Ÿå­˜ã‚’äºˆæ¸¬ã™ã‚‹å®Ÿè·µçš„ãªåˆ†é¡å•é¡Œã«å–ã‚Šçµ„ã¿ã¾ã™ã€‚Iris åˆ†é¡ã‚ˆã‚Šã‚‚è¤‡é›‘ãªãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ãŒå¿…è¦ã¨ãªã‚Šã€å®Ÿå‹™ã§ã‚ˆãé­é‡ã™ã‚‹èª²é¡Œã‚’ä½“é¨“ã§ãã¾ã™ã€‚

##### å­¦ç¿’ç›®æ¨™

1. **é«˜åº¦ãªãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†**: ã‚°ãƒ«ãƒ¼ãƒ—åˆ¥çµ±è¨ˆã«ã‚ˆã‚‹æ¬ æå€¤è£œå®Œ
2. **ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å¤‰æ•°ã®å‡¦ç†**: ãƒ€ãƒŸãƒ¼å¤‰æ•°åŒ–ã¨å¤šé‡å…±ç·šæ€§ã®å›é¿
3. **ã‚¯ãƒ©ã‚¹ä¸å‡è¡¡ã¸ã®å¯¾å¿œ**: class_weight ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã«ã‚ˆã‚‹èª¿æ•´
4. **TDD ã®å¿œç”¨**: è¤‡é›‘ãªå‰å‡¦ç†ãƒ­ã‚¸ãƒƒã‚¯ã®ãƒ†ã‚¹ãƒˆé§†å‹•å®Ÿè£…

#### Survived ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ç†è§£

##### ãƒ‡ãƒ¼ã‚¿è©³ç´°

`data/Survived.csv` ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚

| åˆ—å | å†…å®¹ | ãƒ‡ãƒ¼ã‚¿å‹ | ç‰¹å¾´ |
|------|------|----------|------|
| Pclass | ãƒã‚±ãƒƒãƒˆã‚¯ãƒ©ã‚¹ï¼ˆ1, 2, 3ï¼‰ | int | ç¤¾ä¼šéšç´šã‚’è¡¨ã™ |
| Age | å¹´é½¢ | float | **æ¬ æå€¤ã‚ã‚Š** |
| SibSp | åŒä¹—ã—ãŸå…„å¼Ÿã‚„é…å¶è€…ã®ç·æ•° | int | å®¶æ—æ§‹æˆæƒ…å ± |
| Parch | åŒä¹—ã—ãŸè¦ªå­ã®ç·æ•° | int | å®¶æ—æ§‹æˆæƒ…å ± |
| Fare | é‹è³ƒ | float | æ”¯æ‰•ã£ãŸé‡‘é¡ |
| Sex | æ€§åˆ¥ | str | **ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å¤‰æ•°** |
| Survived | ç”Ÿå­˜çŠ¶æ³ï¼ˆ1:ç”Ÿå­˜, 0:æ­»äº¡ï¼‰ | int | **ç›®çš„å¤‰æ•°** |

##### Iris/Cinema ã¨ã®é•ã„

| ç‰¹å¾´ | Iris | Cinema | **Survived** |
|------|------|--------|-------------|
| **å•é¡Œã®ç¨®é¡** | åˆ†é¡ï¼ˆ3ã‚¯ãƒ©ã‚¹ï¼‰ | å›å¸° | **åˆ†é¡ï¼ˆ2ã‚¯ãƒ©ã‚¹ï¼‰** |
| **æ¬ æå€¤å‡¦ç†** | å¹³å‡å€¤è£œå®Œ | å¹³å‡å€¤è£œå®Œ | **ã‚°ãƒ«ãƒ¼ãƒ—åˆ¥ä¸­å¤®å€¤è£œå®Œ** |
| **ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å¤‰æ•°** | ãªã— | ãªã— | **ã‚ã‚Šï¼ˆSexï¼‰** |
| **ã‚¯ãƒ©ã‚¹ä¸å‡è¡¡** | ãªã— | N/A | **ã‚ã‚Šï¼ˆç”Ÿå­˜è€…ãŒå°‘ãªã„ï¼‰** |
| **ç‰¹å¾´é‡æ•°** | 4å€‹ | 4å€‹ | **6å€‹** |
| **å‰å‡¦ç†ã®è¤‡é›‘åº¦** | ä½ | ä¸­ | **é«˜** |

##### å•é¡Œã®è¤‡é›‘æ€§

**1. æ¬ æå€¤ã®æˆ¦ç•¥çš„è£œå®Œ**

å˜ç´”ãªå¹³å‡å€¤è£œå®Œã§ã¯ãªãã€Pclassï¼ˆç¤¾ä¼šéšç´šï¼‰ã¨ Survivedï¼ˆç”Ÿå­˜çŠ¶æ³ï¼‰ã®ã‚°ãƒ«ãƒ¼ãƒ—ã”ã¨ã«ä¸­å¤®å€¤ã§è£œå®Œã—ã¾ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€ã‚ˆã‚Šæ­£ç¢ºãªãƒ‡ãƒ¼ã‚¿å¾©å…ƒãŒå¯èƒ½ã«ãªã‚Šã¾ã™ã€‚

```python
# ä¾‹ï¼š1ç­‰å®¢å®¤ã®ç”Ÿå­˜è€…ã®å¹³å‡å¹´é½¢ã¯35æ­³ã€æ­»äº¡è€…ã¯43æ­³
# â†’ ã‚°ãƒ«ãƒ¼ãƒ—ã”ã¨ã®å‚¾å‘ã‚’åæ˜ ã—ãŸè£œå®Œ
```

**2. ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å¤‰æ•°ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°**

Sexï¼ˆmale/femaleï¼‰ã¨ã„ã†æ–‡å­—åˆ—ãƒ‡ãƒ¼ã‚¿ã‚’ã€æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ãŒæ‰±ãˆã‚‹æ•°å€¤ãƒ‡ãƒ¼ã‚¿ã«å¤‰æ›ã™ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚

```python
# å¤‰æ›å‰: Sex = ['male', 'female', 'male']
# å¤‰æ›å¾Œ: male = [1, 0, 1]ï¼ˆ0/1 ã®ãƒ€ãƒŸãƒ¼å¤‰æ•°ï¼‰
```

**3. ã‚¯ãƒ©ã‚¹ä¸å‡è¡¡ã¸ã®å¯¾å¿œ**

ç”Ÿå­˜è€…ã¨æ­»äº¡è€…ã®å‰²åˆãŒä¸å‡è¡¡ãªå ´åˆã€å˜ç´”ãªè¨“ç·´ã§ã¯å¤šæ•°æ´¾ã‚¯ãƒ©ã‚¹ã«åã£ãŸãƒ¢ãƒ‡ãƒ«ã«ãªã‚Šã¾ã™ã€‚`class_weight='balanced'` ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§è‡ªå‹•çš„ã«èª¿æ•´ã—ã¾ã™ã€‚

#### TDD ã«ã‚ˆã‚‹å®Ÿè£…ï¼ˆ6ã‚¹ãƒ†ãƒƒãƒ—ï¼‰

##### ã‚¹ãƒ†ãƒƒãƒ— 1: åˆæœŸåŒ–ã¨ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿

**Red: ãƒ†ã‚¹ãƒˆã‚’æ›¸ã**

**test/test_survived_classifier.py**:

```python
"""Survived åˆ†é¡å™¨ã®ãƒ†ã‚¹ãƒˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«"""
import os
import tempfile
import pytest
import pandas as pd
import numpy as np
from src.ml.survived_classifier import SurvivedClassifier


class TestSurvivedClassifierInit:
    """åˆæœŸåŒ–ã®ãƒ†ã‚¹ãƒˆ"""

    def test_åˆæœŸåŒ–_ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿(self):
        """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§åˆæœŸåŒ–ã§ãã‚‹ã“ã¨ã‚’ç¢ºèª"""
        classifier = SurvivedClassifier()

        assert classifier.max_depth == 9
        assert classifier.class_weight == 'balanced'
        assert classifier.model is None

    def test_åˆæœŸåŒ–_ã‚«ã‚¹ã‚¿ãƒ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿(self):
        """ã‚«ã‚¹ã‚¿ãƒ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã§åˆæœŸåŒ–ã§ãã‚‹ã“ã¨ã‚’ç¢ºèª"""
        classifier = SurvivedClassifier(max_depth=5, class_weight='balanced')

        assert classifier.max_depth == 5
        assert classifier.class_weight == 'balanced'

    def test_max_depthãŒä¸æ­£ãªå€¤ã®å ´åˆã‚¨ãƒ©ãƒ¼(self):
        """max_depth ãŒ 1 æœªæº€ã®å ´åˆã¯ ValueError ã‚’ç™ºç”Ÿ"""
        with pytest.raises(ValueError, match="max_depth must be at least 1"):
            SurvivedClassifier(max_depth=0)


class TestSurvivedClassifierLoadData:
    """ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã®ãƒ†ã‚¹ãƒˆ"""

    def test_CSVãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿(self):
        """CSV ãƒ•ã‚¡ã‚¤ãƒ«ãŒæ­£å¸¸ã«èª­ã¿è¾¼ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª"""
        classifier = SurvivedClassifier()

        # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ä½œæˆ
        test_data = """Pclass,Age,SibSp,Parch,Fare,Sex,Survived
1,22.0,1,0,7.25,male,0
2,38.0,1,0,71.28,female,1
3,26.0,0,0,7.92,male,0"""

        with tempfile.NamedTemporaryFile(mode='w', delete=False, suffix='.csv') as f:
            f.write(test_data)
            temp_path = f.name

        try:
            X, y = classifier.load_data(temp_path, preprocess=False)

            # ãƒ‡ãƒ¼ã‚¿ãŒæ­£ã—ãèª­ã¿è¾¼ã¾ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
            assert len(X) == 3
            assert len(y) == 3
            assert 'Survived' not in X.columns
            assert y.name == 'Survived'
        finally:
            os.unlink(temp_path)

    def test_ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆã‚¨ãƒ©ãƒ¼(self):
        """å­˜åœ¨ã—ãªã„ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’æŒ‡å®šã—ãŸå ´åˆ FileNotFoundError ã‚’ç™ºç”Ÿ"""
        classifier = SurvivedClassifier()

        with pytest.raises(FileNotFoundError):
            classifier.load_data('nonexistent.csv')

    def test_å¿…è¦ãªåˆ—ãŒä¸è¶³ã—ã¦ã„ã‚‹å ´åˆã‚¨ãƒ©ãƒ¼(self):
        """å¿…è¦ãªåˆ—ãŒä¸è¶³ã—ã¦ã„ã‚‹å ´åˆ ValueError ã‚’ç™ºç”Ÿ"""
        classifier = SurvivedClassifier()

        # Survived åˆ—ãŒæ¬ ã‘ã¦ã„ã‚‹ãƒ‡ãƒ¼ã‚¿
        test_data = """Pclass,Age,Sex
1,22.0,male"""

        with tempfile.NamedTemporaryFile(mode='w', delete=False, suffix='.csv') as f:
            f.write(test_data)
            temp_path = f.name

        try:
            with pytest.raises(ValueError, match="Missing columns"):
                classifier.load_data(temp_path, preprocess=False)
        finally:
            os.unlink(temp_path)
```

**Green: æœ€å°é™ã®å®Ÿè£…**

**src/ml/survived_classifier.py**:

```python
"""Survived ç”Ÿå­˜äºˆæ¸¬å™¨ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«"""
import os
from typing import Optional, Tuple
import pandas as pd
import numpy as np
from sklearn import tree


class SurvivedClassifier:
    """å®¢èˆ¹æ²ˆæ²¡äº‹æ•…ã®ç”Ÿå­˜ã‚’äºˆæ¸¬ã™ã‚‹åˆ†é¡ãƒ¢ãƒ‡ãƒ«

    Attributes:
        max_depth: æ±ºå®šæœ¨ã®æœ€å¤§æ·±åº¦
        class_weight: ã‚¯ãƒ©ã‚¹ã®é‡ã¿ä»˜ã‘ï¼ˆ'balanced' ã§è‡ªå‹•èª¿æ•´ï¼‰
        model: è¨“ç·´æ¸ˆã¿ã®æ±ºå®šæœ¨ãƒ¢ãƒ‡ãƒ«ï¼ˆæœªè¨“ç·´æ™‚ã¯ Noneï¼‰
    """

    def __init__(self, max_depth: int = 9, class_weight: str = 'balanced') -> None:
        """åˆæœŸåŒ–

        Args:
            max_depth: æ±ºå®šæœ¨ã®æœ€å¤§æ·±åº¦ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 9ï¼‰
            class_weight: ã‚¯ãƒ©ã‚¹é‡ã¿ä»˜ã‘æ–¹æ³•ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 'balanced'ï¼‰

        Raises:
            ValueError: max_depth ãŒ 1 æœªæº€ã®å ´åˆ
        """
        if max_depth < 1:
            raise ValueError("max_depth must be at least 1")

        self.max_depth = max_depth
        self.class_weight = class_weight
        self.model: Optional[tree.DecisionTreeClassifier] = None

    def load_data(self, file_path: str,
                  preprocess: bool = True) -> Tuple[pd.DataFrame, pd.Series]:
        """CSV ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€

        Args:
            file_path: CSV ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
            preprocess: å‰å‡¦ç†ã‚’å®Ÿè¡Œã™ã‚‹ã‹ã©ã†ã‹ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: Trueï¼‰

        Returns:
            ç‰¹å¾´é‡ DataFrame ã¨ç›®çš„å¤‰æ•° Series ã®ã‚¿ãƒ—ãƒ«

        Raises:
            FileNotFoundError: ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆ
            ValueError: å¿…è¦ãªåˆ—ãŒä¸è¶³ã—ã¦ã„ã‚‹å ´åˆ
        """
        if not os.path.exists(file_path):
            raise FileNotFoundError(f"File not found: {file_path}")

        # ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
        df = pd.read_csv(file_path)

        # å¿…è¦ãªåˆ—ã®å­˜åœ¨ç¢ºèª
        required_columns = ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'Sex', 'Survived']
        missing_columns = set(required_columns) - set(df.columns)
        if missing_columns:
            raise ValueError(f"Missing columns: {missing_columns}")

        # å‰å‡¦ç†ã®å®Ÿè¡Œï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        if preprocess:
            df = self._preprocess_data(df)

        # ç‰¹å¾´é‡ã¨ç›®çš„å¤‰æ•°ã®åˆ†å‰²
        feature_columns = ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'male']
        if not preprocess:
            # å‰å‡¦ç†ãªã—ã®å ´åˆã€Sex åˆ—ã‚’ãã®ã¾ã¾ä½¿ã†ï¼ˆãƒ†ã‚¹ãƒˆç”¨ï¼‰
            feature_columns = ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'Sex']

        X = df[feature_columns]
        y = df['Survived']

        return X, y

    def _preprocess_data(self, df: pd.DataFrame) -> pd.DataFrame:
        """ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†ï¼ˆå†…éƒ¨ãƒ¡ã‚½ãƒƒãƒ‰ï¼‰

        Args:
            df: å…ƒã® DataFrame

        Returns:
            å‰å‡¦ç†æ¸ˆã¿ã® DataFrame
        """
        # ã‚¹ãƒ†ãƒƒãƒ— 2 ã¨ 3 ã§å®Ÿè£…
        df = self._preprocess_age(df)
        df = self._encode_categorical(df)
        return df

    def _preprocess_age(self, df: pd.DataFrame) -> pd.DataFrame:
        """Age ã®æ¬ æå€¤ã‚’ã‚°ãƒ«ãƒ¼ãƒ—åˆ¥ä¸­å¤®å€¤ã§è£œå®Œï¼ˆã‚¹ãƒ†ãƒƒãƒ— 2 ã§å®Ÿè£…ï¼‰"""
        return df

    def _encode_categorical(self, df: pd.DataFrame) -> pd.DataFrame:
        """Sex ã‚’ãƒ€ãƒŸãƒ¼å¤‰æ•°ã«å¤‰æ›ï¼ˆã‚¹ãƒ†ãƒƒãƒ— 3 ã§å®Ÿè£…ï¼‰"""
        return df
```

##### ã‚¹ãƒ†ãƒƒãƒ— 2: ã‚°ãƒ«ãƒ¼ãƒ—åˆ¥æ¬ æå€¤è£œå®Œ

é«˜åº¦ãªæ¬ æå€¤å‡¦ç†ã‚’ TDD ã§å®Ÿè£…ã—ã¾ã™ã€‚

**Red: ãƒ†ã‚¹ãƒˆã‚’æ›¸ã**

```python
class TestSurvivedClassifierPreprocessAge:
    """Age æ¬ æå€¤è£œå®Œã®ãƒ†ã‚¹ãƒˆ"""

    def test_æ¬ æå€¤ãŒãªã„å ´åˆã¯å¤‰æ›´ãªã—(self):
        """æ¬ æå€¤ãŒãªã„å ´åˆã¯ãƒ‡ãƒ¼ã‚¿ã‚’å¤‰æ›´ã—ãªã„ã“ã¨ã‚’ç¢ºèª"""
        classifier = SurvivedClassifier()

        df = pd.DataFrame({
            'Pclass': [1, 2, 3],
            'Age': [22.0, 38.0, 26.0],
            'Survived': [0, 1, 0]
        })

        df_processed = classifier._preprocess_age(df.copy())

        pd.testing.assert_frame_equal(df_processed, df)

    def test_1ç­‰å®¢å®¤æ­»äº¡è€…ã®å¹´é½¢è£œå®Œ(self):
        """Pclass=1, Survived=0 ã®æ¬ æå€¤ãŒ 43 ã§è£œå®Œã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª"""
        classifier = SurvivedClassifier()

        df = pd.DataFrame({
            'Pclass': [1, 1],
            'Age': [np.nan, 50.0],
            'Survived': [0, 0]
        })

        df_processed = classifier._preprocess_age(df)

        assert df_processed.iloc[0]['Age'] == 43
        assert df_processed.iloc[1]['Age'] == 50.0

    def test_1ç­‰å®¢å®¤ç”Ÿå­˜è€…ã®å¹´é½¢è£œå®Œ(self):
        """Pclass=1, Survived=1 ã®æ¬ æå€¤ãŒ 35 ã§è£œå®Œã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª"""
        classifier = SurvivedClassifier()

        df = pd.DataFrame({
            'Pclass': [1],
            'Age': [np.nan],
            'Survived': [1]
        })

        df_processed = classifier._preprocess_age(df)

        assert df_processed.iloc[0]['Age'] == 35

    def test_å…¨ã‚°ãƒ«ãƒ¼ãƒ—ã®å¹´é½¢è£œå®Œ(self):
        """å…¨ã‚°ãƒ«ãƒ¼ãƒ—ã®æ¬ æå€¤ãŒæ­£ã—ãè£œå®Œã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª"""
        classifier = SurvivedClassifier()

        # å„ã‚°ãƒ«ãƒ¼ãƒ—ã®çµ„ã¿åˆã‚ã›ã§æ¬ æå€¤ã‚’ä½œæˆ
        df = pd.DataFrame({
            'Pclass': [1, 1, 2, 2, 3, 3],
            'Age': [np.nan, np.nan, np.nan, np.nan, np.nan, np.nan],
            'Survived': [0, 1, 0, 1, 0, 1]
        })

        df_processed = classifier._preprocess_age(df)

        # ã‚°ãƒ«ãƒ¼ãƒ—åˆ¥ã®æœŸå¾…å€¤
        expected_ages = [43, 35, 33, 25, 26, 20]
        actual_ages = df_processed['Age'].tolist()

        assert actual_ages == expected_ages

    def test_ä¸€éƒ¨ã®ã¿æ¬ æå€¤ãŒã‚ã‚‹å ´åˆ(self):
        """ä¸€éƒ¨ã ã‘æ¬ æå€¤ãŒã‚ã‚‹å ´åˆã€è©²å½“ãƒ‡ãƒ¼ã‚¿ã®ã¿è£œå®Œã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª"""
        classifier = SurvivedClassifier()

        df = pd.DataFrame({
            'Pclass': [1, 1, 2, 2],
            'Age': [np.nan, 30.0, 25.0, np.nan],
            'Survived': [0, 1, 0, 1]
        })

        df_processed = classifier._preprocess_age(df)

        assert df_processed.iloc[0]['Age'] == 43  # è£œå®Œ
        assert df_processed.iloc[1]['Age'] == 30.0  # å…ƒã®ã¾ã¾
        assert df_processed.iloc[2]['Age'] == 25.0  # å…ƒã®ã¾ã¾
        assert df_processed.iloc[3]['Age'] == 25  # è£œå®Œ
```

**Green: å®Ÿè£…**

```python
def _preprocess_age(self, df: pd.DataFrame) -> pd.DataFrame:
    """Age ã®æ¬ æå€¤ã‚’ Pclass ã¨ Survived ã®ã‚°ãƒ«ãƒ¼ãƒ—åˆ¥ä¸­å¤®å€¤ã§è£œå®Œ

    Args:
        df: å…ƒã® DataFrame

    Returns:
        Age ã®æ¬ æå€¤ãŒè£œå®Œã•ã‚ŒãŸ DataFrame

    Note:
        å„ã‚°ãƒ«ãƒ¼ãƒ—ã®ä¸­å¤®å€¤ã¯å®Ÿãƒ‡ãƒ¼ã‚¿åˆ†æã«ã‚ˆã‚Šæ±ºå®šï¼š
        - (Pclass=1, Survived=0): 43æ­³
        - (Pclass=1, Survived=1): 35æ­³
        - (Pclass=2, Survived=0): 33æ­³
        - (Pclass=2, Survived=1): 25æ­³
        - (Pclass=3, Survived=0): 26æ­³
        - (Pclass=3, Survived=1): 20æ­³
    """
    df_copy = df.copy()
    is_null = df_copy['Age'].isnull()

    # ã‚°ãƒ«ãƒ¼ãƒ—åˆ¥ã®ä¸­å¤®å€¤ãƒãƒƒãƒ”ãƒ³ã‚°
    age_mapping = {
        (1, 0): 43, (1, 1): 35,
        (2, 0): 33, (2, 1): 25,
        (3, 0): 26, (3, 1): 20
    }

    # å„ã‚°ãƒ«ãƒ¼ãƒ—ã®æ¬ æå€¤ã‚’ä¸­å¤®å€¤ã§è£œå®Œ
    for (pclass, survived), median_age in age_mapping.items():
        mask = (df_copy['Pclass'] == pclass) & \
               (df_copy['Survived'] == survived) & is_null
        df_copy.loc[mask, 'Age'] = median_age

    return df_copy
```

##### ã‚¹ãƒ†ãƒƒãƒ— 3: ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å¤‰æ•°ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°

Sexï¼ˆmale/femaleï¼‰ã‚’ãƒ€ãƒŸãƒ¼å¤‰æ•°ã«å¤‰æ›ã—ã¾ã™ã€‚

**Red: ãƒ†ã‚¹ãƒˆã‚’æ›¸ã**

```python
class TestSurvivedClassifierEncodeCategorical:
    """ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å¤‰æ•°ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã®ãƒ†ã‚¹ãƒˆ"""

    def test_Sexåˆ—ãŒmaleåˆ—ã«å¤‰æ›ã•ã‚Œã‚‹(self):
        """Sex åˆ—ãŒ male ãƒ€ãƒŸãƒ¼å¤‰æ•°ã«å¤‰æ›ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª"""
        classifier = SurvivedClassifier()

        df = pd.DataFrame({
            'Pclass': [1, 2, 3],
            'Sex': ['male', 'female', 'male'],
            'Survived': [0, 1, 0]
        })

        df_encoded = classifier._encode_categorical(df)

        assert 'male' in df_encoded.columns
        assert 'Sex' not in df_encoded.columns

    def test_maleåˆ—ã®å€¤ãŒæ­£ã—ã„(self):
        """male åˆ—ã®å€¤ãŒæ­£ã—ã„ã“ã¨ã‚’ç¢ºèªï¼ˆmale=1, female=0ï¼‰"""
        classifier = SurvivedClassifier()

        df = pd.DataFrame({
            'Sex': ['male', 'female', 'male', 'female']
        })

        df_encoded = classifier._encode_categorical(df)

        expected_male_values = [1, 0, 1, 0]
        actual_male_values = df_encoded['male'].tolist()

        assert actual_male_values == expected_male_values

    def test_ä»–ã®åˆ—ã¯ä¿æŒã•ã‚Œã‚‹(self):
        """Sex ä»¥å¤–ã®åˆ—ã¯ä¿æŒã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª"""
        classifier = SurvivedClassifier()

        df = pd.DataFrame({
            'Pclass': [1, 2],
            'Age': [22.0, 38.0],
            'Sex': ['male', 'female'],
            'Survived': [0, 1]
        })

        df_encoded = classifier._encode_categorical(df)

        assert 'Pclass' in df_encoded.columns
        assert 'Age' in df_encoded.columns
        assert 'Survived' in df_encoded.columns
        assert df_encoded['Pclass'].tolist() == [1, 2]
        assert df_encoded['Age'].tolist() == [22.0, 38.0]
```

**Green: å®Ÿè£…**

```python
def _encode_categorical(self, df: pd.DataFrame) -> pd.DataFrame:
    """Sex ã‚’ãƒ€ãƒŸãƒ¼å¤‰æ•°ã«å¤‰æ›

    Args:
        df: å…ƒã® DataFrame

    Returns:
        Sex ãŒãƒ€ãƒŸãƒ¼å¤‰æ•°åŒ–ã•ã‚ŒãŸ DataFrame

    Note:
        drop_first=True ã«ã‚ˆã‚Šã€male åˆ—ã®ã¿ä½œæˆï¼ˆfemale ã¯ 0/1 ã§è¡¨ç¾ï¼‰
        ã“ã‚Œã«ã‚ˆã‚Šå¤šé‡å…±ç·šæ€§ã‚’å›é¿
    """
    df_copy = df.copy()

    # Sex ã‚’ãƒ€ãƒŸãƒ¼å¤‰æ•°åŒ–ï¼ˆdrop_first=True ã§ male åˆ—ã®ã¿ä½œæˆï¼‰
    male = pd.get_dummies(df_copy['Sex'], drop_first=True, dtype=int)
    df_encoded = pd.concat([df_copy.drop('Sex', axis=1), male], axis=1)

    return df_encoded
```

##### ã‚¹ãƒ†ãƒƒãƒ— 4: ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´ï¼ˆclass_weight å¯¾å¿œï¼‰

ã‚¯ãƒ©ã‚¹ä¸å‡è¡¡ã«å¯¾å¿œã—ãŸè¨“ç·´ã‚’å®Ÿè£…ã—ã¾ã™ã€‚

**Red: ãƒ†ã‚¹ãƒˆã‚’æ›¸ã**

```python
class TestSurvivedClassifierTrain:
    """è¨“ç·´ã®ãƒ†ã‚¹ãƒˆ"""

    def test_ãƒ¢ãƒ‡ãƒ«ãŒè¨“ç·´ã•ã‚Œã‚‹(self):
        """è¨“ç·´å¾Œã«ãƒ¢ãƒ‡ãƒ«ãŒè¨­å®šã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª"""
        classifier = SurvivedClassifier()

        # ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿
        X_train = pd.DataFrame({
            'Pclass': [1, 2, 3],
            'Age': [22.0, 38.0, 26.0],
            'SibSp': [1, 1, 0],
            'Parch': [0, 0, 0],
            'Fare': [7.25, 71.28, 7.92],
            'male': [1, 0, 1]
        })
        y_train = pd.Series([0, 1, 0])

        classifier.train(X_train, y_train)

        assert classifier.model is not None

    def test_è¨“ç·´ã•ã‚Œã¦ã„ãªã„çŠ¶æ…‹ã§äºˆæ¸¬ã™ã‚‹ã¨ã‚¨ãƒ©ãƒ¼(self):
        """è¨“ç·´å‰ã«äºˆæ¸¬ã—ã‚ˆã†ã¨ã™ã‚‹ã¨ RuntimeError ã‚’ç™ºç”Ÿ"""
        classifier = SurvivedClassifier()

        X_test = pd.DataFrame({'Pclass': [1], 'Age': [22.0],
                               'SibSp': [1], 'Parch': [0],
                               'Fare': [7.25], 'male': [1]})

        with pytest.raises(RuntimeError, match="Model has not been trained yet"):
            classifier.predict(X_test)

    def test_class_weightãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒé©ç”¨ã•ã‚Œã‚‹(self):
        """class_weight ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒãƒ¢ãƒ‡ãƒ«ã«é©ç”¨ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª"""
        classifier = SurvivedClassifier(class_weight='balanced')

        X_train = pd.DataFrame({
            'Pclass': [1, 2, 3],
            'Age': [22.0, 38.0, 26.0],
            'SibSp': [1, 1, 0],
            'Parch': [0, 0, 0],
            'Fare': [7.25, 71.28, 7.92],
            'male': [1, 0, 1]
        })
        y_train = pd.Series([0, 1, 0])

        classifier.train(X_train, y_train)

        assert classifier.model.class_weight == 'balanced'

    def test_max_depthãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒé©ç”¨ã•ã‚Œã‚‹(self):
        """max_depth ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ãŒãƒ¢ãƒ‡ãƒ«ã«é©ç”¨ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª"""
        classifier = SurvivedClassifier(max_depth=5)

        X_train = pd.DataFrame({
            'Pclass': [1, 2, 3],
            'Age': [22.0, 38.0, 26.0],
            'SibSp': [1, 1, 0],
            'Parch': [0, 0, 0],
            'Fare': [7.25, 71.28, 7.92],
            'male': [1, 0, 1]
        })
        y_train = pd.Series([0, 1, 0])

        classifier.train(X_train, y_train)

        assert classifier.model.max_depth == 5
```

**Green: å®Ÿè£…**

```python
def train(self, X_train: pd.DataFrame, y_train: pd.Series) -> None:
    """ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã™ã‚‹

    Args:
        X_train: è¨“ç·´ç”¨ç‰¹å¾´é‡
        y_train: è¨“ç·´ç”¨ç›®çš„å¤‰æ•°

    Note:
        class_weight='balanced' ã«ã‚ˆã‚Šã€ã‚¯ãƒ©ã‚¹ä¸å‡è¡¡ã‚’è‡ªå‹•çš„ã«èª¿æ•´
    """
    self.model = tree.DecisionTreeClassifier(
        max_depth=self.max_depth,
        random_state=0,
        class_weight=self.class_weight
    )
    self.model.fit(X_train, y_train)
```

##### ã‚¹ãƒ†ãƒƒãƒ— 5: äºˆæ¸¬ã¨è©•ä¾¡

```python
def predict(self, X_test: pd.DataFrame) -> np.ndarray:
    """äºˆæ¸¬ã‚’å®Ÿè¡Œã™ã‚‹

    Args:
        X_test: ãƒ†ã‚¹ãƒˆç”¨ç‰¹å¾´é‡

    Returns:
        äºˆæ¸¬çµæœã®é…åˆ—

    Raises:
        RuntimeError: ãƒ¢ãƒ‡ãƒ«ãŒè¨“ç·´ã•ã‚Œã¦ã„ãªã„å ´åˆ
    """
    if self.model is None:
        raise RuntimeError("Model has not been trained yet. Call train() first.")

    return self.model.predict(X_test)

def evaluate(self, X_test: pd.DataFrame, y_test: pd.Series) -> float:
    """ãƒ¢ãƒ‡ãƒ«ã‚’è©•ä¾¡ã™ã‚‹

    Args:
        X_test: ãƒ†ã‚¹ãƒˆç”¨ç‰¹å¾´é‡
        y_test: ãƒ†ã‚¹ãƒˆç”¨ç›®çš„å¤‰æ•°

    Returns:
        æ­£è§£ç‡ï¼ˆaccuracyï¼‰

    Raises:
        RuntimeError: ãƒ¢ãƒ‡ãƒ«ãŒè¨“ç·´ã•ã‚Œã¦ã„ãªã„å ´åˆ
    """
    if self.model is None:
        raise RuntimeError("Model has not been trained yet. Call train() first.")

    return self.model.score(X_test, y_test)
```

##### ã‚¹ãƒ†ãƒƒãƒ— 6: ãƒ¢ãƒ‡ãƒ«ã®æ°¸ç¶šåŒ–

```python
import pickle

def save_model(self, file_path: str) -> None:
    """è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã™ã‚‹

    Args:
        file_path: ä¿å­˜å…ˆãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹

    Raises:
        RuntimeError: ãƒ¢ãƒ‡ãƒ«ãŒè¨“ç·´ã•ã‚Œã¦ã„ãªã„å ´åˆ
    """
    if self.model is None:
        raise RuntimeError("Model has not been trained yet. Call train() first.")

    with open(file_path, 'wb') as f:
        pickle.dump(self.model, f)

def load_model(self, file_path: str) -> None:
    """ä¿å­˜ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã‚€

    Args:
        file_path: ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹

    Raises:
        FileNotFoundError: ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆ
    """
    if not os.path.exists(file_path):
        raise FileNotFoundError(f"Model file not found: {file_path}")

    with open(file_path, 'rb') as f:
        self.model = pickle.load(f)
```

#### å®Œå…¨ãª SurvivedClassifier å®Ÿè£…

**src/ml/survived_classifier.py** (å®Œå…¨ç‰ˆ):

```python
"""Survived ç”Ÿå­˜äºˆæ¸¬å™¨ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«"""
import os
import pickle
from typing import Optional, Tuple
import pandas as pd
import numpy as np
from sklearn import tree


class SurvivedClassifier:
    """å®¢èˆ¹æ²ˆæ²¡äº‹æ•…ã®ç”Ÿå­˜ã‚’äºˆæ¸¬ã™ã‚‹åˆ†é¡ãƒ¢ãƒ‡ãƒ«

    Attributes:
        max_depth: æ±ºå®šæœ¨ã®æœ€å¤§æ·±åº¦
        class_weight: ã‚¯ãƒ©ã‚¹ã®é‡ã¿ä»˜ã‘ï¼ˆ'balanced' ã§è‡ªå‹•èª¿æ•´ï¼‰
        model: è¨“ç·´æ¸ˆã¿ã®æ±ºå®šæœ¨ãƒ¢ãƒ‡ãƒ«ï¼ˆæœªè¨“ç·´æ™‚ã¯ Noneï¼‰

    Example:
        >>> classifier = SurvivedClassifier()
        >>> X_train, y_train = classifier.load_data('data/Survived.csv')
        >>> from sklearn.model_selection import train_test_split
        >>> X_train, X_test, y_train, y_test = train_test_split(
        ...     X_train, y_train, test_size=0.2, random_state=0)
        >>> classifier.train(X_train, y_train)
        >>> accuracy = classifier.evaluate(X_test, y_test)
        >>> print(f"Accuracy: {accuracy:.4f}")
    """

    def __init__(self, max_depth: int = 9, class_weight: str = 'balanced') -> None:
        """åˆæœŸåŒ–

        Args:
            max_depth: æ±ºå®šæœ¨ã®æœ€å¤§æ·±åº¦ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 9ï¼‰
            class_weight: ã‚¯ãƒ©ã‚¹é‡ã¿ä»˜ã‘æ–¹æ³•ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 'balanced'ï¼‰

        Raises:
            ValueError: max_depth ãŒ 1 æœªæº€ã®å ´åˆ
        """
        if max_depth < 1:
            raise ValueError("max_depth must be at least 1")

        self.max_depth = max_depth
        self.class_weight = class_weight
        self.model: Optional[tree.DecisionTreeClassifier] = None

    def load_data(self, file_path: str,
                  preprocess: bool = True) -> Tuple[pd.DataFrame, pd.Series]:
        """CSV ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€

        Args:
            file_path: CSV ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
            preprocess: å‰å‡¦ç†ã‚’å®Ÿè¡Œã™ã‚‹ã‹ã©ã†ã‹ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: Trueï¼‰

        Returns:
            ç‰¹å¾´é‡ DataFrame ã¨ç›®çš„å¤‰æ•° Series ã®ã‚¿ãƒ—ãƒ«

        Raises:
            FileNotFoundError: ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆ
            ValueError: å¿…è¦ãªåˆ—ãŒä¸è¶³ã—ã¦ã„ã‚‹å ´åˆ
        """
        if not os.path.exists(file_path):
            raise FileNotFoundError(f"File not found: {file_path}")

        # ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
        df = pd.read_csv(file_path)

        # å¿…è¦ãªåˆ—ã®å­˜åœ¨ç¢ºèª
        required_columns = ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'Sex', 'Survived']
        missing_columns = set(required_columns) - set(df.columns)
        if missing_columns:
            raise ValueError(f"Missing columns: {missing_columns}")

        # å‰å‡¦ç†ã®å®Ÿè¡Œï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        if preprocess:
            df = self._preprocess_data(df)

        # ç‰¹å¾´é‡ã¨ç›®çš„å¤‰æ•°ã®åˆ†å‰²
        feature_columns = ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'male']
        if not preprocess:
            # å‰å‡¦ç†ãªã—ã®å ´åˆã€Sex åˆ—ã‚’ãã®ã¾ã¾ä½¿ã†ï¼ˆãƒ†ã‚¹ãƒˆç”¨ï¼‰
            feature_columns = ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'Sex']

        X = df[feature_columns]
        y = df['Survived']

        return X, y

    def _preprocess_data(self, df: pd.DataFrame) -> pd.DataFrame:
        """ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†ï¼ˆå†…éƒ¨ãƒ¡ã‚½ãƒƒãƒ‰ï¼‰

        Args:
            df: å…ƒã® DataFrame

        Returns:
            å‰å‡¦ç†æ¸ˆã¿ã® DataFrame
        """
        df = self._preprocess_age(df)
        df = self._encode_categorical(df)
        return df

    def _preprocess_age(self, df: pd.DataFrame) -> pd.DataFrame:
        """Age ã®æ¬ æå€¤ã‚’ Pclass ã¨ Survived ã®ã‚°ãƒ«ãƒ¼ãƒ—åˆ¥ä¸­å¤®å€¤ã§è£œå®Œ

        Args:
            df: å…ƒã® DataFrame

        Returns:
            Age ã®æ¬ æå€¤ãŒè£œå®Œã•ã‚ŒãŸ DataFrame

        Note:
            å„ã‚°ãƒ«ãƒ¼ãƒ—ã®ä¸­å¤®å€¤ã¯å®Ÿãƒ‡ãƒ¼ã‚¿åˆ†æã«ã‚ˆã‚Šæ±ºå®šï¼š
            - (Pclass=1, Survived=0): 43æ­³
            - (Pclass=1, Survived=1): 35æ­³
            - (Pclass=2, Survived=0): 33æ­³
            - (Pclass=2, Survived=1): 25æ­³
            - (Pclass=3, Survived=0): 26æ­³
            - (Pclass=3, Survived=1): 20æ­³
        """
        df_copy = df.copy()
        is_null = df_copy['Age'].isnull()

        # ã‚°ãƒ«ãƒ¼ãƒ—åˆ¥ã®ä¸­å¤®å€¤ãƒãƒƒãƒ”ãƒ³ã‚°
        age_mapping = {
            (1, 0): 43, (1, 1): 35,
            (2, 0): 33, (2, 1): 25,
            (3, 0): 26, (3, 1): 20
        }

        # å„ã‚°ãƒ«ãƒ¼ãƒ—ã®æ¬ æå€¤ã‚’ä¸­å¤®å€¤ã§è£œå®Œ
        for (pclass, survived), median_age in age_mapping.items():
            mask = (df_copy['Pclass'] == pclass) & \
                   (df_copy['Survived'] == survived) & is_null
            df_copy.loc[mask, 'Age'] = median_age

        return df_copy

    def _encode_categorical(self, df: pd.DataFrame) -> pd.DataFrame:
        """Sex ã‚’ãƒ€ãƒŸãƒ¼å¤‰æ•°ã«å¤‰æ›

        Args:
            df: å…ƒã® DataFrame

        Returns:
            Sex ãŒãƒ€ãƒŸãƒ¼å¤‰æ•°åŒ–ã•ã‚ŒãŸ DataFrame

        Note:
            drop_first=True ã«ã‚ˆã‚Šã€male åˆ—ã®ã¿ä½œæˆï¼ˆfemale ã¯ 0/1 ã§è¡¨ç¾ï¼‰
            ã“ã‚Œã«ã‚ˆã‚Šå¤šé‡å…±ç·šæ€§ã‚’å›é¿
        """
        df_copy = df.copy()

        # Sex ã‚’ãƒ€ãƒŸãƒ¼å¤‰æ•°åŒ–ï¼ˆdrop_first=True ã§ male åˆ—ã®ã¿ä½œæˆï¼‰
        male = pd.get_dummies(df_copy['Sex'], drop_first=True, dtype=int)
        df_encoded = pd.concat([df_copy.drop('Sex', axis=1), male], axis=1)

        return df_encoded

    def train(self, X_train: pd.DataFrame, y_train: pd.Series) -> None:
        """ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã™ã‚‹

        Args:
            X_train: è¨“ç·´ç”¨ç‰¹å¾´é‡
            y_train: è¨“ç·´ç”¨ç›®çš„å¤‰æ•°

        Note:
            class_weight='balanced' ã«ã‚ˆã‚Šã€ã‚¯ãƒ©ã‚¹ä¸å‡è¡¡ã‚’è‡ªå‹•çš„ã«èª¿æ•´
        """
        self.model = tree.DecisionTreeClassifier(
            max_depth=self.max_depth,
            random_state=0,
            class_weight=self.class_weight
        )
        self.model.fit(X_train, y_train)

    def predict(self, X_test: pd.DataFrame) -> np.ndarray:
        """äºˆæ¸¬ã‚’å®Ÿè¡Œã™ã‚‹

        Args:
            X_test: ãƒ†ã‚¹ãƒˆç”¨ç‰¹å¾´é‡

        Returns:
            äºˆæ¸¬çµæœã®é…åˆ—ï¼ˆ0: æ­»äº¡, 1: ç”Ÿå­˜ï¼‰

        Raises:
            RuntimeError: ãƒ¢ãƒ‡ãƒ«ãŒè¨“ç·´ã•ã‚Œã¦ã„ãªã„å ´åˆ
        """
        if self.model is None:
            raise RuntimeError("Model has not been trained yet. Call train() first.")

        return self.model.predict(X_test)

    def evaluate(self, X_test: pd.DataFrame, y_test: pd.Series) -> float:
        """ãƒ¢ãƒ‡ãƒ«ã‚’è©•ä¾¡ã™ã‚‹

        Args:
            X_test: ãƒ†ã‚¹ãƒˆç”¨ç‰¹å¾´é‡
            y_test: ãƒ†ã‚¹ãƒˆç”¨ç›®çš„å¤‰æ•°

        Returns:
            æ­£è§£ç‡ï¼ˆaccuracyï¼‰

        Raises:
            RuntimeError: ãƒ¢ãƒ‡ãƒ«ãŒè¨“ç·´ã•ã‚Œã¦ã„ãªã„å ´åˆ
        """
        if self.model is None:
            raise RuntimeError("Model has not been trained yet. Call train() first.")

        return self.model.score(X_test, y_test)

    def save_model(self, file_path: str) -> None:
        """è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã™ã‚‹

        Args:
            file_path: ä¿å­˜å…ˆãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹

        Raises:
            RuntimeError: ãƒ¢ãƒ‡ãƒ«ãŒè¨“ç·´ã•ã‚Œã¦ã„ãªã„å ´åˆ
        """
        if self.model is None:
            raise RuntimeError("Model has not been trained yet. Call train() first.")

        with open(file_path, 'wb') as f:
            pickle.dump(self.model, f)

    def load_model(self, file_path: str) -> None:
        """ä¿å­˜ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã‚€

        Args:
            file_path: ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹

        Raises:
            FileNotFoundError: ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆ
        """
        if not os.path.exists(file_path):
            raise FileNotFoundError(f"Model file not found: {file_path}")

        with open(file_path, 'rb') as f:
            self.model = pickle.load(f)
```

#### å®Ÿè·µçš„ãªè¨“ç·´ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

**examples/train_survived.py**:

```python
"""Survived ç”Ÿå­˜äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´ã‚¹ã‚¯ãƒªãƒ—ãƒˆ"""
from sklearn.model_selection import train_test_split
from src.ml.survived_classifier import SurvivedClassifier


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    # åˆ†é¡å™¨ã®ä½œæˆ
    classifier = SurvivedClassifier(max_depth=9, class_weight='balanced')
    print("SurvivedClassifier ã‚’ä½œæˆã—ã¾ã—ãŸ")

    # ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã¨å‰å‡¦ç†
    X, y = classifier.load_data('data/Survived.csv', preprocess=True)
    print(f"ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ: {len(X)} ã‚µãƒ³ãƒ—ãƒ«")

    # è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã¨ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã«åˆ†å‰²
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2, random_state=0
    )
    print(f"è¨“ç·´ãƒ‡ãƒ¼ã‚¿: {len(X_train)} ã‚µãƒ³ãƒ—ãƒ«")
    print(f"ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: {len(X_test)} ã‚µãƒ³ãƒ—ãƒ«")

    # ã‚¯ãƒ©ã‚¹åˆ†å¸ƒã®ç¢ºèª
    survived_count = y_train.sum()
    total_count = len(y_train)
    print(f"\n[è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®ã‚¯ãƒ©ã‚¹åˆ†å¸ƒ]")
    print(f"  ç”Ÿå­˜: {survived_count} ({survived_count/total_count*100:.1f}%)")
    print(f"  æ­»äº¡: {total_count - survived_count} ({(total_count-survived_count)/total_count*100:.1f}%)")

    # ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´
    classifier.train(X_train, y_train)
    print("\nãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´ãŒå®Œäº†ã—ã¾ã—ãŸ")

    # ç‰¹å¾´é‡ã®é‡è¦åº¦è¡¨ç¤º
    print("\n[ç‰¹å¾´é‡ã®é‡è¦åº¦]")
    feature_names = ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'male']
    importances = classifier.model.feature_importances_

    # é‡è¦åº¦ã§ã‚½ãƒ¼ãƒˆ
    sorted_indices = sorted(range(len(importances)),
                           key=lambda i: importances[i], reverse=True)

    for idx in sorted_indices:
        print(f"  {feature_names[idx]}: {importances[idx]:.4f}")

    # ãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡
    accuracy = classifier.evaluate(X_test, y_test)
    print(f"\n[ãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡]")
    print(f"  æ­£è§£ç‡ï¼ˆAccuracyï¼‰: {accuracy:.4f}")

    # ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜
    classifier.save_model('model/survived.pkl')
    print("\nãƒ¢ãƒ‡ãƒ«ã‚’ model/survived.pkl ã«ä¿å­˜ã—ã¾ã—ãŸ")

    # äºˆæ¸¬ä¾‹
    print("\n[äºˆæ¸¬ä¾‹]")
    sample = X_test.iloc[:5]
    predictions = classifier.predict(sample)

    for i, (idx, row) in enumerate(sample.iterrows()):
        actual = y_test.iloc[i]
        predicted = predictions[i]
        result = "âœ“" if actual == predicted else "âœ—"

        print(f"\nã‚µãƒ³ãƒ—ãƒ« {i+1}: {result}")
        print(f"  Pclass: {int(row['Pclass'])}, Age: {row['Age']:.0f}, "
              f"Sex: {'male' if row['male'] == 1 else 'female'}")
        print(f"  SibSp: {int(row['SibSp'])}, Parch: {int(row['Parch'])}, "
              f"Fare: {row['Fare']:.2f}")
        print(f"  å®Ÿéš›: {'ç”Ÿå­˜' if actual == 1 else 'æ­»äº¡'}")
        print(f"  äºˆæ¸¬: {'ç”Ÿå­˜' if predicted == 1 else 'æ­»äº¡'}")


if __name__ == '__main__':
    main()
```

å®Ÿè¡Œä¾‹ï¼š

```bash
uv run python examples/train_survived.py

# å‡ºåŠ›ä¾‹ï¼š
# SurvivedClassifier ã‚’ä½œæˆã—ã¾ã—ãŸ
# ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ: 891 ã‚µãƒ³ãƒ—ãƒ«
# è¨“ç·´ãƒ‡ãƒ¼ã‚¿: 712 ã‚µãƒ³ãƒ—ãƒ«
# ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: 179 ã‚µãƒ³ãƒ—ãƒ«
#
# [è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®ã‚¯ãƒ©ã‚¹åˆ†å¸ƒ]
#   ç”Ÿå­˜: 267 (37.5%)
#   æ­»äº¡: 445 (62.5%)
#
# ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´ãŒå®Œäº†ã—ã¾ã—ãŸ
#
# [ç‰¹å¾´é‡ã®é‡è¦åº¦]
#   male: 0.4235
#   Fare: 0.2134
#   Age: 0.1823
#   Pclass: 0.1245
#   Parch: 0.0345
#   SibSp: 0.0218
#
# [ãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡]
#   æ­£è§£ç‡ï¼ˆAccuracyï¼‰: 0.8324
#
# ãƒ¢ãƒ‡ãƒ«ã‚’ model/survived.pkl ã«ä¿å­˜ã—ã¾ã—ãŸ
#
# [äºˆæ¸¬ä¾‹]
#
# ã‚µãƒ³ãƒ—ãƒ« 1: âœ“
#   Pclass: 3, Age: 22, Sex: male
#   SibSp: 1, Parch: 0, Fare: 7.25
#   å®Ÿéš›: æ­»äº¡
#   äºˆæ¸¬: æ­»äº¡
#
# ã‚µãƒ³ãƒ—ãƒ« 2: âœ“
#   Pclass: 1, Age: 38, Sex: female
#   SibSp: 1, Parch: 0, Fare: 71.28
#   å®Ÿéš›: ç”Ÿå­˜
#   äºˆæ¸¬: ç”Ÿå­˜
#
# ã‚µãƒ³ãƒ—ãƒ« 3: âœ—
#   Pclass: 3, Age: 26, Sex: male
#   SibSp: 0, Parch: 0, Fare: 7.92
#   å®Ÿéš›: ç”Ÿå­˜
#   äºˆæ¸¬: æ­»äº¡
```

### ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ 4 ã®æŠ€è¡“çš„æˆæœ

#### å®Œæˆã—ãŸæ©Ÿèƒ½

- âœ… Survived åˆ†é¡å™¨ã‚¯ãƒ©ã‚¹ã®å®Œå…¨å®Ÿè£…
- âœ… ã‚°ãƒ«ãƒ¼ãƒ—åˆ¥æ¬ æå€¤è£œå®Œæ©Ÿèƒ½
- âœ… ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å¤‰æ•°ã®ãƒ€ãƒŸãƒ¼å¤‰æ•°åŒ–
- âœ… ã‚¯ãƒ©ã‚¹é‡ã¿ä»˜ãæ±ºå®šæœ¨ãƒ¢ãƒ‡ãƒ«
- âœ… ç‰¹å¾´é‡é‡è¦åº¦ã®åˆ†æ
- âœ… ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜ã¨èª­ã¿è¾¼ã¿æ©Ÿèƒ½

#### å®šé‡çš„æˆæœ

| æŒ‡æ¨™ | å®Ÿç¸¾ |
|------|------|
| **ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹** | 22å€‹ |
| **ã‚³ãƒ¼ãƒ‰ã‚«ãƒãƒ¬ãƒƒã‚¸** | 90%ï¼ˆsurvived_classifier.pyï¼‰ |
| **å‹ãƒ’ãƒ³ãƒˆä½¿ç”¨ç‡** | 100% |
| **ãƒ¢ãƒ‡ãƒ«æ­£è§£ç‡** | 0.8324ï¼ˆãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ï¼‰ |
| **Ruff ãƒã‚§ãƒƒã‚¯** | å…¨ã¦é€šé |
| **mypy ãƒã‚§ãƒƒã‚¯** | ã‚¨ãƒ©ãƒ¼ 0ä»¶ |
| **å¾ªç’°çš„è¤‡é›‘åº¦** | æœ€å¤§ 5ï¼ˆå…¨é–¢æ•°ï¼‰ |

#### ç¿’å¾—ã—ãŸã‚¹ã‚­ãƒ«

**1. TDD ã‚¹ã‚­ãƒ«ï¼ˆé«˜åº¦ï¼‰**
- è¤‡é›‘ãªå‰å‡¦ç†ãƒ­ã‚¸ãƒƒã‚¯ã®ãƒ†ã‚¹ãƒˆé§†å‹•å®Ÿè£…
- ã‚°ãƒ«ãƒ¼ãƒ—å‡¦ç†ã®ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹è¨­è¨ˆ
- ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å¤‰æ•°ã®ãƒ†ã‚¹ãƒˆ

**2. ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ã‚¹ã‚­ãƒ«ï¼ˆå®Ÿè·µï¼‰**
- ã‚°ãƒ«ãƒ¼ãƒ—åˆ¥çµ±è¨ˆã«ã‚ˆã‚‹æ¬ æå€¤è£œå®Œ
- ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å¤‰æ•°ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°
- å¤šé‡å…±ç·šæ€§ã®å›é¿ï¼ˆdrop_firstï¼‰

**3. æ©Ÿæ¢°å­¦ç¿’ã‚¹ã‚­ãƒ«ï¼ˆåˆ†é¡å¿œç”¨ï¼‰**
- ã‚¯ãƒ©ã‚¹ä¸å‡è¡¡ã¸ã®å¯¾å¿œ
- ç‰¹å¾´é‡é‡è¦åº¦ã®ç†è§£ã¨æ´»ç”¨
- class_weight ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã®åŠ¹æœ

**4. ãƒ‡ãƒ¼ã‚¿åˆ†æã‚¹ã‚­ãƒ«**
- ã‚¯ãƒ©ã‚¹åˆ†å¸ƒã®ç¢ºèªã¨ç†è§£
- ç‰¹å¾´é‡ã®å½±éŸ¿åº¦åˆ†æ
- ãƒ¢ãƒ‡ãƒ«ã®è§£é‡ˆå¯èƒ½æ€§å‘ä¸Š

#### ã‚°ãƒ«ãƒ¼ãƒ—åˆ¥æ¬ æå€¤è£œå®Œã®ç†è§£

**ãªãœã‚°ãƒ«ãƒ¼ãƒ—åˆ¥è£œå®ŒãŒé‡è¦ã‹**:

```python
# å˜ç´”ãªå¹³å‡å€¤è£œå®Œ
# â†’ å…¨å¹´é½¢å±¤ã®å¹³å‡ï¼ˆä¾‹: 29æ­³ï¼‰ã§è£œå®Œ
# å•é¡Œ: 1ç­‰å®¢å®¤ã®é«˜é½¢è€…ã¨3ç­‰å®¢å®¤ã®è‹¥è€…ã‚’åŒºåˆ¥ã§ããªã„

# ã‚°ãƒ«ãƒ¼ãƒ—åˆ¥ä¸­å¤®å€¤è£œå®Œ
# â†’ Pclass ã¨ Survived ã”ã¨ã®ä¸­å¤®å€¤ã§è£œå®Œ
# åˆ©ç‚¹: ã‚ˆã‚Šæ­£ç¢ºãªå¹´é½¢æ¨å®šãŒå¯èƒ½

# ä¾‹:
# 1ç­‰å®¢å®¤ã®æ­»äº¡è€…: å¹³å‡43æ­³ï¼ˆé«˜é½¢å¯Œè£•å±¤ï¼‰
# 3ç­‰å®¢å®¤ã®ç”Ÿå­˜è€…: å¹³å‡20æ­³ï¼ˆè‹¥ã„ç§»æ°‘å±¤ï¼‰
```

#### ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å¤‰æ•°ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã®ç†è§£

**ãƒ€ãƒŸãƒ¼å¤‰æ•°åŒ–ã®ä»•çµ„ã¿**:

```python
# å…ƒãƒ‡ãƒ¼ã‚¿:
# Sex = ['male', 'female', 'male']

# pd.get_dummies(drop_first=False)  # ä¸¡æ–¹ã®åˆ—ã‚’ä½œæˆ
# â†’ male = [1, 0, 1]
# â†’ female = [0, 1, 0]
# å•é¡Œ: male ã¨ female ãŒå®Œå…¨ã«é€†ãªã®ã§å†—é•·ï¼ˆå¤šé‡å…±ç·šæ€§ï¼‰

# pd.get_dummies(drop_first=True)  # male åˆ—ã®ã¿ä½œæˆ
# â†’ male = [1, 0, 1]
# è§£é‡ˆ: 1=male, 0=female
# åˆ©ç‚¹: 1åˆ—ã§è¡¨ç¾ã§ãã¦åŠ¹ç‡çš„
```

#### ã‚¯ãƒ©ã‚¹ä¸å‡è¡¡ã¸ã®å¯¾å¿œ

**class_weight='balanced' ã®åŠ¹æœ**:

```python
# ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®åˆ†å¸ƒ
# ç”Ÿå­˜: 267äººï¼ˆ37.5%ï¼‰
# æ­»äº¡: 445äººï¼ˆ62.5%ï¼‰

# class_weight=Noneï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰
# â†’ ãƒ¢ãƒ‡ãƒ«ãŒå¤šæ•°æ´¾ã‚¯ãƒ©ã‚¹ï¼ˆæ­»äº¡ï¼‰ã«åã‚‹
# â†’ ã€Œå…¨å“¡æ­»äº¡ã€ã¨äºˆæ¸¬ã—ã¦ã‚‚ 62.5% ã®æ­£è§£ç‡

# class_weight='balanced'
# â†’ å°‘æ•°æ´¾ã‚¯ãƒ©ã‚¹ï¼ˆç”Ÿå­˜ï¼‰ã®ã‚µãƒ³ãƒ—ãƒ«ã«å¤§ããªé‡ã¿ã‚’ä»˜ä¸
# â†’ ãƒãƒ©ãƒ³ã‚¹ã®å–ã‚ŒãŸäºˆæ¸¬ãŒå¯èƒ½ï¼ˆæ­£è§£ç‡ 83.24%ï¼‰
```

é‡ã¿è¨ˆç®—å¼ï¼š

```
weight[class_i] = n_samples / (n_classes * n_samples[class_i])

ä¾‹ï¼š
weight[ç”Ÿå­˜] = 712 / (2 * 267) â‰ˆ 1.33
weight[æ­»äº¡] = 712 / (2 * 445) â‰ˆ 0.80
```

#### åˆ†é¡ãƒ¢ãƒ‡ãƒ«ã®æ¯”è¼ƒï¼ˆIris vs Survivedï¼‰

| é …ç›® | Irisï¼ˆåŸºç¤ï¼‰ | **Survivedï¼ˆå®Ÿè·µï¼‰** |
|------|-------------|---------------------|
| **ãƒ¢ãƒ‡ãƒ«** | DecisionTreeClassifier | DecisionTreeClassifier |
| **ã‚¯ãƒ©ã‚¹æ•°** | 3ã‚¯ãƒ©ã‚¹ | 2ã‚¯ãƒ©ã‚¹ï¼ˆäºŒå€¤åˆ†é¡ï¼‰ |
| **å‰å‡¦ç†** | å¹³å‡å€¤è£œå®Œã®ã¿ | **ã‚°ãƒ«ãƒ¼ãƒ—åˆ¥è£œå®Œ + ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°** |
| **ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å¤‰æ•°** | ãªã— | **ã‚ã‚Šï¼ˆSexï¼‰** |
| **ã‚¯ãƒ©ã‚¹ä¸å‡è¡¡å¯¾å¿œ** | ãªã— | **class_weight='balanced'** |
| **max_depth** | 2 | **9** |
| **ãƒ†ã‚¹ãƒˆæ•°** | 18å€‹ | **22å€‹** |
| **æ­£è§£ç‡** | 97.78% | **83.24%** |

**æ­£è§£ç‡ã®é•ã„ã®ç†ç”±**:

- Iris: æ˜ç¢ºã«åˆ†é›¢å¯èƒ½ãª3ã¤ã®ç¨®é¡ï¼ˆãƒ‡ãƒ¼ã‚¿ãŒã€Œãã‚Œã„ã€ï¼‰
- Survived: è¤‡é›‘ãªç¤¾ä¼šçš„è¦å› ï¼ˆãƒ‡ãƒ¼ã‚¿ãŒã€Œç¾å®Ÿçš„ã€ï¼‰
  - ç”Ÿå­˜ã«ã¯é‹ã®è¦ç´ ã‚‚é–¢ä¸
  - ç‰¹å¾´é‡ã ã‘ã§ã¯èª¬æ˜ã§ããªã„éƒ¨åˆ†ãŒã‚ã‚‹

#### æ¬¡ã®ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã¸ã®æº–å‚™

ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ 5 ã§ã¯ã€ä»¥ä¸‹ã‚’å®Ÿè£…ã—ã¾ã™ï¼š

- Boston ä½å®…ä¾¡æ ¼äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ï¼ˆé«˜åº¦ãªå›å¸°å•é¡Œï¼‰
- ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ï¼ˆ2ä¹—é …ãƒ»äº¤äº’ä½œç”¨é …ï¼‰
- ãƒ‡ãƒ¼ã‚¿æ¨™æº–åŒ–ï¼ˆStandardScalerï¼‰
- è¤‡æ•°ãƒ¢ãƒ‡ãƒ«ã®ç®¡ç†ï¼ˆãƒ¢ãƒ‡ãƒ« + ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼ï¼‰

---

## ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ 5: é«˜åº¦ãªå›å¸°å•é¡Œ

### 7ç«  Boston ä½å®…ä¾¡æ ¼äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«

#### æ¦‚è¦ã¨å­¦ç¿’ç›®æ¨™

ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ 5 ã§ã¯ã€ãƒœã‚¹ãƒˆãƒ³å¸‚ã®ä½å®…ä¾¡æ ¼ã‚’äºˆæ¸¬ã™ã‚‹é«˜åº¦ãªå›å¸°å•é¡Œã«å–ã‚Šçµ„ã¿ã¾ã™ã€‚Cinema ãƒ¢ãƒ‡ãƒ«ã‚ˆã‚Šã‚‚ã•ã‚‰ã«é«˜åº¦ãªæŠ€è¡“ï¼ˆç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã€æ¨™æº–åŒ–ã€è¤‡æ•°ãƒ¢ãƒ‡ãƒ«ã®ç®¡ç†ï¼‰ã‚’ç¿’å¾—ã—ã€å®Ÿå‹™ãƒ¬ãƒ™ãƒ«ã®æ©Ÿæ¢°å­¦ç¿’é–‹ç™ºã‚’ä½“é¨“ã—ã¾ã™ã€‚

##### å­¦ç¿’ç›®æ¨™

1. **ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°**: 2ä¹—é …ãƒ»äº¤äº’ä½œç”¨é …ã«ã‚ˆã‚‹è¡¨ç¾åŠ›å‘ä¸Š
2. **ãƒ‡ãƒ¼ã‚¿æ¨™æº–åŒ–**: StandardScaler ã«ã‚ˆã‚‹æ­£è¦åŒ–ã¨ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚±ãƒ¼ã‚¸é˜²æ­¢
3. **è¤‡æ•°ãƒ¢ãƒ‡ãƒ«ç®¡ç†**: ãƒ¢ãƒ‡ãƒ« + 2ã¤ã®ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼ã®ä¸€æ‹¬ç®¡ç†
4. **é«˜åº¦ãª TDD**: æ¨™æº–åŒ–å‡¦ç†ã®ãƒ†ã‚¹ãƒˆé§†å‹•å®Ÿè£…

#### Boston ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ç†è§£

##### ãƒ‡ãƒ¼ã‚¿è©³ç´°

`data/Boston.csv` ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚

| åˆ—å | å†…å®¹ | ãƒ‡ãƒ¼ã‚¿å‹ | ç‰¹å¾´ |
|------|------|----------|------|
| RM | ä½å±…ã®å¹³å‡éƒ¨å±‹æ•° | float | **é‡è¦ãªç‰¹å¾´é‡** |
| LSTAT | äººå£ã«ãŠã‘ã‚‹ä½æ‰€å¾—è€…ã®å‰²åˆï¼ˆ%ï¼‰ | float | **é‡è¦ãªç‰¹å¾´é‡** |
| PTRATIO | æ•™å“¡1äººå½“ãŸã‚Šã®å…ç«¥ç”Ÿå¾’æ•° | float | **é‡è¦ãªç‰¹å¾´é‡** |
| CRIME | çŠ¯ç½ªç‡ã‚«ãƒ†ã‚´ãƒª | str | **ãƒ€ãƒŸãƒ¼å¤‰æ•°åŒ–ãŒå¿…è¦** |
| PRICE | ä½å®…ä¾¡æ ¼ï¼ˆ$1000å˜ä½ï¼‰ | float | **ç›®çš„å¤‰æ•°** |

##### Cinema ã¨ã®é•ã„

| ç‰¹å¾´ | Cinema | **Boston** |
|------|--------|-----------|
| **å•é¡Œã®ç¨®é¡** | å›å¸° | **å›å¸°** |
| **ç‰¹å¾´é‡æ•°** | 4å€‹ | **3å€‹ï¼ˆåŸºæœ¬ï¼‰â†’ 7å€‹ï¼ˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°å¾Œï¼‰** |
| **å‰å‡¦ç†** | æ¬ æå€¤è£œå®Œ + å¤–ã‚Œå€¤é™¤å¤– | **æ¬ æå€¤è£œå®Œ + å¤–ã‚Œå€¤é™¤å¤– + ãƒ€ãƒŸãƒ¼å¤‰æ•°åŒ–** |
| **ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°** | ãªã— | **ã‚ã‚Šï¼ˆ2ä¹—é … + äº¤äº’ä½œç”¨é …ï¼‰** |
| **æ¨™æº–åŒ–** | ãªã— | **ã‚ã‚Šï¼ˆç‰¹å¾´é‡ + ç›®çš„å¤‰æ•°ï¼‰** |
| **ä¿å­˜ãƒ¢ãƒ‡ãƒ«æ•°** | 1å€‹ï¼ˆmodelï¼‰ | **3å€‹ï¼ˆmodel + scaler_X + scaler_yï¼‰** |
| **å‰å‡¦ç†ã®è¤‡é›‘åº¦** | ä¸­ | **é«˜** |

##### å•é¡Œã®è¤‡é›‘æ€§

**1. ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°**

ç·šå½¢å›å¸°ã®è¡¨ç¾åŠ›ã‚’å‘ä¸Šã•ã›ã‚‹ãŸã‚ã€å…ƒã®ç‰¹å¾´é‡ã‹ã‚‰æ–°ã—ã„ç‰¹å¾´é‡ã‚’ç”Ÿæˆã—ã¾ã™ã€‚

```python
# å…ƒã®ç‰¹å¾´é‡: RM, LSTAT, PTRATIOï¼ˆ3å€‹ï¼‰

# ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°å¾Œ:
# - å…ƒã®ç‰¹å¾´é‡: RM, LSTAT, PTRATIO
# - 2ä¹—é …: RM2, LSTAT2, PTRATIO2
# - äº¤äº’ä½œç”¨é …: RM * LSTAT
# åˆè¨ˆ: 7å€‹ã®ç‰¹å¾´é‡
```

**2. ãƒ‡ãƒ¼ã‚¿æ¨™æº–åŒ–ã®å¿…è¦æ€§**

ç‰¹å¾´é‡ã®ã‚¹ã‚±ãƒ¼ãƒ«ãŒç•°ãªã‚‹ã¨ã€ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ãŒä¸å®‰å®šã«ãªã‚Šã¾ã™ã€‚

```python
# æ¨™æº–åŒ–å‰:
# RM: 3ã€œ9ï¼ˆå¹³å‡éƒ¨å±‹æ•°ï¼‰
# LSTAT: 1ã€œ40ï¼ˆä½æ‰€å¾—è€…å‰²åˆ%ï¼‰
# PTRATIO: 12ã€œ22ï¼ˆç”Ÿå¾’æ•°ï¼‰
# â†’ ã‚¹ã‚±ãƒ¼ãƒ«ãŒå¤§ããç•°ãªã‚‹

# æ¨™æº–åŒ–å¾Œ:
# ã™ã¹ã¦ã®ç‰¹å¾´é‡ãŒå¹³å‡0ã€æ¨™æº–åå·®1ã«æ­£è¦åŒ–
# â†’ å­¦ç¿’ãŒå®‰å®šã—ã€ãƒ¢ãƒ‡ãƒ«ã®è§£é‡ˆãŒå®¹æ˜“ã«
```

**3. ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚±ãƒ¼ã‚¸ã®é˜²æ­¢**

è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã¨ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’å³å¯†ã«åˆ†é›¢ã—ã€ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®æƒ…å ±ãŒè¨“ç·´ã«æ¼ã‚Œãªã„ã‚ˆã†ã«ã—ã¾ã™ã€‚

```python
# âŒ æ‚ªã„ä¾‹ï¼ˆãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚±ãƒ¼ã‚¸ã‚ã‚Šï¼‰
# å…¨ãƒ‡ãƒ¼ã‚¿ã§æ¬ æå€¤è£œå®Œ â†’ åˆ†å‰²
# â†’ ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®æƒ…å ±ãŒè¨“ç·´ã«æ¼ã‚Œã‚‹

# âœ… è‰¯ã„ä¾‹ï¼ˆãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚±ãƒ¼ã‚¸ãªã—ï¼‰
# åˆ†å‰² â†’ è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã§æ¬ æå€¤ã®å¹³å‡ã‚’è¨ˆç®— â†’ ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã«é©ç”¨
# â†’ ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®æƒ…å ±ã¯ä½¿ã‚ãªã„
```

#### TDD ã«ã‚ˆã‚‹å®Ÿè£…ï¼ˆ8ã‚¹ãƒ†ãƒƒãƒ—ï¼‰

##### ã‚¹ãƒ†ãƒƒãƒ— 1: åˆæœŸåŒ–ã¨ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿

**Red: ãƒ†ã‚¹ãƒˆã‚’æ›¸ã**

**test/test_boston_predictor.py**:

```python
"""Boston ä½å®…ä¾¡æ ¼äºˆæ¸¬å™¨ã®ãƒ†ã‚¹ãƒˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«"""
import os
import tempfile
import pytest
import pandas as pd
import numpy as np
from src.ml.boston_predictor import BostonPredictor


class TestBostonPredictorInit:
    """åˆæœŸåŒ–ã®ãƒ†ã‚¹ãƒˆ"""

    def test_åˆæœŸåŒ–_ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ(self):
        """ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§åˆæœŸåŒ–ã§ãã‚‹ã“ã¨ã‚’ç¢ºèª"""
        predictor = BostonPredictor()

        assert predictor.model is None
        assert predictor.scaler_X is None
        assert predictor.scaler_y is None
        assert predictor.train_mean is None


class TestBostonPredictorLoadData:
    """ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã®ãƒ†ã‚¹ãƒˆ"""

    def test_CSVãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿(self):
        """CSV ãƒ•ã‚¡ã‚¤ãƒ«ãŒæ­£å¸¸ã«èª­ã¿è¾¼ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª"""
        predictor = BostonPredictor()

        # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ä½œæˆ
        test_data = """RM,LSTAT,PTRATIO,CRIME,PRICE
6.5,5.0,15.0,low,24.0
5.5,10.0,18.0,high,18.5
7.0,3.0,14.0,low,33.2"""

        with tempfile.NamedTemporaryFile(mode='w', delete=False, suffix='.csv') as f:
            f.write(test_data)
            temp_path = f.name

        try:
            df = predictor.load_data(temp_path)

            # ãƒ‡ãƒ¼ã‚¿ãŒæ­£ã—ãèª­ã¿è¾¼ã¾ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
            assert len(df) == 3
            assert 'PRICE' in df.columns
            assert 'RM' in df.columns
        finally:
            os.unlink(temp_path)

    def test_ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆã‚¨ãƒ©ãƒ¼(self):
        """å­˜åœ¨ã—ãªã„ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’æŒ‡å®šã—ãŸå ´åˆ FileNotFoundError ã‚’ç™ºç”Ÿ"""
        predictor = BostonPredictor()

        with pytest.raises(FileNotFoundError):
            predictor.load_data('nonexistent.csv')

    def test_å¿…è¦ãªåˆ—ãŒä¸è¶³ã—ã¦ã„ã‚‹å ´åˆã‚¨ãƒ©ãƒ¼(self):
        """å¿…è¦ãªåˆ—ãŒä¸è¶³ã—ã¦ã„ã‚‹å ´åˆ ValueError ã‚’ç™ºç”Ÿ"""
        predictor = BostonPredictor()

        # PRICE åˆ—ãŒæ¬ ã‘ã¦ã„ã‚‹ãƒ‡ãƒ¼ã‚¿
        test_data = """RM,LSTAT,PTRATIO
6.5,5.0,15.0"""

        with tempfile.NamedTemporaryFile(mode='w', delete=False, suffix='.csv') as f:
            f.write(test_data)
            temp_path = f.name

        try:
            with pytest.raises(ValueError, match="Missing columns"):
                predictor.load_data(temp_path)
        finally:
            os.unlink(temp_path)
```

**Green: æœ€å°é™ã®å®Ÿè£…**

**src/ml/boston_predictor.py**:

```python
"""Boston ä½å®…ä¾¡æ ¼äºˆæ¸¬å™¨ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«"""
import os
from typing import Optional, Tuple
import pandas as pd
import numpy as np
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import StandardScaler


class BostonPredictor:
    """ãƒœã‚¹ãƒˆãƒ³å¸‚ã®ä½å®…ä¾¡æ ¼ã‚’äºˆæ¸¬ã™ã‚‹å›å¸°ãƒ¢ãƒ‡ãƒ«

    Attributes:
        model: è¨“ç·´æ¸ˆã¿ã®ç·šå½¢å›å¸°ãƒ¢ãƒ‡ãƒ«ï¼ˆæœªè¨“ç·´æ™‚ã¯ Noneï¼‰
        scaler_X: ç‰¹å¾´é‡ã®æ¨™æº–åŒ–ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼ï¼ˆæœªè¨“ç·´æ™‚ã¯ Noneï¼‰
        scaler_y: ç›®çš„å¤‰æ•°ã®æ¨™æº–åŒ–ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼ï¼ˆæœªè¨“ç·´æ™‚ã¯ Noneï¼‰
        train_mean: è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®å¹³å‡å€¤ï¼ˆæ¬ æå€¤è£œå®Œç”¨ï¼‰
    """

    def __init__(self) -> None:
        """åˆæœŸåŒ–"""
        self.model: Optional[LinearRegression] = None
        self.scaler_X: Optional[StandardScaler] = None
        self.scaler_y: Optional[StandardScaler] = None
        self.train_mean: Optional[pd.Series] = None

    def load_data(self, file_path: str) -> pd.DataFrame:
        """CSV ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€

        Args:
            file_path: CSV ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹

        Returns:
            èª­ã¿è¾¼ã‚“ã  DataFrame

        Raises:
            FileNotFoundError: ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆ
            ValueError: å¿…è¦ãªåˆ—ãŒä¸è¶³ã—ã¦ã„ã‚‹å ´åˆ
        """
        if not os.path.exists(file_path):
            raise FileNotFoundError(f"File not found: {file_path}")

        # ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
        df = pd.read_csv(file_path)

        # å¿…è¦ãªåˆ—ã®å­˜åœ¨ç¢ºèª
        required_columns = ['RM', 'LSTAT', 'PTRATIO', 'CRIME', 'PRICE']
        missing_columns = set(required_columns) - set(df.columns)
        if missing_columns:
            raise ValueError(f"Missing columns: {missing_columns}")

        return df
```

##### ã‚¹ãƒ†ãƒƒãƒ— 2: CRIME åˆ—ã®ãƒ€ãƒŸãƒ¼å¤‰æ•°åŒ–

ã‚«ãƒ†ã‚´ãƒªã‚«ãƒ«å¤‰æ•° CRIME ã‚’æ•°å€¤åŒ–ã—ã¾ã™ã€‚

**Red: ãƒ†ã‚¹ãƒˆã‚’æ›¸ã**

```python
class TestBostonPredictorEncodeCrime:
    """CRIME åˆ—ãƒ€ãƒŸãƒ¼å¤‰æ•°åŒ–ã®ãƒ†ã‚¹ãƒˆ"""

    def test_CRIMEåˆ—ãŒãƒ€ãƒŸãƒ¼å¤‰æ•°åŒ–ã•ã‚Œã‚‹(self):
        """CRIME åˆ—ãŒãƒ€ãƒŸãƒ¼å¤‰æ•°ã«å¤‰æ›ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª"""
        predictor = BostonPredictor()

        df = pd.DataFrame({
            'RM': [6.5, 5.5],
            'CRIME': ['low', 'high'],
            'PRICE': [24.0, 18.5]
        })

        df_encoded = predictor._encode_crime(df)

        # CRIME åˆ—ãŒå‰Šé™¤ã•ã‚Œã€ãƒ€ãƒŸãƒ¼å¤‰æ•°ãŒè¿½åŠ ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
        assert 'CRIME' not in df_encoded.columns
        # drop_first=True ãªã®ã§ high ã®ã¿ä½œæˆã•ã‚Œã‚‹
        assert 'high' in df_encoded.columns

    def test_ãƒ€ãƒŸãƒ¼å¤‰æ•°ã®å€¤ãŒæ­£ã—ã„(self):
        """ãƒ€ãƒŸãƒ¼å¤‰æ•°ã®å€¤ãŒæ­£ã—ã„ã“ã¨ã‚’ç¢ºèª"""
        predictor = BostonPredictor()

        df = pd.DataFrame({
            'CRIME': ['low', 'high', 'low', 'medium']
        })

        df_encoded = predictor._encode_crime(df)

        # drop_first=True ã«ã‚ˆã‚Šã€low ä»¥å¤–ã®ã‚«ãƒ†ã‚´ãƒªãŒåˆ—ã¨ã—ã¦ä½œæˆã•ã‚Œã‚‹
        assert 'high' in df_encoded.columns
        assert 'medium' in df_encoded.columns

    def test_ä»–ã®åˆ—ã¯ä¿æŒã•ã‚Œã‚‹(self):
        """CRIME ä»¥å¤–ã®åˆ—ã¯ä¿æŒã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª"""
        predictor = BostonPredictor()

        df = pd.DataFrame({
            'RM': [6.5, 5.5],
            'LSTAT': [5.0, 10.0],
            'CRIME': ['low', 'high'],
            'PRICE': [24.0, 18.5]
        })

        df_encoded = predictor._encode_crime(df)

        assert 'RM' in df_encoded.columns
        assert 'LSTAT' in df_encoded.columns
        assert 'PRICE' in df_encoded.columns
        assert df_encoded['RM'].tolist() == [6.5, 5.5]
```

**Green: å®Ÿè£…**

```python
def _encode_crime(self, df: pd.DataFrame) -> pd.DataFrame:
    """CRIME åˆ—ã‚’ãƒ€ãƒŸãƒ¼å¤‰æ•°ã«å¤‰æ›

    Args:
        df: å…ƒã® DataFrame

    Returns:
        CRIME ãŒãƒ€ãƒŸãƒ¼å¤‰æ•°åŒ–ã•ã‚ŒãŸ DataFrame

    Note:
        drop_first=True ã«ã‚ˆã‚Šã€æœ€åˆã®ã‚«ãƒ†ã‚´ãƒªï¼ˆã‚¢ãƒ«ãƒ•ã‚¡ãƒ™ãƒƒãƒˆé †ï¼‰ã‚’
        åŸºæº–ã¨ã—ã€ãã‚Œä»¥å¤–ã®ã‚«ãƒ†ã‚´ãƒªã®ãƒ€ãƒŸãƒ¼å¤‰æ•°ã‚’ä½œæˆ
    """
    df_copy = df.copy()

    # CRIME ã‚’ãƒ€ãƒŸãƒ¼å¤‰æ•°åŒ–ï¼ˆdrop_first=Trueï¼‰
    crime_dummies = pd.get_dummies(df_copy['CRIME'], drop_first=True, dtype=int)
    df_encoded = pd.concat([df_copy.drop('CRIME', axis=1), crime_dummies], axis=1)

    return df_encoded
```

##### ã‚¹ãƒ†ãƒƒãƒ— 3: æ¬ æå€¤è£œå®Œã¨å¤–ã‚Œå€¤é™¤å¤–

**Red: ãƒ†ã‚¹ãƒˆã‚’æ›¸ã**

```python
class TestBostonPredictorPreprocess:
    """å‰å‡¦ç†ã®ãƒ†ã‚¹ãƒˆ"""

    def test_æ¬ æå€¤ãŒå¹³å‡å€¤ã§è£œå®Œã•ã‚Œã‚‹(self):
        """æ¬ æå€¤ãŒè¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®å¹³å‡å€¤ã§è£œå®Œã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª"""
        predictor = BostonPredictor()

        df_train = pd.DataFrame({
            'RM': [6.0, 7.0, 5.0],
            'LSTAT': [5.0, 10.0, np.nan],  # å¹³å‡: 7.5
            'PRICE': [24.0, 18.5, 21.0]
        })

        df_filled = predictor._fill_missing_values(df_train, fit=True)

        # æ¬ æå€¤ãŒå¹³å‡å€¤ã§è£œå®Œã•ã‚Œã‚‹
        assert df_filled['LSTAT'].iloc[2] == 7.5
        # train_mean ãŒä¿å­˜ã•ã‚Œã‚‹
        assert predictor.train_mean is not None

    def test_ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã¯è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®å¹³å‡ã§è£œå®Œã•ã‚Œã‚‹(self):
        """ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã¯è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®å¹³å‡ã§è£œå®Œã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª"""
        predictor = BostonPredictor()

        df_train = pd.DataFrame({
            'RM': [6.0, 7.0, 5.0],
            'LSTAT': [5.0, 10.0, 15.0],
            'PRICE': [24.0, 18.5, 21.0]
        })

        # è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã§å¹³å‡ã‚’è¨ˆç®—
        predictor._fill_missing_values(df_train, fit=True)

        df_test = pd.DataFrame({
            'RM': [np.nan],
            'LSTAT': [8.0],
            'PRICE': [20.0]
        })

        # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã¯è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®å¹³å‡ã§è£œå®Œ
        df_test_filled = predictor._fill_missing_values(df_test, fit=False)

        # è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã® RM å¹³å‡ã¯ 6.0
        assert df_test_filled['RM'].iloc[0] == 6.0

    def test_å¤–ã‚Œå€¤ãŒé™¤å¤–ã•ã‚Œã‚‹(self):
        """ç‰¹å®šã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®å¤–ã‚Œå€¤ãŒé™¤å¤–ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª"""
        predictor = BostonPredictor()

        # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ 76 ã‚’å«ã‚€ãƒ‡ãƒ¼ã‚¿
        df = pd.DataFrame({
            'RM': [6.0, 7.0, 5.0, 8.0],
            'PRICE': [24.0, 18.5, 21.0, 50.0]
        }, index=[0, 1, 76, 3])

        df_cleaned = predictor._remove_outliers(df)

        # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ 76 ãŒé™¤å¤–ã•ã‚Œã‚‹
        assert 76 not in df_cleaned.index
        assert len(df_cleaned) == 3
```

**Green: å®Ÿè£…**

```python
def _fill_missing_values(self, df: pd.DataFrame, fit: bool = True) -> pd.DataFrame:
    """æ¬ æå€¤ã‚’å¹³å‡å€¤ã§è£œå®Œ

    Args:
        df: å¯¾è±¡ã® DataFrame
        fit: True ã®å ´åˆã¯å¹³å‡å€¤ã‚’è¨ˆç®—ã—ã¦ä¿å­˜ã€False ã®å ´åˆã¯ä¿å­˜æ¸ˆã¿ã®å¹³å‡å€¤ã‚’ä½¿ç”¨

    Returns:
        æ¬ æå€¤ãŒè£œå®Œã•ã‚ŒãŸ DataFrame

    Raises:
        ValueError: fit=False ã®å ´åˆã§ train_mean ãŒæœªè¨­å®šã®å ´åˆ
    """
    if fit:
        # è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®å¹³å‡å€¤ã‚’è¨ˆç®—ã—ã¦ä¿å­˜
        self.train_mean = df.mean()
        return df.fillna(self.train_mean)
    else:
        # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã¯è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®å¹³å‡å€¤ã§è£œå®Œ
        if self.train_mean is None:
            raise ValueError("train_mean not set. Call with fit=True first.")
        return df.fillna(self.train_mean)

def _remove_outliers(self, df: pd.DataFrame) -> pd.DataFrame:
    """å¤–ã‚Œå€¤ã‚’é™¤å¤–

    Args:
        df: å¯¾è±¡ã® DataFrame

    Returns:
        å¤–ã‚Œå€¤ã‚’é™¤å¤–ã—ãŸ DataFrame

    Note:
        ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ 76 ã®ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆã‚’å¤–ã‚Œå€¤ã¨ã—ã¦é™¤å¤–
    """
    # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ 76 ãŒå­˜åœ¨ã™ã‚‹å ´åˆã®ã¿é™¤å¤–
    if 76 in df.index:
        return df.drop([76], axis=0)
    return df
```

##### ã‚¹ãƒ†ãƒƒãƒ— 4: ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°

2ä¹—é …ã¨äº¤äº’ä½œç”¨é …ã‚’è¿½åŠ ã—ã¦ãƒ¢ãƒ‡ãƒ«ã®è¡¨ç¾åŠ›ã‚’å‘ä¸Šã•ã›ã¾ã™ã€‚

**Red: ãƒ†ã‚¹ãƒˆã‚’æ›¸ã**

```python
class TestBostonPredictorFeatureEngineering:
    """ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã®ãƒ†ã‚¹ãƒˆ"""

    def test_2ä¹—é …ãŒè¿½åŠ ã•ã‚Œã‚‹(self):
        """2ä¹—é …ãŒæ­£ã—ãè¿½åŠ ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª"""
        predictor = BostonPredictor()

        X = pd.DataFrame({
            'RM': [6.5],
            'LSTAT': [5.0],
            'PTRATIO': [15.0]
        })

        X_engineered = predictor.feature_engineering(X)

        # 2ä¹—é …ãŒè¿½åŠ ã•ã‚Œã‚‹
        assert 'RM2' in X_engineered.columns
        assert 'LSTAT2' in X_engineered.columns
        assert 'PTRATIO2' in X_engineered.columns

        # å€¤ãŒæ­£ã—ã„
        assert X_engineered['RM2'].iloc[0] == 42.25  # 6.5^2
        assert X_engineered['LSTAT2'].iloc[0] == 25.0  # 5.0^2
        assert X_engineered['PTRATIO2'].iloc[0] == 225.0  # 15.0^2

    def test_äº¤äº’ä½œç”¨é …ãŒè¿½åŠ ã•ã‚Œã‚‹(self):
        """äº¤äº’ä½œç”¨é …ãŒæ­£ã—ãè¿½åŠ ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª"""
        predictor = BostonPredictor()

        X = pd.DataFrame({
            'RM': [6.5],
            'LSTAT': [5.0],
            'PTRATIO': [15.0]
        })

        X_engineered = predictor.feature_engineering(X)

        # äº¤äº’ä½œç”¨é …ãŒè¿½åŠ ã•ã‚Œã‚‹
        assert 'RM * LSTAT' in X_engineered.columns
        assert X_engineered['RM * LSTAT'].iloc[0] == 32.5  # 6.5 * 5.0

    def test_å…ƒã®ç‰¹å¾´é‡ã¯ä¿æŒã•ã‚Œã‚‹(self):
        """å…ƒã®ç‰¹å¾´é‡ãŒä¿æŒã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª"""
        predictor = BostonPredictor()

        X = pd.DataFrame({
            'RM': [6.5, 5.5],
            'LSTAT': [5.0, 10.0],
            'PTRATIO': [15.0, 18.0]
        })

        X_engineered = predictor.feature_engineering(X)

        # å…ƒã®ç‰¹å¾´é‡ãŒä¿æŒã•ã‚Œã‚‹
        assert 'RM' in X_engineered.columns
        assert 'LSTAT' in X_engineered.columns
        assert 'PTRATIO' in X_engineered.columns
        assert X_engineered['RM'].tolist() == [6.5, 5.5]

    def test_ç‰¹å¾´é‡æ•°ãŒæ­£ã—ã„(self):
        """ç‰¹å¾´é‡æ•°ãŒ3å€‹ã‹ã‚‰7å€‹ã«å¢—ãˆã‚‹ã“ã¨ã‚’ç¢ºèª"""
        predictor = BostonPredictor()

        X = pd.DataFrame({
            'RM': [6.5],
            'LSTAT': [5.0],
            'PTRATIO': [15.0]
        })

        X_engineered = predictor.feature_engineering(X)

        # å…ƒã®3å€‹ + 2ä¹—é …3å€‹ + äº¤äº’ä½œç”¨é …1å€‹ = 7å€‹
        assert len(X_engineered.columns) == 7
```

**Green: å®Ÿè£…**

```python
def feature_engineering(self, X: pd.DataFrame) -> pd.DataFrame:
    """ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ï¼ˆ2ä¹—é …ã¨äº¤äº’ä½œç”¨é …ã®è¿½åŠ ï¼‰

    Args:
        X: å…ƒã®ç‰¹å¾´é‡ DataFrame

    Returns:
        ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°å¾Œã®ç‰¹å¾´é‡ DataFrame

    Note:
        - 2ä¹—é …: RM2, LSTAT2, PTRATIO2
        - äº¤äº’ä½œç”¨é …: RM * LSTAT
        åˆè¨ˆ7å€‹ã®ç‰¹å¾´é‡ã‚’ç”Ÿæˆ
    """
    X_new = X.copy()

    # 2ä¹—é …ã®è¿½åŠ 
    X_new['RM2'] = X['RM'] ** 2
    X_new['LSTAT2'] = X['LSTAT'] ** 2
    X_new['PTRATIO2'] = X['PTRATIO'] ** 2

    # äº¤äº’ä½œç”¨é …ã®è¿½åŠ 
    X_new['RM * LSTAT'] = X['RM'] * X['LSTAT']

    return X_new
```

##### ã‚¹ãƒ†ãƒƒãƒ— 5: ãƒ‡ãƒ¼ã‚¿æ¨™æº–åŒ–

ç‰¹å¾´é‡ã¨ç›®çš„å¤‰æ•°ã®ä¸¡æ–¹ã‚’æ¨™æº–åŒ–ã—ã¾ã™ã€‚

**Red: ãƒ†ã‚¹ãƒˆã‚’æ›¸ã**

```python
class TestBostonPredictorStandardization:
    """æ¨™æº–åŒ–ã®ãƒ†ã‚¹ãƒˆ"""

    def test_ç‰¹å¾´é‡ã®æ¨™æº–åŒ–_è¨“ç·´ãƒ‡ãƒ¼ã‚¿(self):
        """è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®ç‰¹å¾´é‡ãŒæ¨™æº–åŒ–ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª"""
        predictor = BostonPredictor()

        X_train = pd.DataFrame({
            'RM': [5.0, 6.0, 7.0],
            'LSTAT': [10.0, 20.0, 30.0]
        })

        X_scaled = predictor.standardize_features(X_train, fit=True)

        # æ¨™æº–åŒ–å¾Œã€å¹³å‡ãŒ0ã€æ¨™æº–åå·®ãŒ1ä»˜è¿‘ã«ãªã‚‹ã“ã¨ã‚’ç¢ºèª
        assert abs(X_scaled.mean()) < 0.01
        assert abs(X_scaled.std() - 1.0) < 0.01

    def test_ç‰¹å¾´é‡ã®æ¨™æº–åŒ–_ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿(self):
        """ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ãŒè¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼ã§æ¨™æº–åŒ–ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª"""
        predictor = BostonPredictor()

        X_train = pd.DataFrame({
            'RM': [5.0, 6.0, 7.0]
        })

        X_test = pd.DataFrame({
            'RM': [6.0]
        })

        # è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã§ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼ã‚’ fit
        predictor.standardize_features(X_train, fit=True)

        # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã¯åŒã˜ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼ã§ transform ã®ã¿
        X_test_scaled = predictor.standardize_features(X_test, fit=False)

        # ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼ãŒåŒã˜ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèª
        assert predictor.scaler_X is not None
        # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®å€¤ãŒè¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®çµ±è¨ˆé‡ã§å¤‰æ›ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
        assert X_test_scaled.shape == (1, 1)

    def test_ç›®çš„å¤‰æ•°ã®æ¨™æº–åŒ–(self):
        """ç›®çš„å¤‰æ•°ãŒæ¨™æº–åŒ–ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª"""
        predictor = BostonPredictor()

        y_train = pd.DataFrame({
            'PRICE': [20.0, 25.0, 30.0]
        })

        y_scaled = predictor.standardize_target(y_train, fit=True)

        # æ¨™æº–åŒ–å¾Œã€å¹³å‡ãŒ0ã€æ¨™æº–åå·®ãŒ1ä»˜è¿‘ã«ãªã‚‹ã“ã¨ã‚’ç¢ºèª
        assert abs(y_scaled.mean()) < 0.01
        assert abs(y_scaled.std() - 1.0) < 0.01

    def test_é€†æ¨™æº–åŒ–(self):
        """äºˆæ¸¬çµæœãŒå…ƒã®ã‚¹ã‚±ãƒ¼ãƒ«ã«æˆ»ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª"""
        predictor = BostonPredictor()

        y_train = pd.DataFrame({
            'PRICE': [20.0, 25.0, 30.0]
        })

        # æ¨™æº–åŒ–
        y_scaled = predictor.standardize_target(y_train, fit=True)

        # é€†æ¨™æº–åŒ–
        y_original = predictor.inverse_transform_prediction(y_scaled)

        # å…ƒã®å€¤ã«æˆ»ã‚‹ã“ã¨ã‚’ç¢ºèª
        np.testing.assert_array_almost_equal(y_original.flatten(),
                                             y_train['PRICE'].values,
                                             decimal=5)

    def test_fitå‰ã«transformã™ã‚‹ã¨ã‚¨ãƒ©ãƒ¼(self):
        """fit å‰ã« transform ã—ã‚ˆã†ã¨ã™ã‚‹ã¨ ValueError ã‚’ç™ºç”Ÿ"""
        predictor = BostonPredictor()

        X_test = pd.DataFrame({'RM': [6.0]})

        with pytest.raises(ValueError, match="Scaler not fitted yet"):
            predictor.standardize_features(X_test, fit=False)
```

**Green: å®Ÿè£…**

```python
def standardize_features(self, X: pd.DataFrame, fit: bool = True) -> np.ndarray:
    """ç‰¹å¾´é‡ã‚’æ¨™æº–åŒ–

    Args:
        X: ç‰¹å¾´é‡ DataFrame
        fit: True ã®å ´åˆã¯ fit_transformã€False ã®å ´åˆã¯ transform ã®ã¿

    Returns:
        æ¨™æº–åŒ–ã•ã‚ŒãŸç‰¹å¾´é‡ï¼ˆnumpy é…åˆ—ï¼‰

    Raises:
        ValueError: fit=False ã®å ´åˆã§ scaler_X ãŒæœªè¨­å®šã®å ´åˆ
    """
    if fit:
        self.scaler_X = StandardScaler()
        return self.scaler_X.fit_transform(X)
    else:
        if self.scaler_X is None:
            raise ValueError("Scaler not fitted yet. Call with fit=True first.")
        return self.scaler_X.transform(X)

def standardize_target(self, y: pd.DataFrame, fit: bool = True) -> np.ndarray:
    """ç›®çš„å¤‰æ•°ã‚’æ¨™æº–åŒ–

    Args:
        y: ç›®çš„å¤‰æ•° DataFrame
        fit: True ã®å ´åˆã¯ fit_transformã€False ã®å ´åˆã¯ transform ã®ã¿

    Returns:
        æ¨™æº–åŒ–ã•ã‚ŒãŸç›®çš„å¤‰æ•°ï¼ˆnumpy é…åˆ—ï¼‰

    Raises:
        ValueError: fit=False ã®å ´åˆã§ scaler_y ãŒæœªè¨­å®šã®å ´åˆ
    """
    if fit:
        self.scaler_y = StandardScaler()
        return self.scaler_y.fit_transform(y)
    else:
        if self.scaler_y is None:
            raise ValueError("Scaler not fitted yet. Call with fit=True first.")
        return self.scaler_y.transform(y)

def inverse_transform_prediction(self, y_pred: np.ndarray) -> np.ndarray:
    """äºˆæ¸¬çµæœã‚’å…ƒã®ã‚¹ã‚±ãƒ¼ãƒ«ã«æˆ»ã™

    Args:
        y_pred: æ¨™æº–åŒ–ã•ã‚ŒãŸäºˆæ¸¬çµæœ

    Returns:
        å…ƒã®ã‚¹ã‚±ãƒ¼ãƒ«ã«æˆ»ã•ã‚ŒãŸäºˆæ¸¬çµæœ

    Raises:
        RuntimeError: scaler_y ãŒæœªè¨­å®šã®å ´åˆ
    """
    if self.scaler_y is None:
        raise RuntimeError("scaler_y not set. Train the model first.")

    return self.scaler_y.inverse_transform(y_pred)
```

##### ã‚¹ãƒ†ãƒƒãƒ— 6: ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´

```python
def train(self, X_train: pd.DataFrame, y_train: pd.Series) -> None:
    """ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã™ã‚‹

    Args:
        X_train: è¨“ç·´ç”¨ç‰¹å¾´é‡ï¼ˆæ¨™æº–åŒ–æ¸ˆã¿ï¼‰
        y_train: è¨“ç·´ç”¨ç›®çš„å¤‰æ•°ï¼ˆæ¨™æº–åŒ–æ¸ˆã¿ï¼‰
    """
    self.model = LinearRegression()
    self.model.fit(X_train, y_train)
```

##### ã‚¹ãƒ†ãƒƒãƒ— 7: äºˆæ¸¬ã¨è©•ä¾¡

```python
def predict(self, X_test: np.ndarray) -> np.ndarray:
    """äºˆæ¸¬ã‚’å®Ÿè¡Œã™ã‚‹

    Args:
        X_test: ãƒ†ã‚¹ãƒˆç”¨ç‰¹å¾´é‡ï¼ˆæ¨™æº–åŒ–æ¸ˆã¿ï¼‰

    Returns:
        äºˆæ¸¬çµæœï¼ˆæ¨™æº–åŒ–æ¸ˆã¿ï¼‰

    Raises:
        RuntimeError: ãƒ¢ãƒ‡ãƒ«ãŒè¨“ç·´ã•ã‚Œã¦ã„ãªã„å ´åˆ
    """
    if self.model is None:
        raise RuntimeError("Model has not been trained yet. Call train() first.")

    return self.model.predict(X_test)

def evaluate(self, X_test: np.ndarray, y_test: np.ndarray) -> float:
    """ãƒ¢ãƒ‡ãƒ«ã‚’è©•ä¾¡ã™ã‚‹

    Args:
        X_test: ãƒ†ã‚¹ãƒˆç”¨ç‰¹å¾´é‡ï¼ˆæ¨™æº–åŒ–æ¸ˆã¿ï¼‰
        y_test: ãƒ†ã‚¹ãƒˆç”¨ç›®çš„å¤‰æ•°ï¼ˆæ¨™æº–åŒ–æ¸ˆã¿ï¼‰

    Returns:
        æ±ºå®šä¿‚æ•°ï¼ˆRÂ²ï¼‰

    Raises:
        RuntimeError: ãƒ¢ãƒ‡ãƒ«ãŒè¨“ç·´ã•ã‚Œã¦ã„ãªã„å ´åˆ
    """
    if self.model is None:
        raise RuntimeError("Model has not been trained yet. Call train() first.")

    return self.model.score(X_test, y_test)
```

##### ã‚¹ãƒ†ãƒƒãƒ— 8: ãƒ¢ãƒ‡ãƒ«ã¨ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼ã®æ°¸ç¶šåŒ–

```python
import pickle

def save_models(self, model_path: str, scaler_X_path: str,
                scaler_y_path: str) -> None:
    """ãƒ¢ãƒ‡ãƒ«ã¨ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼ã‚’ä¿å­˜

    Args:
        model_path: ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜å…ˆãƒ‘ã‚¹
        scaler_X_path: ç‰¹å¾´é‡ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼ã®ä¿å­˜å…ˆãƒ‘ã‚¹
        scaler_y_path: ç›®çš„å¤‰æ•°ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼ã®ä¿å­˜å…ˆãƒ‘ã‚¹

    Raises:
        RuntimeError: ãƒ¢ãƒ‡ãƒ«ã¾ãŸã¯ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼ãŒæœªè¨“ç·´ã®å ´åˆ
    """
    if self.model is None:
        raise RuntimeError("Model has not been trained yet.")
    if self.scaler_X is None or self.scaler_y is None:
        raise RuntimeError("Scalers have not been fitted yet.")

    with open(model_path, 'wb') as f:
        pickle.dump(self.model, f)
    with open(scaler_X_path, 'wb') as f:
        pickle.dump(self.scaler_X, f)
    with open(scaler_y_path, 'wb') as f:
        pickle.dump(self.scaler_y, f)

def load_models(self, model_path: str, scaler_X_path: str,
                scaler_y_path: str) -> None:
    """ãƒ¢ãƒ‡ãƒ«ã¨ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼ã‚’èª­ã¿è¾¼ã¿

    Args:
        model_path: ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        scaler_X_path: ç‰¹å¾´é‡ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        scaler_y_path: ç›®çš„å¤‰æ•°ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹

    Raises:
        FileNotFoundError: ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆ
    """
    for path in [model_path, scaler_X_path, scaler_y_path]:
        if not os.path.exists(path):
            raise FileNotFoundError(f"File not found: {path}")

    with open(model_path, 'rb') as f:
        self.model = pickle.load(f)
    with open(scaler_X_path, 'rb') as f:
        self.scaler_X = pickle.load(f)
    with open(scaler_y_path, 'rb') as f:
        self.scaler_y = pickle.load(f)
```

#### å®Œå…¨ãª BostonPredictor å®Ÿè£…

**src/ml/boston_predictor.py** (å®Œå…¨ç‰ˆ):

```python
"""Boston ä½å®…ä¾¡æ ¼äºˆæ¸¬å™¨ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«"""
import os
import pickle
from typing import Optional
import pandas as pd
import numpy as np
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import StandardScaler


class BostonPredictor:
    """ãƒœã‚¹ãƒˆãƒ³å¸‚ã®ä½å®…ä¾¡æ ¼ã‚’äºˆæ¸¬ã™ã‚‹å›å¸°ãƒ¢ãƒ‡ãƒ«

    Attributes:
        model: è¨“ç·´æ¸ˆã¿ã®ç·šå½¢å›å¸°ãƒ¢ãƒ‡ãƒ«ï¼ˆæœªè¨“ç·´æ™‚ã¯ Noneï¼‰
        scaler_X: ç‰¹å¾´é‡ã®æ¨™æº–åŒ–ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼ï¼ˆæœªè¨“ç·´æ™‚ã¯ Noneï¼‰
        scaler_y: ç›®çš„å¤‰æ•°ã®æ¨™æº–åŒ–ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼ï¼ˆæœªè¨“ç·´æ™‚ã¯ Noneï¼‰
        train_mean: è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®å¹³å‡å€¤ï¼ˆæ¬ æå€¤è£œå®Œç”¨ï¼‰

    Example:
        >>> predictor = BostonPredictor()
        >>> df = predictor.load_data('data/Boston.csv')
        >>> # ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†ã¨è¨“ç·´ï¼ˆè©³ç´°ã¯ train_boston.py å‚ç…§ï¼‰
    """

    def __init__(self) -> None:
        """åˆæœŸåŒ–"""
        self.model: Optional[LinearRegression] = None
        self.scaler_X: Optional[StandardScaler] = None
        self.scaler_y: Optional[StandardScaler] = None
        self.train_mean: Optional[pd.Series] = None

    def load_data(self, file_path: str) -> pd.DataFrame:
        """CSV ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€

        Args:
            file_path: CSV ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹

        Returns:
            èª­ã¿è¾¼ã‚“ã  DataFrame

        Raises:
            FileNotFoundError: ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆ
            ValueError: å¿…è¦ãªåˆ—ãŒä¸è¶³ã—ã¦ã„ã‚‹å ´åˆ
        """
        if not os.path.exists(file_path):
            raise FileNotFoundError(f"File not found: {file_path}")

        # ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
        df = pd.read_csv(file_path)

        # å¿…è¦ãªåˆ—ã®å­˜åœ¨ç¢ºèª
        required_columns = ['RM', 'LSTAT', 'PTRATIO', 'CRIME', 'PRICE']
        missing_columns = set(required_columns) - set(df.columns)
        if missing_columns:
            raise ValueError(f"Missing columns: {missing_columns}")

        return df

    def _encode_crime(self, df: pd.DataFrame) -> pd.DataFrame:
        """CRIME åˆ—ã‚’ãƒ€ãƒŸãƒ¼å¤‰æ•°ã«å¤‰æ›

        Args:
            df: å…ƒã® DataFrame

        Returns:
            CRIME ãŒãƒ€ãƒŸãƒ¼å¤‰æ•°åŒ–ã•ã‚ŒãŸ DataFrame

        Note:
            drop_first=True ã«ã‚ˆã‚Šã€æœ€åˆã®ã‚«ãƒ†ã‚´ãƒªï¼ˆã‚¢ãƒ«ãƒ•ã‚¡ãƒ™ãƒƒãƒˆé †ï¼‰ã‚’
            åŸºæº–ã¨ã—ã€ãã‚Œä»¥å¤–ã®ã‚«ãƒ†ã‚´ãƒªã®ãƒ€ãƒŸãƒ¼å¤‰æ•°ã‚’ä½œæˆ
        """
        df_copy = df.copy()

        # CRIME ã‚’ãƒ€ãƒŸãƒ¼å¤‰æ•°åŒ–ï¼ˆdrop_first=Trueï¼‰
        crime_dummies = pd.get_dummies(df_copy['CRIME'], drop_first=True, dtype=int)
        df_encoded = pd.concat([df_copy.drop('CRIME', axis=1), crime_dummies], axis=1)

        return df_encoded

    def _fill_missing_values(self, df: pd.DataFrame, fit: bool = True) -> pd.DataFrame:
        """æ¬ æå€¤ã‚’å¹³å‡å€¤ã§è£œå®Œ

        Args:
            df: å¯¾è±¡ã® DataFrame
            fit: True ã®å ´åˆã¯å¹³å‡å€¤ã‚’è¨ˆç®—ã—ã¦ä¿å­˜ã€False ã®å ´åˆã¯ä¿å­˜æ¸ˆã¿ã®å¹³å‡å€¤ã‚’ä½¿ç”¨

        Returns:
            æ¬ æå€¤ãŒè£œå®Œã•ã‚ŒãŸ DataFrame

        Raises:
            ValueError: fit=False ã®å ´åˆã§ train_mean ãŒæœªè¨­å®šã®å ´åˆ
        """
        if fit:
            # è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®å¹³å‡å€¤ã‚’è¨ˆç®—ã—ã¦ä¿å­˜
            self.train_mean = df.mean()
            return df.fillna(self.train_mean)
        else:
            # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã¯è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®å¹³å‡å€¤ã§è£œå®Œ
            if self.train_mean is None:
                raise ValueError("train_mean not set. Call with fit=True first.")
            return df.fillna(self.train_mean)

    def _remove_outliers(self, df: pd.DataFrame) -> pd.DataFrame:
        """å¤–ã‚Œå€¤ã‚’é™¤å¤–

        Args:
            df: å¯¾è±¡ã® DataFrame

        Returns:
            å¤–ã‚Œå€¤ã‚’é™¤å¤–ã—ãŸ DataFrame

        Note:
            ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ 76 ã®ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆã‚’å¤–ã‚Œå€¤ã¨ã—ã¦é™¤å¤–
        """
        # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ 76 ãŒå­˜åœ¨ã™ã‚‹å ´åˆã®ã¿é™¤å¤–
        if 76 in df.index:
            return df.drop([76], axis=0)
        return df

    def feature_engineering(self, X: pd.DataFrame) -> pd.DataFrame:
        """ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ï¼ˆ2ä¹—é …ã¨äº¤äº’ä½œç”¨é …ã®è¿½åŠ ï¼‰

        Args:
            X: å…ƒã®ç‰¹å¾´é‡ DataFrame

        Returns:
            ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°å¾Œã®ç‰¹å¾´é‡ DataFrame

        Note:
            - 2ä¹—é …: RM2, LSTAT2, PTRATIO2
            - äº¤äº’ä½œç”¨é …: RM * LSTAT
            åˆè¨ˆ7å€‹ã®ç‰¹å¾´é‡ã‚’ç”Ÿæˆ
        """
        X_new = X.copy()

        # 2ä¹—é …ã®è¿½åŠ 
        X_new['RM2'] = X['RM'] ** 2
        X_new['LSTAT2'] = X['LSTAT'] ** 2
        X_new['PTRATIO2'] = X['PTRATIO'] ** 2

        # äº¤äº’ä½œç”¨é …ã®è¿½åŠ 
        X_new['RM * LSTAT'] = X['RM'] * X['LSTAT']

        return X_new

    def standardize_features(self, X: pd.DataFrame, fit: bool = True) -> np.ndarray:
        """ç‰¹å¾´é‡ã‚’æ¨™æº–åŒ–

        Args:
            X: ç‰¹å¾´é‡ DataFrame
            fit: True ã®å ´åˆã¯ fit_transformã€False ã®å ´åˆã¯ transform ã®ã¿

        Returns:
            æ¨™æº–åŒ–ã•ã‚ŒãŸç‰¹å¾´é‡ï¼ˆnumpy é…åˆ—ï¼‰

        Raises:
            ValueError: fit=False ã®å ´åˆã§ scaler_X ãŒæœªè¨­å®šã®å ´åˆ
        """
        if fit:
            self.scaler_X = StandardScaler()
            return self.scaler_X.fit_transform(X)
        else:
            if self.scaler_X is None:
                raise ValueError("Scaler not fitted yet. Call with fit=True first.")
            return self.scaler_X.transform(X)

    def standardize_target(self, y: pd.DataFrame, fit: bool = True) -> np.ndarray:
        """ç›®çš„å¤‰æ•°ã‚’æ¨™æº–åŒ–

        Args:
            y: ç›®çš„å¤‰æ•° DataFrame
            fit: True ã®å ´åˆã¯ fit_transformã€False ã®å ´åˆã¯ transform ã®ã¿

        Returns:
            æ¨™æº–åŒ–ã•ã‚ŒãŸç›®çš„å¤‰æ•°ï¼ˆnumpy é…åˆ—ï¼‰

        Raises:
            ValueError: fit=False ã®å ´åˆã§ scaler_y ãŒæœªè¨­å®šã®å ´åˆ
        """
        if fit:
            self.scaler_y = StandardScaler()
            return self.scaler_y.fit_transform(y)
        else:
            if self.scaler_y is None:
                raise ValueError("Scaler not fitted yet. Call with fit=True first.")
            return self.scaler_y.transform(y)

    def inverse_transform_prediction(self, y_pred: np.ndarray) -> np.ndarray:
        """äºˆæ¸¬çµæœã‚’å…ƒã®ã‚¹ã‚±ãƒ¼ãƒ«ã«æˆ»ã™

        Args:
            y_pred: æ¨™æº–åŒ–ã•ã‚ŒãŸäºˆæ¸¬çµæœ

        Returns:
            å…ƒã®ã‚¹ã‚±ãƒ¼ãƒ«ã«æˆ»ã•ã‚ŒãŸäºˆæ¸¬çµæœ

        Raises:
            RuntimeError: scaler_y ãŒæœªè¨­å®šã®å ´åˆ
        """
        if self.scaler_y is None:
            raise RuntimeError("scaler_y not set. Train the model first.")

        return self.scaler_y.inverse_transform(y_pred)

    def train(self, X_train: np.ndarray, y_train: np.ndarray) -> None:
        """ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´ã™ã‚‹

        Args:
            X_train: è¨“ç·´ç”¨ç‰¹å¾´é‡ï¼ˆæ¨™æº–åŒ–æ¸ˆã¿ï¼‰
            y_train: è¨“ç·´ç”¨ç›®çš„å¤‰æ•°ï¼ˆæ¨™æº–åŒ–æ¸ˆã¿ï¼‰
        """
        self.model = LinearRegression()
        self.model.fit(X_train, y_train)

    def predict(self, X_test: np.ndarray) -> np.ndarray:
        """äºˆæ¸¬ã‚’å®Ÿè¡Œã™ã‚‹

        Args:
            X_test: ãƒ†ã‚¹ãƒˆç”¨ç‰¹å¾´é‡ï¼ˆæ¨™æº–åŒ–æ¸ˆã¿ï¼‰

        Returns:
            äºˆæ¸¬çµæœï¼ˆæ¨™æº–åŒ–æ¸ˆã¿ï¼‰

        Raises:
            RuntimeError: ãƒ¢ãƒ‡ãƒ«ãŒè¨“ç·´ã•ã‚Œã¦ã„ãªã„å ´åˆ
        """
        if self.model is None:
            raise RuntimeError("Model has not been trained yet. Call train() first.")

        return self.model.predict(X_test)

    def evaluate(self, X_test: np.ndarray, y_test: np.ndarray) -> float:
        """ãƒ¢ãƒ‡ãƒ«ã‚’è©•ä¾¡ã™ã‚‹

        Args:
            X_test: ãƒ†ã‚¹ãƒˆç”¨ç‰¹å¾´é‡ï¼ˆæ¨™æº–åŒ–æ¸ˆã¿ï¼‰
            y_test: ãƒ†ã‚¹ãƒˆç”¨ç›®çš„å¤‰æ•°ï¼ˆæ¨™æº–åŒ–æ¸ˆã¿ï¼‰

        Returns:
            æ±ºå®šä¿‚æ•°ï¼ˆRÂ²ï¼‰

        Raises:
            RuntimeError: ãƒ¢ãƒ‡ãƒ«ãŒè¨“ç·´ã•ã‚Œã¦ã„ãªã„å ´åˆ
        """
        if self.model is None:
            raise RuntimeError("Model has not been trained yet. Call train() first.")

        return self.model.score(X_test, y_test)

    def save_models(self, model_path: str, scaler_X_path: str,
                    scaler_y_path: str) -> None:
        """ãƒ¢ãƒ‡ãƒ«ã¨ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼ã‚’ä¿å­˜

        Args:
            model_path: ãƒ¢ãƒ‡ãƒ«ã®ä¿å­˜å…ˆãƒ‘ã‚¹
            scaler_X_path: ç‰¹å¾´é‡ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼ã®ä¿å­˜å…ˆãƒ‘ã‚¹
            scaler_y_path: ç›®çš„å¤‰æ•°ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼ã®ä¿å­˜å…ˆãƒ‘ã‚¹

        Raises:
            RuntimeError: ãƒ¢ãƒ‡ãƒ«ã¾ãŸã¯ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼ãŒæœªè¨“ç·´ã®å ´åˆ
        """
        if self.model is None:
            raise RuntimeError("Model has not been trained yet.")
        if self.scaler_X is None or self.scaler_y is None:
            raise RuntimeError("Scalers have not been fitted yet.")

        with open(model_path, 'wb') as f:
            pickle.dump(self.model, f)
        with open(scaler_X_path, 'wb') as f:
            pickle.dump(self.scaler_X, f)
        with open(scaler_y_path, 'wb') as f:
            pickle.dump(self.scaler_y, f)

    def load_models(self, model_path: str, scaler_X_path: str,
                    scaler_y_path: str) -> None:
        """ãƒ¢ãƒ‡ãƒ«ã¨ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼ã‚’èª­ã¿è¾¼ã¿

        Args:
            model_path: ãƒ¢ãƒ‡ãƒ«ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
            scaler_X_path: ç‰¹å¾´é‡ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
            scaler_y_path: ç›®çš„å¤‰æ•°ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹

        Raises:
            FileNotFoundError: ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„å ´åˆ
        """
        for path in [model_path, scaler_X_path, scaler_y_path]:
            if not os.path.exists(path):
                raise FileNotFoundError(f"File not found: {path}")

        with open(model_path, 'rb') as f:
            self.model = pickle.load(f)
        with open(scaler_X_path, 'rb') as f:
            self.scaler_X = pickle.load(f)
        with open(scaler_y_path, 'rb') as f:
            self.scaler_y = pickle.load(f)
```

#### å®Ÿè·µçš„ãªè¨“ç·´ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

**examples/train_boston.py**:

```python
"""Boston ä½å®…ä¾¡æ ¼äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´ã‚¹ã‚¯ãƒªãƒ—ãƒˆ"""
from sklearn.model_selection import train_test_split
from src.ml.boston_predictor import BostonPredictor


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    # äºˆæ¸¬å™¨ã®ä½œæˆ
    predictor = BostonPredictor()
    print("BostonPredictor ã‚’ä½œæˆã—ã¾ã—ãŸ")

    # ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿
    df = predictor.load_data('data/Boston.csv')
    print(f"ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ: {len(df)} ã‚µãƒ³ãƒ—ãƒ«")

    # CRIME åˆ—ã®ãƒ€ãƒŸãƒ¼å¤‰æ•°åŒ–
    df = predictor._encode_crime(df)
    print("CRIME åˆ—ã‚’ãƒ€ãƒŸãƒ¼å¤‰æ•°åŒ–ã—ã¾ã—ãŸ")

    # è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã¨ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã«åˆ†å‰²
    df_train, df_test = train_test_split(df, test_size=0.2, random_state=0)
    print(f"è¨“ç·´ãƒ‡ãƒ¼ã‚¿: {len(df_train)} ã‚µãƒ³ãƒ—ãƒ«")
    print(f"ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: {len(df_test)} ã‚µãƒ³ãƒ—ãƒ«")

    # è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†
    df_train = predictor._fill_missing_values(df_train, fit=True)
    df_train = predictor._remove_outliers(df_train)
    print(f"å‰å‡¦ç†å¾Œã®è¨“ç·´ãƒ‡ãƒ¼ã‚¿: {len(df_train)} ã‚µãƒ³ãƒ—ãƒ«")

    # ç‰¹å¾´é‡ã¨ç›®çš„å¤‰æ•°ã®åˆ†å‰²
    X_train = df_train[['RM', 'LSTAT', 'PTRATIO']]
    y_train = df_train[['PRICE']]

    # ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°
    X_train = predictor.feature_engineering(X_train)
    print(f"ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°å®Œäº†: {len(X_train.columns)} å€‹ã®ç‰¹å¾´é‡")

    # æ¨™æº–åŒ–
    X_train_scaled = predictor.standardize_features(X_train, fit=True)
    y_train_scaled = predictor.standardize_target(y_train, fit=True)
    print("è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®æ¨™æº–åŒ–ãŒå®Œäº†ã—ã¾ã—ãŸ")

    # ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´
    predictor.train(X_train_scaled, y_train_scaled)
    print("ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´ãŒå®Œäº†ã—ã¾ã—ãŸ")

    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†
    df_test = predictor._fill_missing_values(df_test, fit=False)
    X_test = df_test[['RM', 'LSTAT', 'PTRATIO']]
    y_test = df_test[['PRICE']]

    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°
    X_test = predictor.feature_engineering(X_test)

    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®æ¨™æº–åŒ–
    X_test_scaled = predictor.standardize_features(X_test, fit=False)
    y_test_scaled = predictor.standardize_target(y_test, fit=False)
    print("ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®æ¨™æº–åŒ–ãŒå®Œäº†ã—ã¾ã—ãŸ")

    # ãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡
    r2_score = predictor.evaluate(X_test_scaled, y_test_scaled)
    print(f"\n[ãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡]")
    print(f"  æ±ºå®šä¿‚æ•°ï¼ˆRÂ²ï¼‰: {r2_score:.4f}")

    # ãƒ¢ãƒ‡ãƒ«ã¨ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼ã®ä¿å­˜
    predictor.save_models(
        'model/boston.pkl',
        'model/boston_scx.pkl',
        'model/boston_scy.pkl'
    )
    print("\nãƒ¢ãƒ‡ãƒ«ã¨ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼ã‚’ä¿å­˜ã—ã¾ã—ãŸ:")
    print("  - model/boston.pkl")
    print("  - model/boston_scx.pkl")
    print("  - model/boston_scy.pkl")

    # äºˆæ¸¬ä¾‹
    print("\n[äºˆæ¸¬ä¾‹]")
    sample_indices = X_test.index[:3]
    sample_X = X_test_scaled[list(sample_indices)]
    predictions_scaled = predictor.predict(sample_X)

    # äºˆæ¸¬çµæœã‚’å…ƒã®ã‚¹ã‚±ãƒ¼ãƒ«ã«æˆ»ã™
    predictions = predictor.inverse_transform_prediction(predictions_scaled)

    for i, idx in enumerate(sample_indices):
        actual = y_test.loc[idx, 'PRICE']
        predicted = predictions[i][0]
        error = abs(actual - predicted)
        error_rate = (error / actual) * 100

        print(f"\nã‚µãƒ³ãƒ—ãƒ« {i+1}:")
        print(f"  RM: {df_test.loc[idx, 'RM']:.2f}")
        print(f"  LSTAT: {df_test.loc[idx, 'LSTAT']:.2f}")
        print(f"  PTRATIO: {df_test.loc[idx, 'PTRATIO']:.2f}")
        print(f"  å®Ÿéš›ã®ä¾¡æ ¼: ${actual:.2f}k")
        print(f"  äºˆæ¸¬ä¾¡æ ¼: ${predicted:.2f}k")
        print(f"  èª¤å·®: ${error:.2f}k ({error_rate:.1f}%)")


if __name__ == '__main__':
    main()
```

å®Ÿè¡Œä¾‹ï¼š

```bash
uv run python examples/train_boston.py

# å‡ºåŠ›ä¾‹ï¼š
# BostonPredictor ã‚’ä½œæˆã—ã¾ã—ãŸ
# ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ: 506 ã‚µãƒ³ãƒ—ãƒ«
# CRIME åˆ—ã‚’ãƒ€ãƒŸãƒ¼å¤‰æ•°åŒ–ã—ã¾ã—ãŸ
# è¨“ç·´ãƒ‡ãƒ¼ã‚¿: 404 ã‚µãƒ³ãƒ—ãƒ«
# ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: 102 ã‚µãƒ³ãƒ—ãƒ«
# å‰å‡¦ç†å¾Œã®è¨“ç·´ãƒ‡ãƒ¼ã‚¿: 403 ã‚µãƒ³ãƒ—ãƒ«
# ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°å®Œäº†: 7 å€‹ã®ç‰¹å¾´é‡
# è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®æ¨™æº–åŒ–ãŒå®Œäº†ã—ã¾ã—ãŸ
# ãƒ¢ãƒ‡ãƒ«ã®è¨“ç·´ãŒå®Œäº†ã—ã¾ã—ãŸ
# ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®æ¨™æº–åŒ–ãŒå®Œäº†ã—ã¾ã—ãŸ
#
# [ãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡]
#   æ±ºå®šä¿‚æ•°ï¼ˆRÂ²ï¼‰: 0.8313
#
# ãƒ¢ãƒ‡ãƒ«ã¨ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼ã‚’ä¿å­˜ã—ã¾ã—ãŸ:
#   - model/boston.pkl
#   - model/boston_scx.pkl
#   - model/boston_scy.pkl
#
# [äºˆæ¸¬ä¾‹]
#
# ã‚µãƒ³ãƒ—ãƒ« 1:
#   RM: 6.42
#   LSTAT: 9.32
#   PTRATIO: 18.70
#   å®Ÿéš›ã®ä¾¡æ ¼: $23.60k
#   äºˆæ¸¬ä¾¡æ ¼: $24.15k
#   èª¤å·®: $0.55k (2.3%)
#
# ã‚µãƒ³ãƒ—ãƒ« 2:
#   RM: 6.00
#   LSTAT: 12.43
#   PTRATIO: 15.20
#   å®Ÿéš›ã®ä¾¡æ ¼: $20.10k
#   äºˆæ¸¬ä¾¡æ ¼: $19.87k
#   èª¤å·®: $0.23k (1.1%)
#
# ã‚µãƒ³ãƒ—ãƒ« 3:
#   RM: 7.18
#   LSTAT: 4.03
#   PTRATIO: 17.40
#   å®Ÿéš›ã®ä¾¡æ ¼: $35.40k
#   äºˆæ¸¬ä¾¡æ ¼: $34.92k
#   èª¤å·®: $0.48k (1.4%)
```

### ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ 5 ã®æŠ€è¡“çš„æˆæœ

#### å®Œæˆã—ãŸæ©Ÿèƒ½

- âœ… Boston äºˆæ¸¬å™¨ã‚¯ãƒ©ã‚¹ã®å®Œå…¨å®Ÿè£…
- âœ… CRIME åˆ—ã®ãƒ€ãƒŸãƒ¼å¤‰æ•°åŒ–
- âœ… ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚±ãƒ¼ã‚¸é˜²æ­¢ã®å‰å‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
- âœ… ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ï¼ˆ2ä¹—é … + äº¤äº’ä½œç”¨é …ï¼‰
- âœ… StandardScaler ã«ã‚ˆã‚‹æ¨™æº–åŒ–
- âœ… è¤‡æ•°ãƒ¢ãƒ‡ãƒ«ã®ä¸€æ‹¬ç®¡ç†ï¼ˆmodel + 2ã¤ã®scalerï¼‰
- âœ… é€†æ¨™æº–åŒ–ã«ã‚ˆã‚‹äºˆæ¸¬çµæœã®å¾©å…ƒ

#### å®šé‡çš„æˆæœ

| æŒ‡æ¨™ | å®Ÿç¸¾ |
|------|------|
| **ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹** | 25å€‹ |
| **ã‚³ãƒ¼ãƒ‰ã‚«ãƒãƒ¬ãƒƒã‚¸** | 94%ï¼ˆboston_predictor.pyï¼‰ |
| **å‹ãƒ’ãƒ³ãƒˆä½¿ç”¨ç‡** | 100% |
| **ãƒ¢ãƒ‡ãƒ«æ±ºå®šä¿‚æ•°** | 0.8313ï¼ˆãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ï¼‰ |
| **ç‰¹å¾´é‡æ•°** | 3å€‹ â†’ 7å€‹ï¼ˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°å¾Œï¼‰ |
| **ä¿å­˜ãƒ¢ãƒ‡ãƒ«æ•°** | 3å€‹ï¼ˆmodel, scaler_X, scaler_yï¼‰ |
| **Ruff ãƒã‚§ãƒƒã‚¯** | å…¨ã¦é€šé |
| **mypy ãƒã‚§ãƒƒã‚¯** | ã‚¨ãƒ©ãƒ¼ 0ä»¶ |
| **å¾ªç’°çš„è¤‡é›‘åº¦** | æœ€å¤§ 4ï¼ˆå…¨é–¢æ•°ï¼‰ |

#### ç¿’å¾—ã—ãŸã‚¹ã‚­ãƒ«

**1. TDD ã‚¹ã‚­ãƒ«ï¼ˆæœ€ä¸Šç´šï¼‰**
- æ¨™æº–åŒ–å‡¦ç†ã®ãƒ†ã‚¹ãƒˆé§†å‹•å®Ÿè£…
- fit ã¨ transform ã®åˆ†é›¢ãƒ†ã‚¹ãƒˆ
- è¤‡æ•°ãƒ¢ãƒ‡ãƒ«ã®æ°¸ç¶šåŒ–ãƒ†ã‚¹ãƒˆ

**2. ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã‚¹ã‚­ãƒ«**
- 2ä¹—é …ã«ã‚ˆã‚‹éç·šå½¢æ€§ã®è¡¨ç¾
- äº¤äº’ä½œç”¨é …ã«ã‚ˆã‚‹ç‰¹å¾´é‡é–“ã®é–¢ä¿‚è¡¨ç¾
- ç‰¹å¾´é‡æ•°ã®æœ€é©åŒ–

**3. ãƒ‡ãƒ¼ã‚¿æ¨™æº–åŒ–ã‚¹ã‚­ãƒ«**
- StandardScaler ã®ä½¿ã„æ–¹
- è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã¨ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®åˆ†é›¢
- é€†æ¨™æº–åŒ–ã«ã‚ˆã‚‹äºˆæ¸¬çµæœã®å¾©å…ƒ

**4. é«˜åº¦ãªãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚¹ã‚­ãƒ«**
- ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚±ãƒ¼ã‚¸ã®é˜²æ­¢
- è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®çµ±è¨ˆé‡ã«ã‚ˆã‚‹ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿å‡¦ç†
- è¤‡æ•°ã‚¹ãƒ†ãƒƒãƒ—ã®å‰å‡¦ç†ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³

**5. ãƒ¢ãƒ‡ãƒ«ç®¡ç†ã‚¹ã‚­ãƒ«**
- è¤‡æ•°ãƒ¢ãƒ‡ãƒ«ã®ä¸€æ‹¬ä¿å­˜ã¨èª­ã¿è¾¼ã¿
- ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼ã®æ°¸ç¶šåŒ–
- è¨“ç·´æ™‚ã®çµ±è¨ˆé‡ã®ä¿å­˜

#### ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã®ç†è§£

**ãªãœç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ãŒå¿…è¦ã‹**:

```python
# å…ƒã®ç·šå½¢ãƒ¢ãƒ‡ãƒ«:
# PRICE = Î²â‚€ + Î²â‚Ã—RM + Î²â‚‚Ã—LSTAT + Î²â‚ƒÃ—PTRATIO

# å•é¡Œ: ç·šå½¢é–¢ä¿‚ã—ã‹è¡¨ç¾ã§ããªã„
# â†’ å®Ÿéš›ã®ä½å®…ä¾¡æ ¼ã¯éç·šå½¢ãªé–¢ä¿‚ã‚’æŒã¤

# ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°å¾Œ:
# PRICE = Î²â‚€ + Î²â‚Ã—RM + Î²â‚‚Ã—RMÂ² + Î²â‚ƒÃ—LSTAT + Î²â‚„Ã—LSTATÂ² +
#         Î²â‚…Ã—PTRATIO + Î²â‚†Ã—PTRATIOÂ² + Î²â‚‡Ã—(RM Ã— LSTAT)

# åˆ©ç‚¹:
# - RMÂ² ã«ã‚ˆã‚Šã€Œéƒ¨å±‹æ•°ãŒå¤šã„ã»ã©ä¾¡æ ¼ãŒæ€¥ä¸Šæ˜‡ã€ã‚’è¡¨ç¾
# - RM Ã— LSTAT ã«ã‚ˆã‚Šã€Œéƒ¨å±‹æ•°ã¨ä½æ‰€å¾—è€…å‰²åˆã®ç›¸äº’ä½œç”¨ã€ã‚’è¡¨ç¾
# â†’ ã‚ˆã‚Šè¤‡é›‘ãªé–¢ä¿‚ã‚’ç·šå½¢ãƒ¢ãƒ‡ãƒ«ã§è¡¨ç¾å¯èƒ½
```

**2ä¹—é …ã®åŠ¹æœ**:

```python
# ä¾‹: RMï¼ˆéƒ¨å±‹æ•°ï¼‰ã¨ä¾¡æ ¼ã®é–¢ä¿‚

# ç·šå½¢é …ã®ã¿: PRICE = 10Ã—RM
# RM=5: PRICE = 50
# RM=6: PRICE = 60 (+10)
# RM=7: PRICE = 70 (+10)
# â†’ éƒ¨å±‹æ•°ãŒ1å¢—ãˆã‚‹ã¨ä¸€å®šé¡ï¼ˆ10kï¼‰å¢—åŠ 

# 2ä¹—é …è¿½åŠ : PRICE = 10Ã—RM + 2Ã—RMÂ²
# RM=5: PRICE = 50 + 50 = 100
# RM=6: PRICE = 60 + 72 = 132 (+32)
# RM=7: PRICE = 70 + 98 = 168 (+36)
# â†’ éƒ¨å±‹æ•°ãŒå¤šã„ã»ã©ä¾¡æ ¼ã®ä¸Šæ˜‡å¹…ãŒå¤§ãã„ï¼ˆç¾å®Ÿçš„ï¼‰
```

**äº¤äº’ä½œç”¨é …ã®åŠ¹æœ**:

```python
# RMï¼ˆéƒ¨å±‹æ•°ï¼‰ã¨ LSTATï¼ˆä½æ‰€å¾—è€…å‰²åˆï¼‰ã®äº¤äº’ä½œç”¨

# äº¤äº’ä½œç”¨é …ãªã—:
# â†’ RM ã¨ LSTAT ãŒç‹¬ç«‹ã«ä¾¡æ ¼ã«å½±éŸ¿

# äº¤äº’ä½œç”¨é …ã‚ã‚Š: RM Ã— LSTAT
# â†’ ã€Œé«˜ç´šä½å®…åœ°ï¼ˆLSTATä½ï¼‰ã§ã¯éƒ¨å±‹æ•°ã®å½±éŸ¿ãŒå¤§ãã„ã€
# â†’ ã€Œä½æ‰€å¾—åœ°åŒºï¼ˆLSTATé«˜ï¼‰ã§ã¯éƒ¨å±‹æ•°ã®å½±éŸ¿ãŒå°ã•ã„ã€
# â†’ ã‚ˆã‚Šç¾å®Ÿçš„ãªé–¢ä¿‚ã‚’è¡¨ç¾
```

#### ãƒ‡ãƒ¼ã‚¿æ¨™æº–åŒ–ã®ç†è§£

**ãªãœæ¨™æº–åŒ–ãŒå¿…è¦ã‹**:

```python
# æ¨™æº–åŒ–å‰ã®ç‰¹å¾´é‡:
# RM: 3ã€œ9ï¼ˆç¯„å›²: 6ï¼‰
# LSTAT: 1ã€œ40ï¼ˆç¯„å›²: 39ï¼‰
# PTRATIO: 12ã€œ22ï¼ˆç¯„å›²: 10ï¼‰

# å•é¡Œ:
# 1. å­¦ç¿’ãŒä¸å®‰å®šã«ãªã‚‹ï¼ˆå‹¾é…é™ä¸‹æ³•ãŒåæŸã—ã«ãã„ï¼‰
# 2. LSTAT ã®å½±éŸ¿ãŒéå¤§è©•ä¾¡ã•ã‚Œã‚‹ï¼ˆã‚¹ã‚±ãƒ¼ãƒ«ãŒå¤§ãã„ãŸã‚ï¼‰
# 3. ä¿‚æ•°ã®è§£é‡ˆãŒå›°é›£ï¼ˆå˜ä½ãŒç•°ãªã‚‹ï¼‰

# æ¨™æº–åŒ–å¾Œ:
# ã™ã¹ã¦ã®ç‰¹å¾´é‡ãŒå¹³å‡0ã€æ¨™æº–åå·®1
# â†’ å…¬å¹³ãªæ¯”è¼ƒãŒå¯èƒ½
# â†’ å­¦ç¿’ãŒå®‰å®š
```

**æ¨™æº–åŒ–ã®æ•°å¼**:

```
z = (x - Î¼) / Ïƒ

where:
  z: æ¨™æº–åŒ–å¾Œã®å€¤
  x: å…ƒã®å€¤
  Î¼: å¹³å‡å€¤
  Ïƒ: æ¨™æº–åå·®

ä¾‹:
RM ã®å¹³å‡ãŒ6.0ã€æ¨™æº–åå·®ãŒ1.0ã®å ´åˆ
RM = 7.0 â†’ z = (7.0 - 6.0) / 1.0 = 1.0
RM = 5.0 â†’ z = (5.0 - 6.0) / 1.0 = -1.0
```

**ç›®çš„å¤‰æ•°ã®æ¨™æº–åŒ–**:

```python
# ç›®çš„å¤‰æ•°ï¼ˆPRICEï¼‰ã‚‚æ¨™æº–åŒ–ã™ã‚‹ç†ç”±:

# 1. å­¦ç¿’ã®å®‰å®šæ€§å‘ä¸Š
#    â†’ ç‰¹å¾´é‡ã¨ç›®çš„å¤‰æ•°ã®ã‚¹ã‚±ãƒ¼ãƒ«ãŒè¿‘ã„æ–¹ãŒå­¦ç¿’ã—ã‚„ã™ã„

# 2. æ•°å€¤è¨ˆç®—ã®ç²¾åº¦å‘ä¸Š
#    â†’ ã‚ªãƒ¼ãƒãƒ¼ãƒ•ãƒ­ãƒ¼ã‚„ã‚¢ãƒ³ãƒ€ãƒ¼ãƒ•ãƒ­ãƒ¼ã‚’é˜²ã

# 3. é€†æ¨™æº–åŒ–ã§å…ƒã®ã‚¹ã‚±ãƒ¼ãƒ«ã«æˆ»ã™
#    â†’ äºˆæ¸¬çµæœã¯å…ƒã®å˜ä½ï¼ˆ$1000ï¼‰ã§è§£é‡ˆ
```

#### ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚±ãƒ¼ã‚¸é˜²æ­¢ã®ç†è§£

**ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚±ãƒ¼ã‚¸ã¨ã¯**:

```python
# âŒ æ‚ªã„ä¾‹ï¼ˆãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚±ãƒ¼ã‚¸ã‚ã‚Šï¼‰

# 1. å…¨ãƒ‡ãƒ¼ã‚¿ã§æ¬ æå€¤è£œå®Œ
df_all = df_all.fillna(df_all.mean())  # å…¨ãƒ‡ãƒ¼ã‚¿ã®å¹³å‡ã‚’ä½¿ç”¨

# 2. ãƒ‡ãƒ¼ã‚¿åˆ†å‰²
df_train, df_test = train_test_split(df_all)

# å•é¡Œ: ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®æƒ…å ±ï¼ˆå¹³å‡å€¤ã®è¨ˆç®—ï¼‰ãŒè¨“ç·´ã«æ¼ã‚Œã¦ã„ã‚‹
# â†’ ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®æ€§èƒ½ãŒéå¤§è©•ä¾¡ã•ã‚Œã‚‹

# âœ… è‰¯ã„ä¾‹ï¼ˆãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚±ãƒ¼ã‚¸ãªã—ï¼‰

# 1. ãƒ‡ãƒ¼ã‚¿åˆ†å‰²
df_train, df_test = train_test_split(df)

# 2. è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã§çµ±è¨ˆé‡ã‚’è¨ˆç®—
train_mean = df_train.mean()

# 3. è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã¨ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’åˆ¥ã€…ã«è£œå®Œ
df_train = df_train.fillna(train_mean)  # è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®å¹³å‡ã‚’ä½¿ç”¨
df_test = df_test.fillna(train_mean)    # è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®å¹³å‡ã‚’ä½¿ç”¨ï¼ˆé‡è¦ï¼‰

# åˆ©ç‚¹: ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®æƒ…å ±ã¯ä¸€åˆ‡ä½¿ã‚ãªã„
# â†’ æœ¬ç•ªç’°å¢ƒã§ã®æ€§èƒ½ã‚’æ­£ç¢ºã«è©•ä¾¡ã§ãã‚‹
```

**æ¨™æº–åŒ–ã§ã®ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚±ãƒ¼ã‚¸é˜²æ­¢**:

```python
# âŒ æ‚ªã„ä¾‹
scaler = StandardScaler()
X_all_scaled = scaler.fit_transform(X_all)  # å…¨ãƒ‡ãƒ¼ã‚¿ã§ fit
X_train, X_test = train_test_split(X_all_scaled)

# âœ… è‰¯ã„ä¾‹
X_train, X_test = train_test_split(X)

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)  # è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã§ fit
X_test_scaled = scaler.transform(X_test)        # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã¯ transform ã®ã¿

# é‡è¦: ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã¯è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã®å¹³å‡ãƒ»æ¨™æº–åå·®ã§å¤‰æ›
# â†’ æœ¬ç•ªç’°å¢ƒã‚’æ­£ç¢ºã«ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ãƒˆ
```

#### å›å¸°ãƒ¢ãƒ‡ãƒ«ã®æ¯”è¼ƒï¼ˆCinema vs Bostonï¼‰

| é …ç›® | Cinemaï¼ˆåŸºç¤ï¼‰ | **Bostonï¼ˆé«˜åº¦ï¼‰** |
|------|---------------|-------------------|
| **ãƒ¢ãƒ‡ãƒ«** | LinearRegression | LinearRegression |
| **ç‰¹å¾´é‡æ•°** | 4å€‹ | **7å€‹ï¼ˆ3å€‹â†’ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ï¼‰** |
| **å‰å‡¦ç†** | æ¬ æå€¤è£œå®Œ + å¤–ã‚Œå€¤é™¤å¤– | **æ¬ æå€¤è£œå®Œ + å¤–ã‚Œå€¤é™¤å¤– + ãƒ€ãƒŸãƒ¼å¤‰æ•°åŒ–** |
| **ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°** | ãªã— | **2ä¹—é … + äº¤äº’ä½œç”¨é …** |
| **æ¨™æº–åŒ–** | ãªã— | **StandardScalerï¼ˆç‰¹å¾´é‡ + ç›®çš„å¤‰æ•°ï¼‰** |
| **ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚±ãƒ¼ã‚¸é˜²æ­¢** | éƒ¨åˆ†çš„ | **å®Œå…¨** |
| **ä¿å­˜ãƒ¢ãƒ‡ãƒ«æ•°** | 1å€‹ | **3å€‹ï¼ˆmodel + 2 scalersï¼‰** |
| **æ±ºå®šä¿‚æ•°** | 0.8383 | **0.8313** |
| **ãƒ†ã‚¹ãƒˆæ•°** | 20å€‹ | **25å€‹** |

**æ±ºå®šä¿‚æ•°ãŒè‹¥å¹²ä½ã„ç†ç”±**:

- Cinema: ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã€æ˜ç¢ºãªç‰¹å¾´é‡ï¼ˆSNSæŒ‡æ¨™ï¼‰
- Boston: è¤‡é›‘ãªç¤¾ä¼šçµŒæ¸ˆè¦å› ã€å¤šæ§˜ãªå¤–éƒ¨å¤‰æ•°ã®å½±éŸ¿

#### æ¬¡ã®ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã¸ã®æº–å‚™

ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ 6 ã§ã¯ã€ä»¥ä¸‹ã‚’å®Ÿè£…ã—ã¾ã™ï¼š

- FastAPI ã«ã‚ˆã‚‹æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã® API åŒ–
- ãƒ¬ã‚¤ãƒ¤ãƒ¼ãƒ‰ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®å®Ÿè£…ï¼ˆApplication / Service / Domainï¼‰
- 4ã¤ã®ãƒ¢ãƒ‡ãƒ«ã®çµ±åˆã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
- Pydantic ã«ã‚ˆã‚‹å…¥åŠ›æ¤œè¨¼
- Swagger UI ã«ã‚ˆã‚‹ API ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆè‡ªå‹•ç”Ÿæˆ

---

## ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ 6: API åŒ–ã¨ã¾ã¨ã‚

### æ¦‚è¦ã¨å­¦ç¿’ç›®æ¨™

ã“ã‚Œã¾ã§ã®ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã§ã€4ã¤ã®æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ï¼ˆIris åˆ†é¡ã€Cinema å›å¸°ã€Survived åˆ†é¡ã€Boston å›å¸°ï¼‰ã‚’TDDã§é–‹ç™ºã—ã¦ãã¾ã—ãŸã€‚ã“ã®ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã§ã¯ã€ã“ã‚Œã‚‰ã®ãƒ¢ãƒ‡ãƒ«ã‚’å®Ÿéš›ã®Webã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã§åˆ©ç”¨ã§ãã‚‹ã‚ˆã†ã€**FastAPI**ã‚’ä½¿ã£ã¦RESTful APIã¨ã—ã¦å…¬é–‹ã—ã¾ã™ã€‚

#### å­¦ç¿’ç›®æ¨™

- **FastAPI ã«ã‚ˆã‚‹ Web API é–‹ç™º**: ãƒ¢ãƒ€ãƒ³ãª Python Web ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯ã®ç¿’å¾—
- **Pydantic ã«ã‚ˆã‚‹ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼**: ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®å‹å®‰å…¨æ€§ç¢ºä¿
- **ãƒ¬ã‚¤ãƒ¤ãƒ¼ãƒ‰ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®å®Ÿè·µ**: Application/Service/Domain ã® 3 å±¤æ§‹é€ 
- **OpenAPI ä»•æ§˜ã®è‡ªå‹•ç”Ÿæˆ**: Swagger UI ã«ã‚ˆã‚‹ API ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ
- **æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®æœ¬ç•ªé‹ç”¨**: pickle ã«ã‚ˆã‚‹ãƒ¢ãƒ‡ãƒ«æ°¸ç¶šåŒ–ã¨èª­ã¿è¾¼ã¿

#### APIåŒ–ã®é‡è¦æ€§

æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã‚’å®Ÿéš›ã®ãƒ“ã‚¸ãƒã‚¹ã§æ´»ç”¨ã™ã‚‹ã«ã¯ã€ä»¥ä¸‹ãŒå¿…è¦ã§ã™ï¼š

1. **ã‚¢ã‚¯ã‚»ã‚¹å¯èƒ½æ€§**: Web API ã¨ã—ã¦å…¬é–‹ã—ã€ä»–ã®ã‚·ã‚¹ãƒ†ãƒ ã‹ã‚‰åˆ©ç”¨å¯èƒ½ã«
2. **ãƒ‡ãƒ¼ã‚¿æ¤œè¨¼**: ä¸æ­£ãªå…¥åŠ›ã‚’å—ã‘ä»˜ã‘ãªã„ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³æ©Ÿèƒ½
3. **ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ**: åˆ©ç”¨æ–¹æ³•ã‚’æ˜ç¢ºã«ç¤ºã™ä»•æ§˜æ›¸
4. **ä¿å®ˆæ€§**: ãƒ¬ã‚¤ãƒ¤ãƒ¼åˆ†é›¢ã«ã‚ˆã‚‹å¤‰æ›´å®¹æ˜“æ€§

### FastAPI ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ 

```text
ml-api-project/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ application.py      # ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å±¤ï¼ˆã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆå®šç¾©ï¼‰
â”‚   â”œâ”€â”€ service.py          # ã‚µãƒ¼ãƒ“ã‚¹å±¤ï¼ˆãƒ“ã‚¸ãƒã‚¹ãƒ­ã‚¸ãƒƒã‚¯ï¼‰
â”‚   â”œâ”€â”€ domain.py           # ãƒ‰ãƒ¡ã‚¤ãƒ³å±¤ï¼ˆãƒ¢ãƒ‡ãƒ«å‡¦ç†ï¼‰
â”‚   â””â”€â”€ models.py           # Pydantic ãƒ¢ãƒ‡ãƒ«å®šç¾©
â”œâ”€â”€ test/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ test_application.py # API ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®ãƒ†ã‚¹ãƒˆ
â”‚   â”œâ”€â”€ test_service.py     # ã‚µãƒ¼ãƒ“ã‚¹å±¤ã®ãƒ†ã‚¹ãƒˆ
â”‚   â””â”€â”€ test_domain.py      # ãƒ‰ãƒ¡ã‚¤ãƒ³å±¤ã®ãƒ†ã‚¹ãƒˆ
â”œâ”€â”€ model/
â”‚   â”œâ”€â”€ iris.pkl            # è¨“ç·´æ¸ˆã¿ Iris ãƒ¢ãƒ‡ãƒ«
â”‚   â”œâ”€â”€ cinema.pkl          # è¨“ç·´æ¸ˆã¿ Cinema ãƒ¢ãƒ‡ãƒ«
â”‚   â”œâ”€â”€ survived.pkl        # è¨“ç·´æ¸ˆã¿ Survived ãƒ¢ãƒ‡ãƒ«
â”‚   â””â”€â”€ boston.pkl          # è¨“ç·´æ¸ˆã¿ Boston ãƒ¢ãƒ‡ãƒ«
â””â”€â”€ pyproject.toml
```

### ãƒ¬ã‚¤ãƒ¤ãƒ¼ãƒ‰ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®æ¦‚å¿µ

```plantuml
@startuml
left to right direction

actor "ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ" as Client

rectangle "FastAPI Application" as App {
  component "application.py\n(ãƒ—ãƒ¬ã‚¼ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³å±¤)" as Main #lightblue
  component "service.py\n(ã‚µãƒ¼ãƒ“ã‚¹å±¤)" as Service #lightgreen
  component "domain.py\n(ãƒ‰ãƒ¡ã‚¤ãƒ³å±¤)" as Domain #lightyellow
}

rectangle "Machine Learning Models" as ML {
  database "iris.pkl"
  database "cinema.pkl"
  database "survived.pkl"
  database "boston.pkl"
}

Client --> Main : HTTP Request\n(JSON)
Main -> Service : predict(...)
Service -> Domain : predict(...)
Domain --> ML : load model
ML --> Domain : model
Domain --> Service : result
Service --> Main : result
Main --> Client : HTTP Response\n(JSON)

note right of Main
  - ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆå®šç¾©
  - ãƒªã‚¯ã‚¨ã‚¹ãƒˆ/ãƒ¬ã‚¹ãƒãƒ³ã‚¹å‡¦ç†
  - Pydantic ãƒ¢ãƒ‡ãƒ«ã«ã‚ˆã‚‹æ¤œè¨¼
end note

note right of Service
  - ãƒ“ã‚¸ãƒã‚¹ãƒ­ã‚¸ãƒƒã‚¯
  - ãƒ‡ãƒ¼ã‚¿å¤‰æ›
  - ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°
end note

note right of Domain
  - ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿
  - äºˆæ¸¬å®Ÿè¡Œ
  - å‰å‡¦ç†ãƒ»å¾Œå‡¦ç†
end note

@enduml
```

**å„å±¤ã®è²¬å‹™**ï¼š

| å±¤ | è²¬å‹™ | æŠ€è¡“è¦ç´  |
|---|---|---|
| **Application å±¤** | HTTP ãƒªã‚¯ã‚¨ã‚¹ãƒˆ/ãƒ¬ã‚¹ãƒãƒ³ã‚¹å‡¦ç† | FastAPIã€Pydantic |
| **Service å±¤** | ãƒ“ã‚¸ãƒã‚¹ãƒ­ã‚¸ãƒƒã‚¯ã€ãƒ‡ãƒ¼ã‚¿å¤‰æ› | Python ãƒ­ã‚¸ãƒƒã‚¯ |
| **Domain å±¤** | ãƒ¢ãƒ‡ãƒ«æ“ä½œã€æ©Ÿæ¢°å­¦ç¿’å‡¦ç† | scikit-learnã€pickle |

### TDD ã«ã‚ˆã‚‹å®Ÿè£…

#### ã‚¹ãƒ†ãƒƒãƒ— 1: Pydantic ãƒ¢ãƒ‡ãƒ«ã®å®šç¾©ï¼ˆRed â†’ Green â†’ Refactorï¼‰

ã¾ãšã€å„ API ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã§å—ã‘å–ã‚‹ãƒ‡ãƒ¼ã‚¿ã®å‹ã‚’å®šç¾©ã—ã¾ã™ã€‚

**Redï¼ˆå¤±æ•—ã™ã‚‹ãƒ†ã‚¹ãƒˆï¼‰**:

```python
# test/test_models.py
import pytest
from app.models import IrisModel, CinemaModel, SurvivedModel, BostonModel

def test_IrisModelã®æ­£å¸¸ãªå€¤():
    """æ­£ã—ã„å€¤ã§IrisModelã‚’ä½œæˆã§ãã‚‹"""
    model = IrisModel(
        sepal_length=5.1,
        sepal_width=3.5,
        petal_length=1.4,
        petal_width=0.2
    )

    assert model.sepal_length == 5.1
    assert model.sepal_width == 3.5
    assert model.petal_length == 1.4
    assert model.petal_width == 0.2

def test_IrisModelã®è² ã®å€¤ã§ã‚¨ãƒ©ãƒ¼():
    """è² ã®å€¤ã‚’æŒ‡å®šã™ã‚‹ã¨ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚¨ãƒ©ãƒ¼"""
    with pytest.raises(ValueError):
        IrisModel(
            sepal_length=-1.0,
            sepal_width=3.5,
            petal_length=1.4,
            petal_width=0.2
        )

def test_CinemaModelã®æ­£å¸¸ãªå€¤():
    """æ­£ã—ã„å€¤ã§CinemaModelã‚’ä½œæˆã§ãã‚‹"""
    model = CinemaModel(
        sns1=500,
        sns2=300,
        actor=70,
        original=1
    )

    assert model.sns1 == 500
    assert model.sns2 == 300
    assert model.actor == 70
    assert model.original == 1

def test_SurvivedModelã®æ­£å¸¸ãªå€¤():
    """æ­£ã—ã„å€¤ã§SurvivedModelã‚’ä½œæˆã§ãã‚‹"""
    model = SurvivedModel(
        pclass=3,
        age=22,
        sex="male"
    )

    assert model.pclass == 3
    assert model.age == 22
    assert model.sex == "male"

def test_SurvivedModelã®ä¸æ­£ãªsexã§ã‚¨ãƒ©ãƒ¼():
    """sex ãŒ male/female ä»¥å¤–ã§ã‚¨ãƒ©ãƒ¼"""
    with pytest.raises(ValueError):
        SurvivedModel(pclass=1, age=30, sex="unknown")

def test_BostonModelã®æ­£å¸¸ãªå€¤():
    """æ­£ã—ã„å€¤ã§BostonModelã‚’ä½œæˆã§ãã‚‹"""
    model = BostonModel(
        rm=6.5,
        lstat=4.98,
        ptratio=15.3
    )

    assert model.rm == 6.5
    assert model.lstat == 4.98
    assert model.ptratio == 15.3
```

**å®Ÿè¡Œçµæœï¼ˆRedï¼‰**:

```bash
$ pytest test/test_models.py
ModuleNotFoundError: No module named 'app.models'
```

**Greenï¼ˆæœ€å°é™ã®å®Ÿè£…ï¼‰**:

```python
# app/models.py
from pydantic import BaseModel, Field, field_validator
from typing import Literal

class IrisModel(BaseModel):
    """Iris åˆ†é¡ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«"""
    sepal_length: float = Field(..., ge=0, description="ãŒãç‰‡ã®é•·ã• (cm)")
    sepal_width: float = Field(..., ge=0, description="ãŒãç‰‡ã®å¹… (cm)")
    petal_length: float = Field(..., ge=0, description="èŠ±å¼ã®é•·ã• (cm)")
    petal_width: float = Field(..., ge=0, description="èŠ±å¼ã®å¹… (cm)")

class CinemaModel(BaseModel):
    """Cinema å£²ä¸Šäºˆæ¸¬ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«"""
    sns1: int = Field(..., ge=0, description="SNS è¨€åŠæ•° 1")
    sns2: int = Field(..., ge=0, description="SNS è¨€åŠæ•° 2")
    actor: int = Field(..., ge=0, le=100, description="ä¸»æ¼”ä¿³å„ªã‚¹ã‚³ã‚¢ (0-100)")
    original: int = Field(..., ge=0, le=1, description="ã‚ªãƒªã‚¸ãƒŠãƒ«ä½œå“ãƒ•ãƒ©ã‚° (0 or 1)")

class SurvivedModel(BaseModel):
    """Survived ç”Ÿå­˜äºˆæ¸¬ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«"""
    pclass: int = Field(..., ge=1, le=3, description="å®¢å®¤ã‚¯ãƒ©ã‚¹ (1, 2, 3)")
    age: int = Field(..., ge=0, le=100, description="å¹´é½¢")
    sex: Literal["male", "female"] = Field(..., description="æ€§åˆ¥ (male or female)")

class BostonModel(BaseModel):
    """Boston ä½å®…ä¾¡æ ¼äºˆæ¸¬ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«"""
    rm: float = Field(..., gt=0, description="éƒ¨å±‹æ•°")
    lstat: float = Field(..., ge=0, le=100, description="ä½æ‰€å¾—è€…äººå£å‰²åˆ (%)")
    ptratio: float = Field(..., gt=0, description="ç”Ÿå¾’ã¨æ•™å¸«ã®æ¯”ç‡")
```

**å®Ÿè¡Œçµæœï¼ˆGreenï¼‰**:

```bash
$ pytest test/test_models.py -v
test_models.py::test_IrisModelã®æ­£å¸¸ãªå€¤ PASSED                        [ 16%]
test_models.py::test_IrisModelã®è² ã®å€¤ã§ã‚¨ãƒ©ãƒ¼ PASSED                   [ 33%]
test_models.py::test_CinemaModelã®æ­£å¸¸ãªå€¤ PASSED                      [ 50%]
test_models.py::test_SurvivedModelã®æ­£å¸¸ãªå€¤ PASSED                    [ 66%]
test_models.py::test_SurvivedModelã®ä¸æ­£ãªsexã§ã‚¨ãƒ©ãƒ¼ PASSED           [ 83%]
test_models.py::test_BostonModelã®æ­£å¸¸ãªå€¤ PASSED                      [100%]

============================== 6 passed in 0.12s ==============================
```

**Refactorï¼ˆæ”¹å–„ï¼‰**:

ç¾æ™‚ç‚¹ã§ã¯ç‰¹ã«ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°ã¯ä¸è¦ã§ã™ã€‚Pydantic ã® Field ã¨ Literal ã‚’ä½¿ç”¨ã—ã¦ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®£è¨€çš„ã«è¨˜è¿°ã§ãã¦ã„ã¾ã™ã€‚

#### ã‚¹ãƒ†ãƒƒãƒ— 2: ãƒ‰ãƒ¡ã‚¤ãƒ³å±¤ã®å®Ÿè£…ï¼ˆRed â†’ Green â†’ Refactorï¼‰

æ¬¡ã«ã€è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚“ã§äºˆæ¸¬ã‚’è¡Œã†ãƒ‰ãƒ¡ã‚¤ãƒ³å±¤ã‚’å®Ÿè£…ã—ã¾ã™ã€‚

**Redï¼ˆå¤±æ•—ã™ã‚‹ãƒ†ã‚¹ãƒˆï¼‰**:

```python
# test/test_domain.py
import pytest
import pickle
import numpy as np
import pandas as pd
from sklearn import tree
from sklearn.linear_model import LinearRegression
from app.domain import IrisDomain, CinemaDomain, SurvivedDomain, BostonDomain

def test_IrisDomainã§ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚ã‚‹():
    """è¨“ç·´æ¸ˆã¿Irisãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚ã‚‹"""
    domain = IrisDomain()
    assert domain.model is not None

def test_IrisDomainã§äºˆæ¸¬ãŒã§ãã‚‹():
    """Irisãƒ¢ãƒ‡ãƒ«ã§äºˆæ¸¬ã‚’å®Ÿè¡Œã§ãã‚‹"""
    domain = IrisDomain()
    X = [[5.1, 3.5, 1.4, 0.2]]
    result = domain.predict(X)

    assert len(result) == 1
    assert result[0] in ["setosa", "versicolor", "virginica"]

def test_CinemaDomainã§ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚ã‚‹():
    """è¨“ç·´æ¸ˆã¿Cinemaãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚ã‚‹"""
    domain = CinemaDomain()
    assert domain.model is not None

def test_CinemaDomainã§äºˆæ¸¬ãŒã§ãã‚‹():
    """Cinemaãƒ¢ãƒ‡ãƒ«ã§äºˆæ¸¬ã‚’å®Ÿè¡Œã§ãã‚‹"""
    domain = CinemaDomain()
    X = [[500, 300, 70, 1]]
    result = domain.predict(X)

    assert len(result) == 1
    assert isinstance(result[0], (int, float))
    assert result[0] > 0

def test_SurvivedDomainã§ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚ã‚‹():
    """è¨“ç·´æ¸ˆã¿Survivedãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚ã‚‹"""
    domain = SurvivedDomain()
    assert domain.model is not None

def test_SurvivedDomainã§äºˆæ¸¬ãŒã§ãã‚‹():
    """Survivedãƒ¢ãƒ‡ãƒ«ã§äºˆæ¸¬ã‚’å®Ÿè¡Œã§ãã‚‹"""
    domain = SurvivedDomain()
    X_dict = [{"Pclass": 3, "Age": 22, "male": 1}]
    result = domain.predict(X_dict)

    assert len(result) == 1
    assert result[0] in [0, 1]

def test_BostonDomainã§ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚ã‚‹():
    """è¨“ç·´æ¸ˆã¿Bostonãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚ã‚‹"""
    domain = BostonDomain()
    assert domain.model is not None
    assert domain.scaler_X is not None
    assert domain.scaler_y is not None

def test_BostonDomainã§äºˆæ¸¬ãŒã§ãã‚‹():
    """Bostonãƒ¢ãƒ‡ãƒ«ã§äºˆæ¸¬ã‚’å®Ÿè¡Œã§ãã‚‹"""
    domain = BostonDomain()
    X_dict = [{"RM": 6.5, "LSTAT": 4.98, "PTRATIO": 15.3}]
    result = domain.predict(X_dict)

    assert len(result) == 1
    assert isinstance(result[0], (int, float))
    assert result[0] > 0
```

**å®Ÿè¡Œçµæœï¼ˆRedï¼‰**:

```bash
$ pytest test/test_domain.py
ModuleNotFoundError: No module named 'app.domain'
```

**Greenï¼ˆæœ€å°é™ã®å®Ÿè£…ï¼‰**:

```python
# app/domain.py
import pickle
import numpy as np
import pandas as pd
from typing import List, Union, Dict
from pathlib import Path

class IrisDomain:
    """Iris åˆ†é¡ãƒ‰ãƒ¡ã‚¤ãƒ³"""

    def __init__(self, model_path: str = "model/iris.pkl") -> None:
        self.model_path = model_path
        self.model = None
        self.load_model()

    def load_model(self) -> None:
        """è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿"""
        with open(self.model_path, 'rb') as f:
            self.model = pickle.load(f)

    def predict(self, X: List[List[float]]) -> List[str]:
        """äºˆæ¸¬ã‚’å®Ÿè¡Œ

        Args:
            X: ç‰¹å¾´é‡ã®ãƒªã‚¹ãƒˆ [[sepal_length, sepal_width, petal_length, petal_width]]

        Returns:
            äºˆæ¸¬çµæœï¼ˆç¨®åï¼‰ã®ãƒªã‚¹ãƒˆ
        """
        if self.model is None:
            raise ValueError("Model not loaded")

        predictions = self.model.predict(X)
        return predictions.tolist()

class CinemaDomain:
    """Cinema å£²ä¸Šäºˆæ¸¬ãƒ‰ãƒ¡ã‚¤ãƒ³"""

    def __init__(self, model_path: str = "model/cinema.pkl") -> None:
        self.model_path = model_path
        self.model = None
        self.load_model()

    def load_model(self) -> None:
        """è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿"""
        with open(self.model_path, 'rb') as f:
            self.model = pickle.load(f)

    def predict(self, X: List[List[Union[int, float]]]) -> List[float]:
        """äºˆæ¸¬ã‚’å®Ÿè¡Œ

        Args:
            X: ç‰¹å¾´é‡ã®ãƒªã‚¹ãƒˆ [[sns1, sns2, actor, original]]

        Returns:
            äºˆæ¸¬çµæœï¼ˆå£²ä¸Šï¼‰ã®ãƒªã‚¹ãƒˆ
        """
        if self.model is None:
            raise ValueError("Model not loaded")

        predictions = self.model.predict(X)
        return predictions.tolist()

class SurvivedDomain:
    """Survived ç”Ÿå­˜äºˆæ¸¬ãƒ‰ãƒ¡ã‚¤ãƒ³"""

    def __init__(self, model_path: str = "model/survived.pkl") -> None:
        self.model_path = model_path
        self.model = None
        self.load_model()

    def load_model(self) -> None:
        """è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿"""
        with open(self.model_path, 'rb') as f:
            self.model = pickle.load(f)

    def predict(self, X_dict: List[Dict[str, Union[int, float]]]) -> List[int]:
        """äºˆæ¸¬ã‚’å®Ÿè¡Œ

        Args:
            X_dict: ç‰¹å¾´é‡ã®è¾æ›¸ã®ãƒªã‚¹ãƒˆ [{"Pclass": 3, "Age": 22, "male": 1}]

        Returns:
            äºˆæ¸¬çµæœï¼ˆ0: æ­»äº¡, 1: ç”Ÿå­˜ï¼‰ã®ãƒªã‚¹ãƒˆ
        """
        if self.model is None:
            raise ValueError("Model not loaded")

        # è¾æ›¸ã‚’DataFrameã«å¤‰æ›
        X = pd.DataFrame(X_dict)
        predictions = self.model.predict(X)
        return predictions.tolist()

class BostonDomain:
    """Boston ä½å®…ä¾¡æ ¼äºˆæ¸¬ãƒ‰ãƒ¡ã‚¤ãƒ³"""

    def __init__(self, model_path: str = "model/boston.pkl") -> None:
        self.model_path = model_path
        self.model = None
        self.scaler_X = None
        self.scaler_y = None
        self.load_model()

    def load_model(self) -> None:
        """è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã¨ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼ã®èª­ã¿è¾¼ã¿"""
        with open(self.model_path, 'rb') as f:
            saved_data = pickle.load(f)
            self.model = saved_data['model']
            self.scaler_X = saved_data['scaler_X']
            self.scaler_y = saved_data['scaler_y']

    def predict(self, X_dict: List[Dict[str, float]]) -> List[float]:
        """äºˆæ¸¬ã‚’å®Ÿè¡Œ

        Args:
            X_dict: ç‰¹å¾´é‡ã®è¾æ›¸ã®ãƒªã‚¹ãƒˆ [{"RM": 6.5, "LSTAT": 4.98, "PTRATIO": 15.3}]

        Returns:
            äºˆæ¸¬çµæœï¼ˆä½å®…ä¾¡æ ¼ï¼‰ã®ãƒªã‚¹ãƒˆ
        """
        if self.model is None or self.scaler_X is None or self.scaler_y is None:
            raise ValueError("Model or scalers not loaded")

        # è¾æ›¸ã‚’DataFrameã«å¤‰æ›
        X = pd.DataFrame(X_dict)

        # ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ï¼ˆè¨“ç·´æ™‚ã¨åŒã˜å‡¦ç†ï¼‰
        X_engineered = self._feature_engineering(X)

        # ç‰¹å¾´é‡ã®æ¨™æº–åŒ–
        X_scaled = self.scaler_X.transform(X_engineered)

        # äºˆæ¸¬ï¼ˆæ¨™æº–åŒ–ã•ã‚ŒãŸå€¤ï¼‰
        y_pred_scaled = self.model.predict(X_scaled)

        # äºˆæ¸¬çµæœã‚’å…ƒã®ã‚¹ã‚±ãƒ¼ãƒ«ã«æˆ»ã™
        y_pred = self.scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1))

        return y_pred.flatten().tolist()

    def _feature_engineering(self, X: pd.DataFrame) -> pd.DataFrame:
        """ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ï¼ˆ2ä¹—é …ã¨äº¤äº’ä½œç”¨é …ã®è¿½åŠ ï¼‰"""
        X_new = X.copy()

        # 2ä¹—é …ã®è¿½åŠ 
        X_new['RM2'] = X['RM'] ** 2
        X_new['LSTAT2'] = X['LSTAT'] ** 2
        X_new['PTRATIO2'] = X['PTRATIO'] ** 2

        # äº¤äº’ä½œç”¨é …ã®è¿½åŠ 
        X_new['RM * LSTAT'] = X['RM'] * X['LSTAT']

        return X_new
```

**å®Ÿè¡Œçµæœï¼ˆGreenï¼‰**:

```bash
$ pytest test/test_domain.py -v
test_domain.py::test_IrisDomainã§ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚ã‚‹ PASSED              [ 12%]
test_domain.py::test_IrisDomainã§äºˆæ¸¬ãŒã§ãã‚‹ PASSED                    [ 25%]
test_domain.py::test_CinemaDomainã§ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚ã‚‹ PASSED            [ 37%]
test_domain.py::test_CinemaDomainã§äºˆæ¸¬ãŒã§ãã‚‹ PASSED                  [ 50%]
test_domain.py::test_SurvivedDomainã§ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚ã‚‹ PASSED          [ 62%]
test_domain.py::test_SurvivedDomainã§äºˆæ¸¬ãŒã§ãã‚‹ PASSED                [ 75%]
test_domain.py::test_BostonDomainã§ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚ã‚‹ PASSED            [ 87%]
test_domain.py::test_BostonDomainã§äºˆæ¸¬ãŒã§ãã‚‹ PASSED                  [100%]

============================== 8 passed in 0.45s ==============================
```

**Refactorï¼ˆæ”¹å–„ï¼‰**:

ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿ã®ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã‚’è¿½åŠ ã—ã¾ã™ï¼š

```python
# app/domain.py (ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°å¾Œ)
class IrisDomain:
    """Iris åˆ†é¡ãƒ‰ãƒ¡ã‚¤ãƒ³"""

    def __init__(self, model_path: str = "model/iris.pkl") -> None:
        self.model_path = model_path
        self.model = None
        self.load_model()

    def load_model(self) -> None:
        """è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿"""
        try:
            with open(self.model_path, 'rb') as f:
                self.model = pickle.load(f)
        except FileNotFoundError:
            raise FileNotFoundError(f"Model file not found: {self.model_path}")
        except Exception as e:
            raise RuntimeError(f"Failed to load model: {e}")

    # ä»¥ä¸‹ç•¥ï¼ˆä»–ã®ãƒ‰ãƒ¡ã‚¤ãƒ³ã‚¯ãƒ©ã‚¹ã‚‚åŒæ§˜ã«ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã‚’è¿½åŠ ï¼‰
```

#### ã‚¹ãƒ†ãƒƒãƒ— 3: ã‚µãƒ¼ãƒ“ã‚¹å±¤ã®å®Ÿè£…ï¼ˆRed â†’ Green â†’ Refactorï¼‰

ã‚µãƒ¼ãƒ“ã‚¹å±¤ã§ã¯ã€ãƒ‰ãƒ¡ã‚¤ãƒ³å±¤ã‚’ä½¿ç”¨ã—ã¦ãƒ“ã‚¸ãƒã‚¹ãƒ­ã‚¸ãƒƒã‚¯ã‚’å®Ÿè£…ã—ã¾ã™ã€‚

**Redï¼ˆå¤±æ•—ã™ã‚‹ãƒ†ã‚¹ãƒˆï¼‰**:

```python
# test/test_service.py
import pytest
from app.service import MLService

def test_predict_iris():
    """Irisäºˆæ¸¬ã‚µãƒ¼ãƒ“ã‚¹ãŒæ­£ã—ãå‹•ä½œã™ã‚‹"""
    service = MLService()
    result = service.predict_iris([[5.1, 3.5, 1.4, 0.2]])

    assert isinstance(result, str)
    assert result in ["setosa", "versicolor", "virginica"]

def test_predict_cinema():
    """Cinemaäºˆæ¸¬ã‚µãƒ¼ãƒ“ã‚¹ãŒæ­£ã—ãå‹•ä½œã™ã‚‹"""
    service = MLService()
    result = service.predict_cinema([[500, 300, 70, 1]])

    assert isinstance(result, float)
    assert result > 0

def test_predict_survived():
    """Survivedäºˆæ¸¬ã‚µãƒ¼ãƒ“ã‚¹ãŒæ­£ã—ãå‹•ä½œã™ã‚‹"""
    service = MLService()
    result = service.predict_survived(pclass=3, age=22, sex="male")

    assert isinstance(result, int)
    assert result in [0, 1]

def test_predict_boston():
    """Bostonäºˆæ¸¬ã‚µãƒ¼ãƒ“ã‚¹ãŒæ­£ã—ãå‹•ä½œã™ã‚‹"""
    service = MLService()
    result = service.predict_boston(rm=6.5, lstat=4.98, ptratio=15.3)

    assert isinstance(result, float)
    assert result > 0
```

**å®Ÿè¡Œçµæœï¼ˆRedï¼‰**:

```bash
$ pytest test/test_service.py
ModuleNotFoundError: No module named 'app.service'
```

**Greenï¼ˆæœ€å°é™ã®å®Ÿè£…ï¼‰**:

```python
# app/service.py
from typing import List, Union
from app.domain import IrisDomain, CinemaDomain, SurvivedDomain, BostonDomain

class MLService:
    """æ©Ÿæ¢°å­¦ç¿’ã‚µãƒ¼ãƒ“ã‚¹å±¤"""

    def __init__(self) -> None:
        # ãƒ‰ãƒ¡ã‚¤ãƒ³ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã¯æ¯å›ç”Ÿæˆï¼ˆã‚·ãƒ³ã‚°ãƒ«ãƒˆãƒ³ã«ã—ã¦ã‚‚è‰¯ã„ï¼‰
        pass

    def predict_iris(self, features: List[List[float]]) -> str:
        """Iris åˆ†é¡äºˆæ¸¬

        Args:
            features: [[sepal_length, sepal_width, petal_length, petal_width]]

        Returns:
            äºˆæ¸¬ã•ã‚ŒãŸç¨®å
        """
        domain = IrisDomain()
        predictions = domain.predict(features)
        return predictions[0]  # æœ€åˆã®äºˆæ¸¬çµæœã‚’è¿”ã™

    def predict_cinema(self, features: List[List[Union[int, float]]]) -> float:
        """Cinema å£²ä¸Šäºˆæ¸¬

        Args:
            features: [[sns1, sns2, actor, original]]

        Returns:
            äºˆæ¸¬ã•ã‚ŒãŸå£²ä¸Š
        """
        domain = CinemaDomain()
        predictions = domain.predict(features)
        return float(predictions[0])

    def predict_survived(self, pclass: int, age: int, sex: str) -> int:
        """Survived ç”Ÿå­˜äºˆæ¸¬

        Args:
            pclass: å®¢å®¤ã‚¯ãƒ©ã‚¹
            age: å¹´é½¢
            sex: æ€§åˆ¥

        Returns:
            äºˆæ¸¬çµæœï¼ˆ0: æ­»äº¡, 1: ç”Ÿå­˜ï¼‰
        """
        domain = SurvivedDomain()

        # sex ã‚’ male ãƒ€ãƒŸãƒ¼å¤‰æ•°ã«å¤‰æ›
        male = 1 if sex == "male" else 0

        X_dict = [{"Pclass": pclass, "Age": age, "male": male}]
        predictions = domain.predict(X_dict)
        return int(predictions[0])

    def predict_boston(self, rm: float, lstat: float, ptratio: float) -> float:
        """Boston ä½å®…ä¾¡æ ¼äºˆæ¸¬

        Args:
            rm: éƒ¨å±‹æ•°
            lstat: ä½æ‰€å¾—è€…äººå£å‰²åˆ
            ptratio: ç”Ÿå¾’ã¨æ•™å¸«ã®æ¯”ç‡

        Returns:
            äºˆæ¸¬ã•ã‚ŒãŸä½å®…ä¾¡æ ¼
        """
        domain = BostonDomain()

        X_dict = [{"RM": rm, "LSTAT": lstat, "PTRATIO": ptratio}]
        predictions = domain.predict(X_dict)
        return float(predictions[0])
```

**å®Ÿè¡Œçµæœï¼ˆGreenï¼‰**:

```bash
$ pytest test/test_service.py -v
test_service.py::test_predict_iris PASSED                               [ 25%]
test_service.py::test_predict_cinema PASSED                             [ 50%]
test_service.py::test_predict_survived PASSED                           [ 75%]
test_service.py::test_predict_boston PASSED                             [100%]

============================== 4 passed in 0.56s ==============================
```

**Refactorï¼ˆæ”¹å–„ï¼‰**:

ãƒ‰ãƒ¡ã‚¤ãƒ³ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’ã‚·ãƒ³ã‚°ãƒ«ãƒˆãƒ³ãƒ‘ã‚¿ãƒ¼ãƒ³ã§å†åˆ©ç”¨ã™ã‚‹ã‚ˆã†ã«æ”¹å–„ã—ã¾ã™ï¼š

```python
# app/service.py (ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°å¾Œ)
from typing import List, Union, Optional
from app.domain import IrisDomain, CinemaDomain, SurvivedDomain, BostonDomain

class MLService:
    """æ©Ÿæ¢°å­¦ç¿’ã‚µãƒ¼ãƒ“ã‚¹å±¤"""

    def __init__(self) -> None:
        # åˆå›ã‚¢ã‚¯ã‚»ã‚¹æ™‚ã«ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ã€ä»¥é™ã¯å†åˆ©ç”¨
        self._iris_domain: Optional[IrisDomain] = None
        self._cinema_domain: Optional[CinemaDomain] = None
        self._survived_domain: Optional[SurvivedDomain] = None
        self._boston_domain: Optional[BostonDomain] = None

    @property
    def iris_domain(self) -> IrisDomain:
        """Lazy loading ã§ IrisDomain ã‚’å–å¾—"""
        if self._iris_domain is None:
            self._iris_domain = IrisDomain()
        return self._iris_domain

    @property
    def cinema_domain(self) -> CinemaDomain:
        """Lazy loading ã§ CinemaDomain ã‚’å–å¾—"""
        if self._cinema_domain is None:
            self._cinema_domain = CinemaDomain()
        return self._cinema_domain

    @property
    def survived_domain(self) -> SurvivedDomain:
        """Lazy loading ã§ SurvivedDomain ã‚’å–å¾—"""
        if self._survived_domain is None:
            self._survived_domain = SurvivedDomain()
        return self._survived_domain

    @property
    def boston_domain(self) -> BostonDomain:
        """Lazy loading ã§ BostonDomain ã‚’å–å¾—"""
        if self._boston_domain is None:
            self._boston_domain = BostonDomain()
        return self._boston_domain

    def predict_iris(self, features: List[List[float]]) -> str:
        """Iris åˆ†é¡äºˆæ¸¬"""
        predictions = self.iris_domain.predict(features)
        return predictions[0]

    def predict_cinema(self, features: List[List[Union[int, float]]]) -> float:
        """Cinema å£²ä¸Šäºˆæ¸¬"""
        predictions = self.cinema_domain.predict(features)
        return float(predictions[0])

    def predict_survived(self, pclass: int, age: int, sex: str) -> int:
        """Survived ç”Ÿå­˜äºˆæ¸¬"""
        male = 1 if sex == "male" else 0
        X_dict = [{"Pclass": pclass, "Age": age, "male": male}]
        predictions = self.survived_domain.predict(X_dict)
        return int(predictions[0])

    def predict_boston(self, rm: float, lstat: float, ptratio: float) -> float:
        """Boston ä½å®…ä¾¡æ ¼äºˆæ¸¬"""
        X_dict = [{"RM": rm, "LSTAT": lstat, "PTRATIO": ptratio}]
        predictions = self.boston_domain.predict(X_dict)
        return float(predictions[0])
```

#### ã‚¹ãƒ†ãƒƒãƒ— 4: ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å±¤ã®å®Ÿè£…ï¼ˆRed â†’ Green â†’ Refactorï¼‰

æœ€å¾Œã«ã€FastAPI ã®ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚’å®Ÿè£…ã—ã¾ã™ã€‚

**Redï¼ˆå¤±æ•—ã™ã‚‹ãƒ†ã‚¹ãƒˆï¼‰**:

```python
# test/test_application.py
import pytest
from fastapi.testclient import TestClient
from app.application import app

client = TestClient(app)

def test_Irisã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®æ­£å¸¸ç³»():
    """Iris ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆãŒæ­£ã—ãå‹•ä½œã™ã‚‹"""
    response = client.post("/iris", json={
        "sepal_length": 5.1,
        "sepal_width": 3.5,
        "petal_length": 1.4,
        "petal_width": 0.2
    })

    assert response.status_code == 200
    data = response.json()
    assert "species" in data
    assert data["species"] in ["setosa", "versicolor", "virginica"]

def test_Irisã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®ç•°å¸¸ç³»_è² ã®å€¤():
    """è² ã®å€¤ã‚’æŒ‡å®šã™ã‚‹ã¨ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚¨ãƒ©ãƒ¼"""
    response = client.post("/iris", json={
        "sepal_length": -1.0,
        "sepal_width": 3.5,
        "petal_length": 1.4,
        "petal_width": 0.2
    })

    assert response.status_code == 422  # Validation error

def test_Cinemaã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®æ­£å¸¸ç³»():
    """Cinema ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆãŒæ­£ã—ãå‹•ä½œã™ã‚‹"""
    response = client.post("/cinema", json={
        "sns1": 500,
        "sns2": 300,
        "actor": 70,
        "original": 1
    })

    assert response.status_code == 200
    data = response.json()
    assert "predicted_sales" in data
    assert data["predicted_sales"] > 0

def test_Survivedã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®æ­£å¸¸ç³»():
    """Survived ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆãŒæ­£ã—ãå‹•ä½œã™ã‚‹"""
    response = client.post("/survived", json={
        "pclass": 3,
        "age": 22,
        "sex": "male"
    })

    assert response.status_code == 200
    data = response.json()
    assert "survived" in data
    assert data["survived"] in [0, 1]

def test_Bostonã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®æ­£å¸¸ç³»():
    """Boston ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆãŒæ­£ã—ãå‹•ä½œã™ã‚‹"""
    response = client.post("/boston", json={
        "rm": 6.5,
        "lstat": 4.98,
        "ptratio": 15.3
    })

    assert response.status_code == 200
    data = response.json()
    assert "predicted_price" in data
    assert data["predicted_price"] > 0

def test_ãƒ«ãƒ¼ãƒˆã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ():
    """ãƒ«ãƒ¼ãƒˆã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆãŒæ­£ã—ãå‹•ä½œã™ã‚‹"""
    response = client.get("/")

    assert response.status_code == 200
    data = response.json()
    assert "message" in data

def test_ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ():
    """ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆãŒæ­£ã—ãå‹•ä½œã™ã‚‹"""
    response = client.get("/health")

    assert response.status_code == 200
    data = response.json()
    assert data["status"] == "ok"
```

**å®Ÿè¡Œçµæœï¼ˆRedï¼‰**:

```bash
$ pytest test/test_application.py
ModuleNotFoundError: No module named 'app.application'
```

**Greenï¼ˆæœ€å°é™ã®å®Ÿè£…ï¼‰**:

```python
# app/application.py
from fastapi import FastAPI
from app.models import IrisModel, CinemaModel, SurvivedModel, BostonModel
from app.service import MLService

app = FastAPI(
    title="Machine Learning API",
    description="TDD ã§æ§‹ç¯‰ã—ãŸæ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã® API",
    version="1.0.0"
)

service = MLService()

@app.get("/", tags=["Root"])
async def root():
    """ãƒ«ãƒ¼ãƒˆã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"""
    return {
        "message": "Machine Learning API",
        "version": "1.0.0",
        "endpoints": ["/iris", "/cinema", "/survived", "/boston"]
    }

@app.get("/health", tags=["Health"])
async def health():
    """ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"""
    return {"status": "ok"}

@app.post("/iris", tags=["Iris"], description="ã‚¢ãƒ¤ãƒ¡ã®ç¨®é¡ã‚’åˆ†é¡")
async def predict_iris(model: IrisModel):
    """Iris åˆ†é¡ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ

    Args:
        model: Iris ã®ç‰¹å¾´é‡

    Returns:
        äºˆæ¸¬ã•ã‚ŒãŸç¨®å
    """
    features = [[
        model.sepal_length,
        model.sepal_width,
        model.petal_length,
        model.petal_width
    ]]

    species = service.predict_iris(features)
    return {"species": species}

@app.post("/cinema", tags=["Cinema"], description="æ˜ ç”»ã®èˆˆè¡Œåå…¥ã‚’äºˆæ¸¬")
async def predict_cinema(model: CinemaModel):
    """Cinema å£²ä¸Šäºˆæ¸¬ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ

    Args:
        model: Cinema ã®ç‰¹å¾´é‡

    Returns:
        äºˆæ¸¬ã•ã‚ŒãŸå£²ä¸Š
    """
    features = [[
        model.sns1,
        model.sns2,
        model.actor,
        model.original
    ]]

    predicted_sales = service.predict_cinema(features)
    return {"predicted_sales": predicted_sales}

@app.post("/survived", tags=["Survived"], description="ã‚¿ã‚¤ã‚¿ãƒ‹ãƒƒã‚¯å·ã§ã®ç”Ÿå­˜ã‚’äºˆæ¸¬")
async def predict_survived(model: SurvivedModel):
    """Survived ç”Ÿå­˜äºˆæ¸¬ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ

    Args:
        model: Survived ã®ç‰¹å¾´é‡

    Returns:
        äºˆæ¸¬çµæœï¼ˆ0: æ­»äº¡, 1: ç”Ÿå­˜ï¼‰
    """
    survived = service.predict_survived(
        pclass=model.pclass,
        age=model.age,
        sex=model.sex
    )
    return {"survived": survived}

@app.post("/boston", tags=["Boston"], description="ãƒœã‚¹ãƒˆãƒ³ä½å®…ä¾¡æ ¼ã‚’äºˆæ¸¬")
async def predict_boston(model: BostonModel):
    """Boston ä½å®…ä¾¡æ ¼äºˆæ¸¬ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ

    Args:
        model: Boston ã®ç‰¹å¾´é‡

    Returns:
        äºˆæ¸¬ã•ã‚ŒãŸä½å®…ä¾¡æ ¼
    """
    predicted_price = service.predict_boston(
        rm=model.rm,
        lstat=model.lstat,
        ptratio=model.ptratio
    )
    return {"predicted_price": predicted_price}
```

**å®Ÿè¡Œçµæœï¼ˆGreenï¼‰**:

```bash
$ pytest test/test_application.py -v
test_application.py::test_Irisã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®æ­£å¸¸ç³» PASSED             [ 14%]
test_application.py::test_Irisã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®ç•°å¸¸ç³»_è² ã®å€¤ PASSED       [ 28%]
test_application.py::test_Cinemaã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®æ­£å¸¸ç³» PASSED           [ 42%]
test_application.py::test_Survivedã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®æ­£å¸¸ç³» PASSED         [ 57%]
test_application.py::test_Bostonã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®æ­£å¸¸ç³» PASSED           [ 71%]
test_application.py::test_ãƒ«ãƒ¼ãƒˆã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ PASSED                   [ 85%]
test_application.py::test_ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ PASSED           [100%]

============================== 7 passed in 0.78s ==============================
```

**Refactorï¼ˆæ”¹å–„ï¼‰**:

ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã¨ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ¢ãƒ‡ãƒ«ã‚’è¿½åŠ ã—ã¾ã™ï¼š

```python
# app/application.py (ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°å¾Œ)
from fastapi import FastAPI, HTTPException
from fastapi.responses import JSONResponse
from pydantic import BaseModel
from app.models import IrisModel, CinemaModel, SurvivedModel, BostonModel
from app.service import MLService

app = FastAPI(
    title="Machine Learning API",
    description="TDD ã§æ§‹ç¯‰ã—ãŸæ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã® API",
    version="1.0.0"
)

service = MLService()

# ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ¢ãƒ‡ãƒ«ã®å®šç¾©
class IrisResponse(BaseModel):
    species: str

class CinemaResponse(BaseModel):
    predicted_sales: float

class SurvivedResponse(BaseModel):
    survived: int

class BostonResponse(BaseModel):
    predicted_price: float

@app.get("/", tags=["Root"])
async def root():
    """ãƒ«ãƒ¼ãƒˆã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"""
    return {
        "message": "Machine Learning API",
        "version": "1.0.0",
        "endpoints": ["/iris", "/cinema", "/survived", "/boston"]
    }

@app.get("/health", tags=["Health"])
async def health():
    """ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"""
    return {"status": "ok"}

@app.post("/iris", response_model=IrisResponse, tags=["Iris"])
async def predict_iris(model: IrisModel):
    """Iris åˆ†é¡ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"""
    try:
        features = [[
            model.sepal_length,
            model.sepal_width,
            model.petal_length,
            model.petal_width
        ]]

        species = service.predict_iris(features)
        return IrisResponse(species=species)
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/cinema", response_model=CinemaResponse, tags=["Cinema"])
async def predict_cinema(model: CinemaModel):
    """Cinema å£²ä¸Šäºˆæ¸¬ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"""
    try:
        features = [[
            model.sns1,
            model.sns2,
            model.actor,
            model.original
        ]]

        predicted_sales = service.predict_cinema(features)
        return CinemaResponse(predicted_sales=predicted_sales)
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/survived", response_model=SurvivedResponse, tags=["Survived"])
async def predict_survived(model: SurvivedModel):
    """Survived ç”Ÿå­˜äºˆæ¸¬ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"""
    try:
        survived = service.predict_survived(
            pclass=model.pclass,
            age=model.age,
            sex=model.sex
        )
        return SurvivedResponse(survived=survived)
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/boston", response_model=BostonResponse, tags=["Boston"])
async def predict_boston(model: BostonModel):
    """Boston ä½å®…ä¾¡æ ¼äºˆæ¸¬ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"""
    try:
        predicted_price = service.predict_boston(
            rm=model.rm,
            lstat=model.lstat,
            ptratio=model.ptratio
        )
        return BostonResponse(predicted_price=predicted_price)
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))
```

### å®Œå…¨ãªã‚³ãƒ¼ãƒ‰å®Ÿè£…

ã“ã‚Œã¾ã§ã®ã‚¹ãƒ†ãƒƒãƒ—ã§å®Ÿè£…ã—ãŸå…¨ã‚³ãƒ¼ãƒ‰ã‚’æ•´ç†ã—ã¾ã™ã€‚

#### app/models.pyï¼ˆå®Œå…¨ç‰ˆï¼‰

```python
"""Pydantic ãƒ¢ãƒ‡ãƒ«å®šç¾©"""
from pydantic import BaseModel, Field
from typing import Literal

class IrisModel(BaseModel):
    """Iris åˆ†é¡ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«"""
    sepal_length: float = Field(..., ge=0, description="ãŒãç‰‡ã®é•·ã• (cm)")
    sepal_width: float = Field(..., ge=0, description="ãŒãç‰‡ã®å¹… (cm)")
    petal_length: float = Field(..., ge=0, description="èŠ±å¼ã®é•·ã• (cm)")
    petal_width: float = Field(..., ge=0, description="èŠ±å¼ã®å¹… (cm)")

    model_config = {
        "json_schema_extra": {
            "examples": [
                {
                    "sepal_length": 5.1,
                    "sepal_width": 3.5,
                    "petal_length": 1.4,
                    "petal_width": 0.2
                }
            ]
        }
    }

class CinemaModel(BaseModel):
    """Cinema å£²ä¸Šäºˆæ¸¬ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«"""
    sns1: int = Field(..., ge=0, description="SNS è¨€åŠæ•° 1")
    sns2: int = Field(..., ge=0, description="SNS è¨€åŠæ•° 2")
    actor: int = Field(..., ge=0, le=100, description="ä¸»æ¼”ä¿³å„ªã‚¹ã‚³ã‚¢ (0-100)")
    original: int = Field(..., ge=0, le=1, description="ã‚ªãƒªã‚¸ãƒŠãƒ«ä½œå“ãƒ•ãƒ©ã‚° (0 or 1)")

    model_config = {
        "json_schema_extra": {
            "examples": [
                {
                    "sns1": 500,
                    "sns2": 300,
                    "actor": 70,
                    "original": 1
                }
            ]
        }
    }

class SurvivedModel(BaseModel):
    """Survived ç”Ÿå­˜äºˆæ¸¬ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«"""
    pclass: int = Field(..., ge=1, le=3, description="å®¢å®¤ã‚¯ãƒ©ã‚¹ (1, 2, 3)")
    age: int = Field(..., ge=0, le=100, description="å¹´é½¢")
    sex: Literal["male", "female"] = Field(..., description="æ€§åˆ¥ (male or female)")

    model_config = {
        "json_schema_extra": {
            "examples": [
                {
                    "pclass": 3,
                    "age": 22,
                    "sex": "male"
                }
            ]
        }
    }

class BostonModel(BaseModel):
    """Boston ä½å®…ä¾¡æ ¼äºˆæ¸¬ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆãƒ¢ãƒ‡ãƒ«"""
    rm: float = Field(..., gt=0, description="éƒ¨å±‹æ•°")
    lstat: float = Field(..., ge=0, le=100, description="ä½æ‰€å¾—è€…äººå£å‰²åˆ (%)")
    ptratio: float = Field(..., gt=0, description="ç”Ÿå¾’ã¨æ•™å¸«ã®æ¯”ç‡")

    model_config = {
        "json_schema_extra": {
            "examples": [
                {
                    "rm": 6.5,
                    "lstat": 4.98,
                    "ptratio": 15.3
                }
            ]
        }
    }
```

#### app/domain.pyï¼ˆå®Œå…¨ç‰ˆï¼‰

```python
"""ãƒ‰ãƒ¡ã‚¤ãƒ³å±¤ï¼šæ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ã¨äºˆæ¸¬"""
import pickle
import numpy as np
import pandas as pd
from typing import List, Union, Dict, Optional
from pathlib import Path

class IrisDomain:
    """Iris åˆ†é¡ãƒ‰ãƒ¡ã‚¤ãƒ³"""

    def __init__(self, model_path: str = "model/iris.pkl") -> None:
        self.model_path = model_path
        self.model = None
        self.load_model()

    def load_model(self) -> None:
        """è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿"""
        try:
            with open(self.model_path, 'rb') as f:
                self.model = pickle.load(f)
        except FileNotFoundError:
            raise FileNotFoundError(f"Model file not found: {self.model_path}")
        except Exception as e:
            raise RuntimeError(f"Failed to load model: {e}")

    def predict(self, X: List[List[float]]) -> List[str]:
        """äºˆæ¸¬ã‚’å®Ÿè¡Œ

        Args:
            X: ç‰¹å¾´é‡ã®ãƒªã‚¹ãƒˆ [[sepal_length, sepal_width, petal_length, petal_width]]

        Returns:
            äºˆæ¸¬çµæœï¼ˆç¨®åï¼‰ã®ãƒªã‚¹ãƒˆ
        """
        if self.model is None:
            raise ValueError("Model not loaded")

        predictions = self.model.predict(X)
        return predictions.tolist()

class CinemaDomain:
    """Cinema å£²ä¸Šäºˆæ¸¬ãƒ‰ãƒ¡ã‚¤ãƒ³"""

    def __init__(self, model_path: str = "model/cinema.pkl") -> None:
        self.model_path = model_path
        self.model = None
        self.load_model()

    def load_model(self) -> None:
        """è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿"""
        try:
            with open(self.model_path, 'rb') as f:
                self.model = pickle.load(f)
        except FileNotFoundError:
            raise FileNotFoundError(f"Model file not found: {self.model_path}")
        except Exception as e:
            raise RuntimeError(f"Failed to load model: {e}")

    def predict(self, X: List[List[Union[int, float]]]) -> List[float]:
        """äºˆæ¸¬ã‚’å®Ÿè¡Œ

        Args:
            X: ç‰¹å¾´é‡ã®ãƒªã‚¹ãƒˆ [[sns1, sns2, actor, original]]

        Returns:
            äºˆæ¸¬çµæœï¼ˆå£²ä¸Šï¼‰ã®ãƒªã‚¹ãƒˆ
        """
        if self.model is None:
            raise ValueError("Model not loaded")

        predictions = self.model.predict(X)
        return predictions.tolist()

class SurvivedDomain:
    """Survived ç”Ÿå­˜äºˆæ¸¬ãƒ‰ãƒ¡ã‚¤ãƒ³"""

    def __init__(self, model_path: str = "model/survived.pkl") -> None:
        self.model_path = model_path
        self.model = None
        self.load_model()

    def load_model(self) -> None:
        """è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿"""
        try:
            with open(self.model_path, 'rb') as f:
                self.model = pickle.load(f)
        except FileNotFoundError:
            raise FileNotFoundError(f"Model file not found: {self.model_path}")
        except Exception as e:
            raise RuntimeError(f"Failed to load model: {e}")

    def predict(self, X_dict: List[Dict[str, Union[int, float]]]) -> List[int]:
        """äºˆæ¸¬ã‚’å®Ÿè¡Œ

        Args:
            X_dict: ç‰¹å¾´é‡ã®è¾æ›¸ã®ãƒªã‚¹ãƒˆ [{"Pclass": 3, "Age": 22, "male": 1}]

        Returns:
            äºˆæ¸¬çµæœï¼ˆ0: æ­»äº¡, 1: ç”Ÿå­˜ï¼‰ã®ãƒªã‚¹ãƒˆ
        """
        if self.model is None:
            raise ValueError("Model not loaded")

        # è¾æ›¸ã‚’DataFrameã«å¤‰æ›
        X = pd.DataFrame(X_dict)
        predictions = self.model.predict(X)
        return predictions.tolist()

class BostonDomain:
    """Boston ä½å®…ä¾¡æ ¼äºˆæ¸¬ãƒ‰ãƒ¡ã‚¤ãƒ³"""

    def __init__(self, model_path: str = "model/boston.pkl") -> None:
        self.model_path = model_path
        self.model = None
        self.scaler_X = None
        self.scaler_y = None
        self.load_model()

    def load_model(self) -> None:
        """è¨“ç·´æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã¨ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼ã®èª­ã¿è¾¼ã¿"""
        try:
            with open(self.model_path, 'rb') as f:
                saved_data = pickle.load(f)
                self.model = saved_data['model']
                self.scaler_X = saved_data['scaler_X']
                self.scaler_y = saved_data['scaler_y']
        except FileNotFoundError:
            raise FileNotFoundError(f"Model file not found: {self.model_path}")
        except Exception as e:
            raise RuntimeError(f"Failed to load model: {e}")

    def predict(self, X_dict: List[Dict[str, float]]) -> List[float]:
        """äºˆæ¸¬ã‚’å®Ÿè¡Œ

        Args:
            X_dict: ç‰¹å¾´é‡ã®è¾æ›¸ã®ãƒªã‚¹ãƒˆ [{"RM": 6.5, "LSTAT": 4.98, "PTRATIO": 15.3}]

        Returns:
            äºˆæ¸¬çµæœï¼ˆä½å®…ä¾¡æ ¼ï¼‰ã®ãƒªã‚¹ãƒˆ
        """
        if self.model is None or self.scaler_X is None or self.scaler_y is None:
            raise ValueError("Model or scalers not loaded")

        # è¾æ›¸ã‚’DataFrameã«å¤‰æ›
        X = pd.DataFrame(X_dict)

        # ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ï¼ˆè¨“ç·´æ™‚ã¨åŒã˜å‡¦ç†ï¼‰
        X_engineered = self._feature_engineering(X)

        # ç‰¹å¾´é‡ã®æ¨™æº–åŒ–
        X_scaled = self.scaler_X.transform(X_engineered)

        # äºˆæ¸¬ï¼ˆæ¨™æº–åŒ–ã•ã‚ŒãŸå€¤ï¼‰
        y_pred_scaled = self.model.predict(X_scaled)

        # äºˆæ¸¬çµæœã‚’å…ƒã®ã‚¹ã‚±ãƒ¼ãƒ«ã«æˆ»ã™
        y_pred = self.scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1))

        return y_pred.flatten().tolist()

    def _feature_engineering(self, X: pd.DataFrame) -> pd.DataFrame:
        """ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ï¼ˆ2ä¹—é …ã¨äº¤äº’ä½œç”¨é …ã®è¿½åŠ ï¼‰"""
        X_new = X.copy()

        # 2ä¹—é …ã®è¿½åŠ 
        X_new['RM2'] = X['RM'] ** 2
        X_new['LSTAT2'] = X['LSTAT'] ** 2
        X_new['PTRATIO2'] = X['PTRATIO'] ** 2

        # äº¤äº’ä½œç”¨é …ã®è¿½åŠ 
        X_new['RM * LSTAT'] = X['RM'] * X['LSTAT']

        return X_new
```

#### app/service.pyï¼ˆå®Œå…¨ç‰ˆï¼‰

```python
"""ã‚µãƒ¼ãƒ“ã‚¹å±¤ï¼šãƒ“ã‚¸ãƒã‚¹ãƒ­ã‚¸ãƒƒã‚¯"""
from typing import List, Union, Optional
from app.domain import IrisDomain, CinemaDomain, SurvivedDomain, BostonDomain

class MLService:
    """æ©Ÿæ¢°å­¦ç¿’ã‚µãƒ¼ãƒ“ã‚¹å±¤"""

    def __init__(self) -> None:
        # åˆå›ã‚¢ã‚¯ã‚»ã‚¹æ™‚ã«ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã¿ã€ä»¥é™ã¯å†åˆ©ç”¨ï¼ˆLazy Loadingï¼‰
        self._iris_domain: Optional[IrisDomain] = None
        self._cinema_domain: Optional[CinemaDomain] = None
        self._survived_domain: Optional[SurvivedDomain] = None
        self._boston_domain: Optional[BostonDomain] = None

    @property
    def iris_domain(self) -> IrisDomain:
        """Lazy loading ã§ IrisDomain ã‚’å–å¾—"""
        if self._iris_domain is None:
            self._iris_domain = IrisDomain()
        return self._iris_domain

    @property
    def cinema_domain(self) -> CinemaDomain:
        """Lazy loading ã§ CinemaDomain ã‚’å–å¾—"""
        if self._cinema_domain is None:
            self._cinema_domain = CinemaDomain()
        return self._cinema_domain

    @property
    def survived_domain(self) -> SurvivedDomain:
        """Lazy loading ã§ SurvivedDomain ã‚’å–å¾—"""
        if self._survived_domain is None:
            self._survived_domain = SurvivedDomain()
        return self._survived_domain

    @property
    def boston_domain(self) -> BostonDomain:
        """Lazy loading ã§ BostonDomain ã‚’å–å¾—"""
        if self._boston_domain is None:
            self._boston_domain = BostonDomain()
        return self._boston_domain

    def predict_iris(self, features: List[List[float]]) -> str:
        """Iris åˆ†é¡äºˆæ¸¬

        Args:
            features: [[sepal_length, sepal_width, petal_length, petal_width]]

        Returns:
            äºˆæ¸¬ã•ã‚ŒãŸç¨®å
        """
        predictions = self.iris_domain.predict(features)
        return predictions[0]

    def predict_cinema(self, features: List[List[Union[int, float]]]) -> float:
        """Cinema å£²ä¸Šäºˆæ¸¬

        Args:
            features: [[sns1, sns2, actor, original]]

        Returns:
            äºˆæ¸¬ã•ã‚ŒãŸå£²ä¸Š
        """
        predictions = self.cinema_domain.predict(features)
        return float(predictions[0])

    def predict_survived(self, pclass: int, age: int, sex: str) -> int:
        """Survived ç”Ÿå­˜äºˆæ¸¬

        Args:
            pclass: å®¢å®¤ã‚¯ãƒ©ã‚¹
            age: å¹´é½¢
            sex: æ€§åˆ¥

        Returns:
            äºˆæ¸¬çµæœï¼ˆ0: æ­»äº¡, 1: ç”Ÿå­˜ï¼‰
        """
        # sex ã‚’ male ãƒ€ãƒŸãƒ¼å¤‰æ•°ã«å¤‰æ›
        male = 1 if sex == "male" else 0

        X_dict = [{"Pclass": pclass, "Age": age, "male": male}]
        predictions = self.survived_domain.predict(X_dict)
        return int(predictions[0])

    def predict_boston(self, rm: float, lstat: float, ptratio: float) -> float:
        """Boston ä½å®…ä¾¡æ ¼äºˆæ¸¬

        Args:
            rm: éƒ¨å±‹æ•°
            lstat: ä½æ‰€å¾—è€…äººå£å‰²åˆ
            ptratio: ç”Ÿå¾’ã¨æ•™å¸«ã®æ¯”ç‡

        Returns:
            äºˆæ¸¬ã•ã‚ŒãŸä½å®…ä¾¡æ ¼
        """
        X_dict = [{"RM": rm, "LSTAT": lstat, "PTRATIO": ptratio}]
        predictions = self.boston_domain.predict(X_dict)
        return float(predictions[0])
```

#### app/application.pyï¼ˆå®Œå…¨ç‰ˆï¼‰

```python
"""ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å±¤ï¼šFastAPI ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"""
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from app.models import IrisModel, CinemaModel, SurvivedModel, BostonModel
from app.service import MLService

app = FastAPI(
    title="Machine Learning API",
    description="TDD ã§æ§‹ç¯‰ã—ãŸæ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã® API",
    version="1.0.0"
)

service = MLService()

# ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ¢ãƒ‡ãƒ«ã®å®šç¾©
class IrisResponse(BaseModel):
    """Iris äºˆæ¸¬ãƒ¬ã‚¹ãƒãƒ³ã‚¹"""
    species: str

class CinemaResponse(BaseModel):
    """Cinema äºˆæ¸¬ãƒ¬ã‚¹ãƒãƒ³ã‚¹"""
    predicted_sales: float

class SurvivedResponse(BaseModel):
    """Survived äºˆæ¸¬ãƒ¬ã‚¹ãƒãƒ³ã‚¹"""
    survived: int

class BostonResponse(BaseModel):
    """Boston äºˆæ¸¬ãƒ¬ã‚¹ãƒãƒ³ã‚¹"""
    predicted_price: float

@app.get("/", tags=["Root"])
async def root():
    """ãƒ«ãƒ¼ãƒˆã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"""
    return {
        "message": "Machine Learning API",
        "version": "1.0.0",
        "endpoints": ["/iris", "/cinema", "/survived", "/boston"],
        "docs": "/docs"
    }

@app.get("/health", tags=["Health"])
async def health():
    """ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ"""
    return {"status": "ok"}

@app.post("/iris", response_model=IrisResponse, tags=["Iris"], description="ã‚¢ãƒ¤ãƒ¡ã®ç¨®é¡ã‚’åˆ†é¡")
async def predict_iris(model: IrisModel):
    """Iris åˆ†é¡ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ

    Args:
        model: Iris ã®ç‰¹å¾´é‡

    Returns:
        äºˆæ¸¬ã•ã‚ŒãŸç¨®å
    """
    try:
        features = [[
            model.sepal_length,
            model.sepal_width,
            model.petal_length,
            model.petal_width
        ]]

        species = service.predict_iris(features)
        return IrisResponse(species=species)
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/cinema", response_model=CinemaResponse, tags=["Cinema"], description="æ˜ ç”»ã®èˆˆè¡Œåå…¥ã‚’äºˆæ¸¬")
async def predict_cinema(model: CinemaModel):
    """Cinema å£²ä¸Šäºˆæ¸¬ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ

    Args:
        model: Cinema ã®ç‰¹å¾´é‡

    Returns:
        äºˆæ¸¬ã•ã‚ŒãŸå£²ä¸Š
    """
    try:
        features = [[
            model.sns1,
            model.sns2,
            model.actor,
            model.original
        ]]

        predicted_sales = service.predict_cinema(features)
        return CinemaResponse(predicted_sales=predicted_sales)
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/survived", response_model=SurvivedResponse, tags=["Survived"], description="ã‚¿ã‚¤ã‚¿ãƒ‹ãƒƒã‚¯å·ã§ã®ç”Ÿå­˜ã‚’äºˆæ¸¬")
async def predict_survived(model: SurvivedModel):
    """Survived ç”Ÿå­˜äºˆæ¸¬ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ

    Args:
        model: Survived ã®ç‰¹å¾´é‡

    Returns:
        äºˆæ¸¬çµæœï¼ˆ0: æ­»äº¡, 1: ç”Ÿå­˜ï¼‰
    """
    try:
        survived = service.predict_survived(
            pclass=model.pclass,
            age=model.age,
            sex=model.sex
        )
        return SurvivedResponse(survived=survived)
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/boston", response_model=BostonResponse, tags=["Boston"], description="ãƒœã‚¹ãƒˆãƒ³ä½å®…ä¾¡æ ¼ã‚’äºˆæ¸¬")
async def predict_boston(model: BostonModel):
    """Boston ä½å®…ä¾¡æ ¼äºˆæ¸¬ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ

    Args:
        model: Boston ã®ç‰¹å¾´é‡

    Returns:
        äºˆæ¸¬ã•ã‚ŒãŸä½å®…ä¾¡æ ¼
    """
    try:
        predicted_price = service.predict_boston(
            rm=model.rm,
            lstat=model.lstat,
            ptratio=model.ptratio
        )
        return BostonResponse(predicted_price=predicted_price)
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))
```

### å®Ÿè·µçš„ãª API ä½¿ç”¨ä¾‹

#### 1. API ã‚µãƒ¼ãƒãƒ¼ã®èµ·å‹•

```bash
# FastAPI ã‚µãƒ¼ãƒãƒ¼ã‚’èµ·å‹•ï¼ˆé–‹ç™ºãƒ¢ãƒ¼ãƒ‰ï¼‰
uvicorn app.application:app --reload

# å‡ºåŠ›:
# INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)
# INFO:     Started reloader process [xxxxx] using StatReload
# INFO:     Started server process [xxxxx]
# INFO:     Waiting for application startup.
# INFO:     Application startup complete.
```

#### 2. Swagger UI ã§ã®ç¢ºèª

ãƒ–ãƒ©ã‚¦ã‚¶ã§ `http://127.0.0.1:8000/docs` ã«ã‚¢ã‚¯ã‚»ã‚¹ã™ã‚‹ã¨ã€è‡ªå‹•ç”Ÿæˆã•ã‚ŒãŸ API ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Machine Learning API - Swagger UI              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                 â”‚
â”‚ GET  /          ãƒ«ãƒ¼ãƒˆã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ            â”‚
â”‚ GET  /health    ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯                  â”‚
â”‚                                                 â”‚
â”‚ POST /iris      ã‚¢ãƒ¤ãƒ¡ã®ç¨®é¡ã‚’åˆ†é¡              â”‚
â”‚ POST /cinema    æ˜ ç”»ã®èˆˆè¡Œåå…¥ã‚’äºˆæ¸¬            â”‚
â”‚ POST /survived  ã‚¿ã‚¤ã‚¿ãƒ‹ãƒƒã‚¯å·ã§ã®ç”Ÿå­˜ã‚’äºˆæ¸¬   â”‚
â”‚ POST /boston    ãƒœã‚¹ãƒˆãƒ³ä½å®…ä¾¡æ ¼ã‚’äºˆæ¸¬          â”‚
â”‚                                                 â”‚
â”‚ [Try it out] ãƒœã‚¿ãƒ³ã§ã‚¤ãƒ³ã‚¿ãƒ©ã‚¯ãƒ†ã‚£ãƒ–ã«ãƒ†ã‚¹ãƒˆå¯èƒ½ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

#### 3. curl ã«ã‚ˆã‚‹ API ãƒ†ã‚¹ãƒˆ

**Iris åˆ†é¡**:

```bash
curl -X POST "http://127.0.0.1:8000/iris" \
  -H "Content-Type: application/json" \
  -d '{
    "sepal_length": 5.1,
    "sepal_width": 3.5,
    "petal_length": 1.4,
    "petal_width": 0.2
  }'

# ãƒ¬ã‚¹ãƒãƒ³ã‚¹:
# {"species":"setosa"}
```

**Cinema å£²ä¸Šäºˆæ¸¬**:

```bash
curl -X POST "http://127.0.0.1:8000/cinema" \
  -H "Content-Type: application/json" \
  -d '{
    "sns1": 500,
    "sns2": 300,
    "actor": 70,
    "original": 1
  }'

# ãƒ¬ã‚¹ãƒãƒ³ã‚¹:
# {"predicted_sales":3254.72}
```

**Survived ç”Ÿå­˜äºˆæ¸¬**:

```bash
curl -X POST "http://127.0.0.1:8000/survived" \
  -H "Content-Type: application/json" \
  -d '{
    "pclass": 3,
    "age": 22,
    "sex": "male"
  }'

# ãƒ¬ã‚¹ãƒãƒ³ã‚¹:
# {"survived":0}
```

**Boston ä½å®…ä¾¡æ ¼äºˆæ¸¬**:

```bash
curl -X POST "http://127.0.0.1:8000/boston" \
  -H "Content-Type: application/json" \
  -d '{
    "rm": 6.5,
    "lstat": 4.98,
    "ptratio": 15.3
  }'

# ãƒ¬ã‚¹ãƒãƒ³ã‚¹:
# {"predicted_price":32.45}
```

#### 4. Python ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‹ã‚‰ã®åˆ©ç”¨

```python
# api_client_example.py
import requests

BASE_URL = "http://127.0.0.1:8000"

def predict_iris():
    """Iris åˆ†é¡ã®å®Ÿè¡Œä¾‹"""
    response = requests.post(f"{BASE_URL}/iris", json={
        "sepal_length": 5.1,
        "sepal_width": 3.5,
        "petal_length": 1.4,
        "petal_width": 0.2
    })

    print(f"Iris äºˆæ¸¬çµæœ: {response.json()}")
    # å‡ºåŠ›: Iris äºˆæ¸¬çµæœ: {'species': 'setosa'}

def predict_cinema():
    """Cinema å£²ä¸Šäºˆæ¸¬ã®å®Ÿè¡Œä¾‹"""
    response = requests.post(f"{BASE_URL}/cinema", json={
        "sns1": 500,
        "sns2": 300,
        "actor": 70,
        "original": 1
    })

    result = response.json()
    print(f"Cinema å£²ä¸Šäºˆæ¸¬: {result['predicted_sales']:.2f} ä¸‡å††")
    # å‡ºåŠ›: Cinema å£²ä¸Šäºˆæ¸¬: 3254.72 ä¸‡å††

def predict_survived():
    """Survived ç”Ÿå­˜äºˆæ¸¬ã®å®Ÿè¡Œä¾‹"""
    passengers = [
        {"pclass": 1, "age": 30, "sex": "female"},
        {"pclass": 3, "age": 22, "sex": "male"},
    ]

    for passenger in passengers:
        response = requests.post(f"{BASE_URL}/survived", json=passenger)
        result = response.json()
        survival_status = "ç”Ÿå­˜" if result['survived'] == 1 else "æ­»äº¡"
        print(f"{passenger} â†’ {survival_status}")

    # å‡ºåŠ›:
    # {'pclass': 1, 'age': 30, 'sex': 'female'} â†’ ç”Ÿå­˜
    # {'pclass': 3, 'age': 22, 'sex': 'male'} â†’ æ­»äº¡

def predict_boston():
    """Boston ä½å®…ä¾¡æ ¼äºˆæ¸¬ã®å®Ÿè¡Œä¾‹"""
    response = requests.post(f"{BASE_URL}/boston", json={
        "rm": 6.5,
        "lstat": 4.98,
        "ptratio": 15.3
    })

    result = response.json()
    print(f"Boston ä½å®…ä¾¡æ ¼äºˆæ¸¬: ${result['predicted_price']:.2f}k")
    # å‡ºåŠ›: Boston ä½å®…ä¾¡æ ¼äºˆæ¸¬: $32.45k

if __name__ == "__main__":
    predict_iris()
    predict_cinema()
    predict_survived()
    predict_boston()
```

**å®Ÿè¡Œçµæœ**:

```bash
$ python api_client_example.py
Iris äºˆæ¸¬çµæœ: {'species': 'setosa'}
Cinema å£²ä¸Šäºˆæ¸¬: 3254.72 ä¸‡å††
{'pclass': 1, 'age': 30, 'sex': 'female'} â†’ ç”Ÿå­˜
{'pclass': 3, 'age': 22, 'sex': 'male'} â†’ æ­»äº¡
Boston ä½å®…ä¾¡æ ¼äºˆæ¸¬: $32.45k
```

### ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ 6 ã®æŠ€è¡“çš„æˆæœ

#### ãƒ†ã‚¹ãƒˆçµæœ

```bash
$ pytest -v --cov=app --cov-report=term-missing

========================== test session starts ==========================
collected 25 items

test/test_models.py::test_IrisModelã®æ­£å¸¸ãªå€¤ PASSED                [ 4%]
test/test_models.py::test_IrisModelã®è² ã®å€¤ã§ã‚¨ãƒ©ãƒ¼ PASSED           [ 8%]
test/test_models.py::test_CinemaModelã®æ­£å¸¸ãªå€¤ PASSED              [12%]
test/test_models.py::test_SurvivedModelã®æ­£å¸¸ãªå€¤ PASSED            [16%]
test/test_models.py::test_SurvivedModelã®ä¸æ­£ãªsexã§ã‚¨ãƒ©ãƒ¼ PASSED   [20%]
test/test_models.py::test_BostonModelã®æ­£å¸¸ãªå€¤ PASSED              [24%]
test/test_domain.py::test_IrisDomainã§ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚ã‚‹ PASSED     [28%]
test/test_domain.py::test_IrisDomainã§äºˆæ¸¬ãŒã§ãã‚‹ PASSED           [32%]
test/test_domain.py::test_CinemaDomainã§ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚ã‚‹ PASSED   [36%]
test/test_domain.py::test_CinemaDomainã§äºˆæ¸¬ãŒã§ãã‚‹ PASSED         [40%]
test/test_domain.py::test_SurvivedDomainã§ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚ã‚‹ PASSED [44%]
test/test_domain.py::test_SurvivedDomainã§äºˆæ¸¬ãŒã§ãã‚‹ PASSED       [48%]
test/test_domain.py::test_BostonDomainã§ãƒ¢ãƒ‡ãƒ«ã‚’èª­ã¿è¾¼ã‚ã‚‹ PASSED   [52%]
test/test_domain.py::test_BostonDomainã§äºˆæ¸¬ãŒã§ãã‚‹ PASSED         [56%]
test/test_service.py::test_predict_iris PASSED                      [60%]
test/test_service.py::test_predict_cinema PASSED                    [64%]
test/test_service.py::test_predict_survived PASSED                  [68%]
test/test_service.py::test_predict_boston PASSED                    [72%]
test/test_application.py::test_Irisã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®æ­£å¸¸ç³» PASSED     [76%]
test/test_application.py::test_Irisã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®ç•°å¸¸ç³» PASSED     [80%]
test/test_application.py::test_Cinemaã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®æ­£å¸¸ç³» PASSED   [84%]
test/test_application.py::test_Survivedã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®æ­£å¸¸ç³» PASSED [88%]
test/test_application.py::test_Bostonã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®æ­£å¸¸ç³» PASSED   [92%]
test/test_application.py::test_ãƒ«ãƒ¼ãƒˆã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ PASSED           [96%]
test/test_application.py::test_ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ PASSED                [100%]

---------- coverage: platform win32, python 3.12.0-final-0 ----------
Name                   Stmts   Miss  Cover   Missing
----------------------------------------------------
app/__init__.py            0      0   100%
app/application.py        45      2    96%   23, 67
app/domain.py             85      4    95%   18, 52, 86, 121
app/models.py             20      0   100%
app/service.py            38      1    97%   58
----------------------------------------------------
TOTAL                    188      7    96%

========================== 25 passed in 1.23s ==========================
```

#### å®šé‡çš„æˆæœ

| æŒ‡æ¨™ | é”æˆå€¤ | è©³ç´° |
|------|--------|------|
| **ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹æ•°** | 25å€‹ | Pydantic (6) + Domain (8) + Service (4) + Application (7) |
| **ã‚³ãƒ¼ãƒ‰ã‚«ãƒãƒ¬ãƒƒã‚¸** | 96% | é«˜ã„å“è³ªåŸºæº–ã‚’é”æˆ |
| **API ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ** | 4å€‹ + 2å€‹ | äºˆæ¸¬ API 4å€‹ + ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ 2å€‹ |
| **ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“** | < 100ms | é«˜é€Ÿãªãƒ¢ãƒ‡ãƒ«æ¨è«– |
| **è‡ªå‹•ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ** | 100% | Swagger UI ã§å®Œå…¨ã«ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆåŒ– |

#### ç¿’å¾—ã—ãŸã‚¹ã‚­ãƒ«

**1. Web API é–‹ç™º**:
- FastAPI ã«ã‚ˆã‚‹ãƒ¢ãƒ€ãƒ³ãª API é–‹ç™º
- Pydantic ã«ã‚ˆã‚‹å‹å®‰å…¨ãªãƒ‡ãƒ¼ã‚¿æ¤œè¨¼
- OpenAPI ä»•æ§˜ã®è‡ªå‹•ç”Ÿæˆ

**2. ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ãƒ‘ã‚¿ãƒ¼ãƒ³**:
- ãƒ¬ã‚¤ãƒ¤ãƒ¼ãƒ‰ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã®å®Ÿè·µï¼ˆ3å±¤åˆ†é›¢ï¼‰
- Lazy Loading ãƒ‘ã‚¿ãƒ¼ãƒ³
- Repository ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆãƒ‰ãƒ¡ã‚¤ãƒ³å±¤ï¼‰

**3. æœ¬ç•ªé‹ç”¨ã‚¹ã‚­ãƒ«**:
- pickle ã«ã‚ˆã‚‹ãƒ¢ãƒ‡ãƒ«ã®æ°¸ç¶šåŒ–ã¨èª­ã¿è¾¼ã¿
- ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã¨ãƒ­ã‚®ãƒ³ã‚°
- ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®å®Ÿè£…

**4. ãƒ†ã‚¹ãƒˆæˆ¦ç•¥**:
- çµ±åˆãƒ†ã‚¹ãƒˆï¼ˆFastAPI TestClientï¼‰
- å„å±¤ã®ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆ
- ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ãƒ†ã‚¹ãƒˆ

---

## ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå…¨ä½“ã®ã¾ã¨ã‚

### å…¨ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³çµ±åˆæˆæœ

ã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’é€šã˜ã¦ã€6ã¤ã®ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã§æ®µéšçš„ã«ã‚¹ã‚­ãƒ«ã‚’ç¿’å¾—ã—ã¦ãã¾ã—ãŸã€‚ä»¥ä¸‹ã¯å…¨ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®çµ±åˆæˆæœã§ã™ã€‚

#### ğŸ“Š å®šé‡çš„æˆæœï¼ˆå…¨ä½“ï¼‰

| æŒ‡æ¨™ | é”æˆå€¤ | è©³ç´° |
|------|--------|------|
| **ç·ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹æ•°** | 84å€‹ | ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³1 (9) + 2 (9) + 3 (11) + 4 (13) + 5 (17) + 6 (25) |
| **å¹³å‡ã‚³ãƒ¼ãƒ‰ã‚«ãƒãƒ¬ãƒƒã‚¸** | 94% | å…¨ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã§ 90% ä»¥ä¸Šã‚’é”æˆ |
| **å®Œæˆãƒ¢ãƒ‡ãƒ«æ•°** | 4æœ¬ | Irisã€Cinemaã€Survivedã€Boston ã®å®Ÿç”¨ãƒ¢ãƒ‡ãƒ« |
| **API ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆæ•°** | 6å€‹ | äºˆæ¸¬ API 4å€‹ + ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ 2å€‹ |
| **ç·ã‚³ãƒ¼ãƒ‰è¡Œæ•°** | ç´„ 1,500è¡Œ | é«˜å“è³ªã§ä¿å®ˆæ€§ã®é«˜ã„ã‚³ãƒ¼ãƒ‰ãƒ™ãƒ¼ã‚¹ |
| **Red-Green-Refactor ã‚µã‚¤ã‚¯ãƒ«** | ç´„ 30ã‚µã‚¤ã‚¯ãƒ« | TDD ã®å¾¹åº•çš„ãªå®Ÿè·µ |

#### ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³åˆ¥æˆæœä¸€è¦§

| ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ | ãƒ†ã‚¹ãƒˆæ•° | ã‚«ãƒãƒ¬ãƒƒã‚¸ | ä¸»è¦æˆæœ |
|--------------|---------|-----------|---------|
| **1. åŸºç¤æº–å‚™** | 9å€‹ | 100% | DataLoaderã€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ ã€å“è³ªç®¡ç†ãƒ„ãƒ¼ãƒ« |
| **2. Iris åˆ†é¡** | 9å€‹ | 95% | æ±ºå®šæœ¨åˆ†é¡ã€æ¬ æå€¤è£œå®Œã€97.78% ç²¾åº¦é”æˆ |
| **3. Cinema å›å¸°** | 11å€‹ | 92% | ç·šå½¢å›å¸°ã€å¤–ã‚Œå€¤é™¤å»ã€RÂ²=0.8383 é”æˆ |
| **4. Survived åˆ†é¡** | 13å€‹ | 90% | ã‚°ãƒ«ãƒ¼ãƒ—åˆ¥è£œå®Œã€ãƒ€ãƒŸãƒ¼å¤‰æ•°ã€83.24% ç²¾åº¦é”æˆ |
| **5. Boston å›å¸°** | 17å€‹ | 94% | ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã€æ¨™æº–åŒ–ã€RÂ²=0.8313 é”æˆ |
| **6. API åŒ–** | 25å€‹ | 96% | FastAPIã€ãƒ¬ã‚¤ãƒ¤ãƒ¼ãƒ‰ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã€Swagger UI |

#### ğŸ¯ ç¿’å¾—ã‚¹ã‚­ãƒ«å…¨ä½“åƒ

**1. ãƒ†ã‚¹ãƒˆé§†å‹•é–‹ç™ºï¼ˆTDDï¼‰ãƒã‚¹ã‚¿ãƒªãƒ¼**
- Red-Green-Refactor ã‚µã‚¤ã‚¯ãƒ«ã®å®Œå…¨ç¿’å¾—ï¼ˆç´„ 30ã‚µã‚¤ã‚¯ãƒ«å®Ÿè·µï¼‰
- ãƒ†ã‚¹ãƒˆãƒ•ã‚¡ãƒ¼ã‚¹ãƒˆæ€è€ƒã®ç¿’æ…£åŒ–
- ç¶™ç¶šçš„ãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°ã«ã‚ˆã‚‹å“è³ªå‘ä¸Š
- pytest ã«ã‚ˆã‚‹åŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆæ§‹ç¯‰

**2. ãƒ¢ãƒ€ãƒ³ Python é–‹ç™ºã®å®Œå…¨ç¿’å¾—**
- å‹ãƒ’ãƒ³ãƒˆå®Œå…¨æ´»ç”¨ã«ã‚ˆã‚‹å‹å®‰å…¨æ€§ç¢ºä¿ï¼ˆ100% ã‚«ãƒãƒ¬ãƒƒã‚¸ï¼‰
- uvã€Ruffã€mypy ã«ã‚ˆã‚‹ç¾ä»£çš„ãƒ„ãƒ¼ãƒ«ãƒã‚§ãƒ¼ãƒ³
- Pydantic ã«ã‚ˆã‚‹å¼·åŠ›ãªãƒ‡ãƒ¼ã‚¿æ¤œè¨¼
- FastAPI ã«ã‚ˆã‚‹ãƒ¢ãƒ€ãƒ³ãª Web API é–‹ç™º

**3. æ©Ÿæ¢°å­¦ç¿’åŸºç¤ã®ç¢ºç«‹**
- **åˆ†é¡å•é¡Œ**: æ±ºå®šæœ¨ï¼ˆIrisã€Survivedï¼‰
- **å›å¸°å•é¡Œ**: ç·šå½¢å›å¸°ï¼ˆCinemaã€Bostonï¼‰
- **ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†**: æ¬ æå€¤è£œå®Œã€å¤–ã‚Œå€¤é™¤å»ã€æ¨™æº–åŒ–ã€ãƒ€ãƒŸãƒ¼å¤‰æ•°åŒ–
- **ãƒ¢ãƒ‡ãƒ«è©•ä¾¡**: Accuracyã€RÂ² Scoreã€MAEã€RMSE
- **ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°**: 2ä¹—é …ã€äº¤äº’ä½œç”¨é …
- **ã‚¯ãƒ©ã‚¹ä¸å‡è¡¡å¯¾å¿œ**: class_weight='balanced'
- **ãƒ‡ãƒ¼ã‚¿ãƒªãƒ¼ã‚±ãƒ¼ã‚¸é˜²æ­¢**: è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã¨ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã®å³å¯†ãªåˆ†é›¢

**4. ã‚½ãƒ•ãƒˆã‚¦ã‚§ã‚¢å·¥å­¦å®Ÿè·µ**
- **ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£è¨­è¨ˆ**: ãƒ¬ã‚¤ãƒ¤ãƒ¼ãƒ‰ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ï¼ˆApplication/Service/Domainï¼‰
- **ãƒ‡ã‚¶ã‚¤ãƒ³ãƒ‘ã‚¿ãƒ¼ãƒ³**: Lazy Loadingã€Repository ãƒ‘ã‚¿ãƒ¼ãƒ³
- **å“è³ªç®¡ç†**: å®šé‡çš„å“è³ªæŒ‡æ¨™ã«ã‚ˆã‚‹ç®¡ç†ã€ç¶™ç¶šçš„ã‚¤ãƒ³ãƒ†ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
- **API è¨­è¨ˆ**: RESTful APIã€OpenAPI ä»•æ§˜ã€Swagger UI
- **ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°**: é©åˆ‡ãªä¾‹å¤–å‡¦ç†ã¨ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸

#### ğŸ“ˆ å­¦ç¿’å†…å®¹ã®é€²åŒ–

**Phase 1ï¼ˆã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ 1-2ï¼‰: åŸºç¤æ§‹é€ ç¢ºç«‹**

```python
# ã‚·ãƒ³ãƒ—ãƒ«ãªåˆ†é¡ãƒ¢ãƒ‡ãƒ«
class IrisClassifier:
    def load_data(self, file_path): pass
    def train(self, X_train, y_train): pass
    def predict(self, X_test): pass
    def evaluate(self, X_test, y_test): pass
```

**é”æˆãƒ¬ãƒ™ãƒ«**: æ©Ÿæ¢°å­¦ç¿’ã®åŸºæœ¬ãƒ•ãƒ­ãƒ¼ã‚’ç†è§£

**Phase 2ï¼ˆã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ 3-4ï¼‰: è¤‡é›‘åŒ–å¯¾å¿œ**

```python
# ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ã®è¿½åŠ 
class SurvivedClassifier:
    def _preprocess_age(self, df): pass      # ã‚°ãƒ«ãƒ¼ãƒ—åˆ¥è£œå®Œ
    def _encode_categorical(self, df): pass  # ãƒ€ãƒŸãƒ¼å¤‰æ•°åŒ–
    def train(self, X_train, y_train): pass
    def predict(self, X_test): pass
```

**é”æˆãƒ¬ãƒ™ãƒ«**: å®Ÿå‹™ãƒ¬ãƒ™ãƒ«ã®ãƒ‡ãƒ¼ã‚¿å‡¦ç†æŠ€è¡“ã‚’ç¿’å¾—

**Phase 3ï¼ˆã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ 5-6ï¼‰: çµ±åˆã‚·ã‚¹ãƒ†ãƒ **

```python
# API åŒ–ã¨çµ±åˆ
class MLService:
    def __init__(self):
        self.iris_domain = IrisDomain()
        self.cinema_domain = CinemaDomain()
        self.survived_domain = SurvivedDomain()
        self.boston_domain = BostonDomain()

    def predict_iris(self, features): pass
    def predict_cinema(self, features): pass
    def predict_survived(self, pclass, age, sex): pass
    def predict_boston(self, rm, lstat, ptratio): pass
```

**é”æˆãƒ¬ãƒ™ãƒ«**: æœ¬ç•ªç’°å¢ƒãƒ¬ãƒ‡ã‚£ãª API ã‚·ã‚¹ãƒ†ãƒ æ§‹ç¯‰

#### ğŸš€ å®Ÿè·µçš„ãªå­¦ç¿’ä¾¡å€¤

##### 1. æ¥­å‹™é©ç”¨å¯èƒ½ãªã‚¹ã‚­ãƒ«

**ãƒ†ã‚¹ãƒˆé§†å‹•é–‹ç™º**
- ä¼æ¥­é–‹ç™ºã§æ±‚ã‚ã‚‰ã‚Œã‚‹å“è³ªç®¡ç†æ‰‹æ³•
- å®‰å…¨ãªãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°æŠ€è¡“
- ç¶™ç¶šçš„ã‚¤ãƒ³ãƒ†ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å¯¾å¿œ

**æ©Ÿæ¢°å­¦ç¿’å®Ÿè£…**
- ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†ã‹ã‚‰ãƒ¢ãƒ‡ãƒ«è¨“ç·´ã¾ã§ã®å®Œå…¨ãƒ•ãƒ­ãƒ¼
- ãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡ã¨æ”¹å–„ãƒ—ãƒ­ã‚»ã‚¹
- æœ¬ç•ªç’°å¢ƒã¸ã®ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆæŠ€è¡“

**Web API é–‹ç™º**
- RESTful API è¨­è¨ˆã¨ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆåŒ–
- ãƒ¬ã‚¤ãƒ¤ãƒ¼ãƒ‰ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã«ã‚ˆã‚‹ä¿å®ˆæ€§ç¢ºä¿
- ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã¨ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³

##### 2. ä»Šå¾Œã®ç™ºå±•å¯èƒ½æ€§

**æŠ€è¡“çš„æ‹¡å¼µæ–¹å‘**
1. **é«˜åº¦ãªãƒ¢ãƒ‡ãƒ«**: ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆTensorFlowã€PyTorchï¼‰ã€ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å­¦ç¿’
2. **MLOps**: ãƒ¢ãƒ‡ãƒ«ãƒãƒ¼ã‚¸ãƒ§ãƒ‹ãƒ³ã‚°ã€A/B ãƒ†ã‚¹ãƒˆã€ãƒ¢ãƒ‡ãƒ«ç›£è¦–
3. **ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°**: ãƒãƒƒãƒäºˆæ¸¬ã€ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ¨è«–ã€åˆ†æ•£å‡¦ç†

**ãƒ“ã‚¸ãƒã‚¹é©ç”¨**
1. **å®Ÿæ¥­å‹™é©ç”¨**: é¡§å®¢è¡Œå‹•äºˆæ¸¬ã€éœ€è¦äºˆæ¸¬ã€ä¸æ­£æ¤œçŸ¥
2. **ãƒ—ãƒ­ãƒ€ã‚¯ãƒˆåŒ–**: SaaS ã¨ã—ã¦ã®æ©Ÿæ¢°å­¦ç¿’ API ã‚µãƒ¼ãƒ“ã‚¹
3. **ãƒ‡ãƒ¼ã‚¿åˆ†æåŸºç›¤**: ä¼æ¥­å†…ãƒ‡ãƒ¼ã‚¿åˆ†æãƒ—ãƒ©ãƒƒãƒˆãƒ•ã‚©ãƒ¼ãƒ ã®æ§‹ç¯‰

**æ•™è‚²ãƒ»ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£æ´»ç”¨**
1. **æ•™è‚²æ•™æ**: ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹è¬›åº§ã®å®Ÿè·µæ•™æ
2. **ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹**: ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£ã«ã‚ˆã‚‹æ©Ÿèƒ½æ‹¡å¼µ
3. **ä¼æ¥­ç ”ä¿®**: æ©Ÿæ¢°å­¦ç¿’ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢è‚²æˆãƒ—ãƒ­ã‚°ãƒ©ãƒ 

#### ğŸ† ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆè©•ä¾¡

**ã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¯ã€ãƒ†ã‚¹ãƒˆé§†å‹•é–‹ç™ºã®å®Ÿè·µçš„ç¿’å¾—ã¨ Python æ©Ÿæ¢°å­¦ç¿’ã®åŒ…æ‹¬çš„å­¦ç¿’ã‚’åŒæ™‚ã«å®Ÿç¾ã™ã‚‹ã€æ¥µã‚ã¦æ•™è‚²ä¾¡å€¤ã®é«˜ã„ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ã™ã€‚**

##### æˆåŠŸè¦å› 

1. **æ®µéšçš„å­¦ç¿’è¨­è¨ˆ**: ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³1ã‹ã‚‰6ã¸ã®ç„¡ç†ã®ãªã„ã‚¹ã‚­ãƒ«ã‚¢ãƒƒãƒ—æ›²ç·š
2. **å®Ÿè·µçš„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ**: ç†è«–ã§ã¯ãªãå®Ÿéš›ã«å‹•ä½œã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã§ã®å­¦ç¿’
3. **å“è³ªé‡è¦–**: é«˜ã„å“è³ªåŸºæº–ï¼ˆã‚«ãƒãƒ¬ãƒƒã‚¸ 90% ä»¥ä¸Šï¼‰ã«ã‚ˆã‚‹å­¦ç¿’åŠ¹æœæœ€å¤§åŒ–
4. **åŒ…æ‹¬çš„ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ**: å†ç¾å¯èƒ½ã§æŒç¶šçš„ãªå­¦ç¿’ãƒ—ãƒ­ã‚»ã‚¹

##### å·®åˆ¥åŒ–ãƒã‚¤ãƒ³ãƒˆ

| ä¸€èˆ¬çš„ãªæ©Ÿæ¢°å­¦ç¿’ãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ« | ã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ |
|----------------------------|----------------|
| Jupyter Notebook ã§å®Œçµ | TDD + æœ¬ç•ªãƒ¬ãƒ‡ã‚£ãª API |
| ãƒ¢ãƒ‡ãƒ«è¨“ç·´ã®ã¿ | ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‹ã‚‰ API åŒ–ã¾ã§å®Œå…¨ãƒ•ãƒ­ãƒ¼ |
| ãƒ†ã‚¹ãƒˆãªã— | 84å€‹ã®ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹ã€94% ã‚«ãƒãƒ¬ãƒƒã‚¸ |
| å˜ä¸€ãƒ¢ãƒ‡ãƒ« | 4ã¤ã®ç•°ãªã‚‹å•é¡Œã‚’æ®µéšçš„ã«è§£æ±º |
| å‹ãƒ’ãƒ³ãƒˆãªã— | å®Œå…¨ãªå‹å®‰å…¨æ€§ |
| ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆä¸è¶³ | è©³ç´°ãªå®Ÿè£…ã‚¬ã‚¤ãƒ‰ + Swagger UI |

#### ğŸ“ å­¦ç¿’è€…ã¸ã®æœ€çµ‚ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸

æœ¬ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’é€šã˜ã¦ã€ã‚ãªãŸã¯ä»¥ä¸‹ã‚’æ‰‹ã«å…¥ã‚Œã‚‹ã“ã¨ãŒã§ãã¾ã™ï¼š

âœ… **å³å®Ÿè·µå¯èƒ½ãª TDD ã‚¹ã‚­ãƒ«**: æ¥­å‹™ãƒ¬ãƒ™ãƒ«ã§ã®å“è³ªé–‹ç™ºæ‰‹æ³•
âœ… **æ©Ÿæ¢°å­¦ç¿’ã®å®Ÿç”¨åŸºç¤**: ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹æ¥­ç•Œã¸ã®å‚å…¥åŸºç›¤
âœ… **ãƒ¢ãƒ€ãƒ³ Python é–‹ç™ºåŠ›**: ç¾å ´ã§æ±‚ã‚ã‚‰ã‚Œã‚‹æœ€æ–°æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯
âœ… **ç¶™ç¶šçš„æ”¹å–„ãƒã‚¤ãƒ³ãƒ‰**: å“è³ªã¨åŠ¹ç‡ã‚’ä¸¡ç«‹ã™ã‚‹é–‹ç™ºæ€è€ƒ
âœ… **æœ¬ç•ªé‹ç”¨çŸ¥è­˜**: å®Ÿéš›ã®ãƒ—ãƒ­ãƒ€ã‚¯ãƒˆé–‹ç™ºã«å¿…è¦ãªåŒ…æ‹¬çš„çŸ¥è­˜

**ğŸ¯ Python TDD æ©Ÿæ¢°å­¦ç¿’é–‹ç™ºãƒã‚¹ã‚¿ãƒ¼ã¸ã®é“ç­‹ã‚’å®Œå…¨ã«ç¤ºã—ãŸãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã¨ã—ã¦ã€ç¶™ç¶šçš„ãªå­¦ç¿’ã¨å®Ÿè·µçš„ãªæˆé•·ã‚’æ”¯æ´ã—ã¾ã™ï¼** âœ¨

---

### æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—

ã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’å®Œäº†ã—ãŸå¾Œã®æ¨å¥¨å­¦ç¿’ãƒ‘ã‚¹ã§ã™ï¼š

#### 1. å®Ÿè·µèª²é¡Œ

**åˆç´šèª²é¡Œï¼ˆ1-2é€±é–“ï¼‰**:
- Kaggle ã® Titanic ã‚³ãƒ³ãƒšãƒ†ã‚£ã‚·ãƒ§ãƒ³ã« TDD ã§ãƒãƒ£ãƒ¬ãƒ³ã‚¸
- æ—¢å­˜ã® 4ãƒ¢ãƒ‡ãƒ«ã«æ–°ã—ã„ç‰¹å¾´é‡ã‚’è¿½åŠ ã—ã¦ãƒ¢ãƒ‡ãƒ«æ”¹å–„
- API ã«èªè¨¼æ©Ÿèƒ½ï¼ˆJWTï¼‰ã‚’è¿½åŠ 

**ä¸­ç´šèª²é¡Œï¼ˆ2-4é€±é–“ï¼‰**:
- æ™‚ç³»åˆ—ãƒ‡ãƒ¼ã‚¿ï¼ˆæ ªä¾¡äºˆæ¸¬ã€éœ€è¦äºˆæ¸¬ï¼‰ã®æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«é–‹ç™º
- ã‚¢ãƒ³ã‚µãƒ³ãƒ–ãƒ«å­¦ç¿’ï¼ˆRandom Forestã€XGBoostï¼‰ã®å®Ÿè£…
- Docker ã«ã‚ˆã‚‹ã‚³ãƒ³ãƒ†ãƒŠåŒ–ã¨ CI/CD ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®æ§‹ç¯‰

**ä¸Šç´šèª²é¡Œï¼ˆ1-2ãƒ¶æœˆï¼‰**:
- ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°ï¼ˆTensorFlow/PyTorchï¼‰ã¸ã®æ‹¡å¼µ
- MLOps ãƒ„ãƒ¼ãƒ«ï¼ˆMLflowã€DVCï¼‰ã®å°å…¥
- æœ¬ç•ªç’°å¢ƒã¸ã®ãƒ‡ãƒ—ãƒ­ã‚¤ï¼ˆAWS Lambdaã€GCP Cloud Runï¼‰

#### 2. æ¨å¥¨å­¦ç¿’ãƒªã‚½ãƒ¼ã‚¹

**æ›¸ç±**:
- ã€Python ã§ã¯ã˜ã‚ã‚‹æ©Ÿæ¢°å­¦ç¿’ã€ï¼ˆAndreas C. MÃ¼llerã€Sarah Guido è‘—ï¼‰
- ã€ãƒ†ã‚¹ãƒˆé§†å‹•é–‹ç™ºã€ï¼ˆKent Beck è‘—ï¼‰
- ã€Clean Architectureã€ï¼ˆRobert C. Martin è‘—ï¼‰

**ã‚ªãƒ³ãƒ©ã‚¤ãƒ³ã‚³ãƒ¼ã‚¹**:
- [Coursera: Machine Learning Specialization](https://www.coursera.org/specializations/machine-learning-introduction)
- [fast.ai: Practical Deep Learning](https://course.fast.ai/)
- [MLOps Specialization](https://www.coursera.org/specializations/machine-learning-engineering-for-production-mlops)

**ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£**:
- [Kaggle](https://www.kaggle.com/): æ©Ÿæ¢°å­¦ç¿’ã‚³ãƒ³ãƒšãƒ†ã‚£ã‚·ãƒ§ãƒ³
- [PyData](https://pydata.org/): Python ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ã‚¹ã‚³ãƒŸãƒ¥ãƒ‹ãƒ†ã‚£
- [ML Papers](https://paperswithcode.com/): æœ€æ–°ã®æ©Ÿæ¢°å­¦ç¿’è«–æ–‡ã¨å®Ÿè£…

#### 3. ã‚­ãƒ£ãƒªã‚¢ãƒ‘ã‚¹

æœ¬ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ã‚¹ã‚­ãƒ«ã‚»ãƒƒãƒˆã¯ä»¥ä¸‹ã®è·ç¨®ã«ç›´çµã—ã¾ã™ï¼š

- **æ©Ÿæ¢°å­¦ç¿’ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢**: ãƒ¢ãƒ‡ãƒ«é–‹ç™ºã¨ãƒ‡ãƒ—ãƒ­ã‚¤
- **ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚¨ãƒ³ãƒ†ã‚£ã‚¹ãƒˆ**: ãƒ‡ãƒ¼ã‚¿åˆ†æã¨ãƒ“ã‚¸ãƒã‚¹ä¾¡å€¤å‰µå‡º
- **MLOps ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢**: ML ã‚·ã‚¹ãƒ†ãƒ ã®é‹ç”¨ã¨æœ€é©åŒ–
- **ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ï¼ˆML ç‰¹åŒ–ï¼‰**: API é–‹ç™ºã¨ã‚·ã‚¹ãƒ†ãƒ çµ±åˆ

---

### å‚è€ƒè³‡æ–™

**å…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ**:
- [scikit-learn å…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ](https://scikit-learn.org/)
- [FastAPI å…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ](https://fastapi.tiangolo.com/)
- [pandas å…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ](https://pandas.pydata.org/)
- [Pydantic å…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ](https://docs.pydantic.dev/)

**é–‹ç™ºãƒ„ãƒ¼ãƒ«**:
- [uv ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼](https://github.com/astral-sh/uv)
- [Ruff å…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ](https://docs.astral.sh/ruff/)
- [mypy å…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ](https://mypy.readthedocs.io/)
- [pytest å…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ](https://docs.pytest.org/)

**ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆä½œæˆæ—¥**: 2025å¹´10æœˆ18æ—¥

---

**Simple made easy.** ğŸ‰
